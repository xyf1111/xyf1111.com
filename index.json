[{"categories":["面试"],"content":"2021秋季面试","date":"2021-12-26","objectID":"/2021%E7%A7%8B%E5%AD%A3%E9%9D%A2%E8%AF%95/","tags":["生活"],"title":"2021秋季面试","uri":"/2021%E7%A7%8B%E5%AD%A3%E9%9D%A2%E8%AF%95/"},{"categories":["面试"],"content":"gin和beego的区别(中捷) Beego是典型的MVC框架 M：Model，即beego ORM，对象关系映射，以及对象的持久化 特性： 支持Go的所有类型存储 更简单的curd风格(增删改查) 完整实现健壮稳定的ORM 支持正则路由 支持session Gin不支持MVC 需要开发者自己实现MVC 特性： HTML渲染和模板 静态文件服务 不支持正则路由 不支持session(需要安装另外的包) 适用场景 Beego在业务方面较Gin支持的更多 在业务更加复杂的项目中，适用Beego 在需要快速开发的项目中，适用Beego 在1.0项目中，适用Beego Gin在性能方面较Beego更好 当某个接口性能遭到巨大挑战的时候，考虑使用Gin重写接口 如果项目的规模不大，业务相对简单，适用Gin ","date":"2021-12-26","objectID":"/2021%E7%A7%8B%E5%AD%A3%E9%9D%A2%E8%AF%95/:1:0","tags":["生活"],"title":"2021秋季面试","uri":"/2021%E7%A7%8B%E5%AD%A3%E9%9D%A2%E8%AF%95/"},{"categories":["面试"],"content":"mongo和redis的持久化区别(中捷) ","date":"2021-12-26","objectID":"/2021%E7%A7%8B%E5%AD%A3%E9%9D%A2%E8%AF%95/:2:0","tags":["生活"],"title":"2021秋季面试","uri":"/2021%E7%A7%8B%E5%AD%A3%E9%9D%A2%E8%AF%95/"},{"categories":["面试"],"content":"mongo和mysql的区别(中捷) ","date":"2021-12-26","objectID":"/2021%E7%A7%8B%E5%AD%A3%E9%9D%A2%E8%AF%95/:3:0","tags":["生活"],"title":"2021秋季面试","uri":"/2021%E7%A7%8B%E5%AD%A3%E9%9D%A2%E8%AF%95/"},{"categories":["面试"],"content":"redis实现分布式锁(珊瑚游戏) ","date":"2021-12-26","objectID":"/2021%E7%A7%8B%E5%AD%A3%E9%9D%A2%E8%AF%95/:4:0","tags":["生活"],"title":"2021秋季面试","uri":"/2021%E7%A7%8B%E5%AD%A3%E9%9D%A2%E8%AF%95/"},{"categories":["面试"],"content":"如果一个锁没有释放，资源被另一个线程获取，等到前一个线程释放之后会发生什么(珊瑚游戏) 两个线程发生并发显然是不允许的。 一般有两种方法解决改问题 确保代码在过期时间之前释放(添加一个确认值的判断) 为获取锁的线程添加守护线程，为将要过期但为释放的锁增加有效时间 ","date":"2021-12-26","objectID":"/2021%E7%A7%8B%E5%AD%A3%E9%9D%A2%E8%AF%95/:4:1","tags":["生活"],"title":"2021秋季面试","uri":"/2021%E7%A7%8B%E5%AD%A3%E9%9D%A2%E8%AF%95/"},{"categories":["面试"],"content":"redis多个进程持续对一个数进行递增，怎么让数增加到9999后回到0(珊瑚游戏) 使用lua脚本保证原子性 ","date":"2021-12-26","objectID":"/2021%E7%A7%8B%E5%AD%A3%E9%9D%A2%E8%AF%95/:5:0","tags":["生活"],"title":"2021秋季面试","uri":"/2021%E7%A7%8B%E5%AD%A3%E9%9D%A2%E8%AF%95/"},{"categories":["面试"],"content":"如何优雅的关闭进程(kill -9 暴力) (珊瑚游戏) 发送一个信号过去signal，类似于(Ctrl + C)，让该执行的执行完毕。 ","date":"2021-12-26","objectID":"/2021%E7%A7%8B%E5%AD%A3%E9%9D%A2%E8%AF%95/:6:0","tags":["生活"],"title":"2021秋季面试","uri":"/2021%E7%A7%8B%E5%AD%A3%E9%9D%A2%E8%AF%95/"},{"categories":["面试"],"content":"es存储后可以马上查到嘛 (珊瑚游戏) es数据插入后，需要刷新片区，最长1s。可以在请求时设置refresh=true，立马可见 ","date":"2021-12-26","objectID":"/2021%E7%A7%8B%E5%AD%A3%E9%9D%A2%E8%AF%95/:7:0","tags":["生活"],"title":"2021秋季面试","uri":"/2021%E7%A7%8B%E5%AD%A3%E9%9D%A2%E8%AF%95/"},{"categories":["面试"],"content":"es存储是同步还是异步的 (珊瑚游戏) 数据从mysql到es的同步 同步双写 将数据写入mysql时，同时将数据写入es，实现数据双写 优点： 业务逻辑简单 缺点： 硬编码：有需要写入mysql的地方都需要添加写入es的代码；业务强耦合；存在双写失败丢数据的风险；性能较差，本来mysql性能就不是很高，再加写一个es，系统的性能必然下降。 异步双写(MQ方式) 针对第一种同步双写的性能和数据丢失的问题，可以考虑引入MQ，从而实现异步双写的方案。由于MQ的性能比mysql高出一个数量级，所以性能可以得到显著的提高。 优点： 性能高，不存在丢数据问题 缺点： 硬编码：依然存在业务强耦合；依然存在复杂度增加；系统中加入MQ的代码；可能存在延时问题，程序的写入性能提高了，但是由于MQ的消费可能由于网络或其他原因导致用户写入的数据不一定可以马上看得到，造成延时。 定时器写入 对于实时性要求不高的情况下，可以考虑使用定时器来处理，具体如下： 数据库中添加一个字段为timestamp字段，任何curd操作都会导致该字段的时间发生变化；原来程序中的curd操作不做任何变化；增加一个定时器程序，让该程序按一定的时间周期扫描指定的表，把该时间段内发生变化的数据提取出来；逐条写入es内。 优点： 不改变原来代码，没有侵入性，没有硬编码；没有业务强耦合；不改变原来的程序性能；定时器代码编写不需要考虑增删改查。 缺点： 时效性较差，由于定时器工作周期不可能设在秒级，所以实时性没有2好；对数据库有一定轮询压力，一种改进方式是将轮询放到压力不大的重库上。 利用mysql的binlog来进行同步 具体步骤如下： 读取mysql的binlog日志，获取指定表的日志信息 将读取的信息转化为MQ 编写一个MQ的消费程序 不断消费MQ，每消费完一条消息，将消息写入es 优点： 没有代码侵入，没有硬编码；原有系统不需要任何变化，没有感知；性能高；业务解耦，不需要关注原来系统的业务逻辑。 缺点： 构建binlog系统复杂；存在MQ延时风险 ","date":"2021-12-26","objectID":"/2021%E7%A7%8B%E5%AD%A3%E9%9D%A2%E8%AF%95/:8:0","tags":["生活"],"title":"2021秋季面试","uri":"/2021%E7%A7%8B%E5%AD%A3%E9%9D%A2%E8%AF%95/"},{"categories":["面试"],"content":"mysql的约束 非空约束(not null 被设置非空约束的字段值不能为空) 唯一约束(unique 被设置唯一约束的字段值不能重复，但是可以为空) 主键约束(primark key 同时保证了唯一和非空) 外键约束(foreign key，让多个表之间关联，从而保证数据的正确性) ","date":"2021-12-26","objectID":"/2021%E7%A7%8B%E5%AD%A3%E9%9D%A2%E8%AF%95/:9:0","tags":["生活"],"title":"2021秋季面试","uri":"/2021%E7%A7%8B%E5%AD%A3%E9%9D%A2%E8%AF%95/"},{"categories":["面试"],"content":"优化MySQL数据库的八种方法 创建索引 对于查询占主要的应用来说，索引显得尤为重要。很多时候性能问题很简单的就是因为我们忘记添加索引造成的，或者说没有添加更为有效的索引导致。如果不添加索引，那么查找任何哪怕只是一条特定的数据都会进行一次全表扫描，如果一张表的数据很大而符合条件的结果又很少，那么不加索引会引起致命的性能下降。但是也不是什么情况都非得建索引不可，比如性别可能就只有两个值，建索引不仅没什么优势，还会影响更新速度，这被称为过度索引。 复合索引 比如有一条语句是这样的：select * from users where area=‘beijing’ and age=22; 如果我们是在area和age上分别创建单个索引的话，由于mysql查询每次只能使用一个索引，虽然这样已经相对不做索引时全表扫描提高了很多效率，但是如果在area和age两列上创建复合索引的话将带来更高的效率。如果我们创建了(area, age, salary)的复合索引，那么其实相当于创建了(area, age, salary), (area, age), (area)三个索引，这被称为最佳左前缀特性。因此我们在创建复合索引时应该将最常用作限制条件的列放在最左边，依次递减。 索引不会包含有Null值的列 只要列中包含有NULL值都将不会被包含在索引中，复合索引中只要有一列含有NULL值，那么这一列对于此复合索引就是无效的。所以我们在数据库设计时不要让字段的默认值为NULL 使用短索引 对串列进行索引，如果可能应该指定一个前缀长度。例如，如果有一个char(255)的列，如果在前10个或20个字符内，多数值是唯一的，那么就不要对这个列进行索引。短索引不仅可以提高查询速度而且可以节省磁盘空间和I/O操作。 排序的索引问题 mysql查询只使用一个索引，因此如果where子句中已经使用了索引的话，那么order by中的列是不会使用索引的。因此数据库默认排序可以符合要求的情况下不要使用排序操作；尽量不要包含多个列的排序，如果需要最好给这些列创建复合索引 like语句的操作 一般情况下不鼓励使用like操作，如果非使用不可，如何使用也是一个问题。like\"%aaa%“不会使用以索引而like\"aaa%“可以使用索引 不要在列上进行运算 select * from users where YEAR(adddate)\u003c2007;将在每个行上进行计算，这将导致索引失效而进行全表扫描，因此我们可以改成 select * from users where adddate\u003c‘2007-01-01’; 不要使用not in和\u003c \u003e操作 not in和\u003c \u003e 操作都不会使用索引将进行全表扫描。not in可以not exists代替，id \u003c \u003e 3则可使用id \u003e 3 or id \u003c 3来代替 ","date":"2021-12-26","objectID":"/2021%E7%A7%8B%E5%AD%A3%E9%9D%A2%E8%AF%95/:10:0","tags":["生活"],"title":"2021秋季面试","uri":"/2021%E7%A7%8B%E5%AD%A3%E9%9D%A2%E8%AF%95/"},{"categories":["生活"],"content":"简历","date":"2021-12-06","objectID":"/resume-2021-12-06/","tags":["简历"],"title":"花开简历","uri":"/resume-2021-12-06/"},{"categories":["生活"],"content":"个人信息 姓名：陈进煌 性别：男 年龄：24 手机号：18759882615 邮箱：2219316464@qq.com 专业：计算机科学与技术 应聘岗位：Golang开发工程师 ","date":"2021-12-06","objectID":"/resume-2021-12-06/:1:0","tags":["简历"],"title":"花开简历","uri":"/resume-2021-12-06/"},{"categories":["生活"],"content":"工作及教育经历 福建省花开传媒科技有限公司 2021-04~至今 软件研发部-golang开发工程师 厦门美城行动科技有限公司 2019-08~2021-03 软件研发部-后端开发 厦门青叶软件股份有限公司 2019-03~2019-07 软件研发部-后端开发 厦门通元微智能科技有限公司 2018-03~2018~11 软件研发部-软件测试 三明学院 2014-09~2018-07 计算机科学与技术 ","date":"2021-12-06","objectID":"/resume-2021-12-06/:2:0","tags":["简历"],"title":"花开简历","uri":"/resume-2021-12-06/"},{"categories":["生活"],"content":"专业技能 熟悉Golang，了解Java等编程语言 了解Beego，Gin框架 熟悉MySQL数据库，了解MongoDB，Elasticsearch 了解缓存系统Redis 了解Git版本控制 了解网络编程，TCP/IP协议 了解React和Ant Design ","date":"2021-12-06","objectID":"/resume-2021-12-06/:3:0","tags":["简历"],"title":"花开简历","uri":"/resume-2021-12-06/"},{"categories":["生活"],"content":"项目经历 花开APP golang开发 2021-04~至今 项目介绍：这个项目是自主研发的社交聊天APP。其中主要的功能包括动态广场、语音视频搭讪聊天、任务、个人信息设置以及充值提现等。采用经过封装的Gin框架，部分功能逐步拆分为微服务。数据库方面主要使用了MySQL、MongoDB和Elasticsearch，缓存方面使用Redis。 我的职责： 根据tapd了解对应任务需求，对于不确定需求进行讨论。 依据具体功能进行数据表的设计。 根据具体需求完成代码编写。 编写代码的单元测试。 提交Git，将任务交付测试进行测试。 根据测试提交的bug对代码进行调试修改。 主要实现功能： 动态模块（类似朋友圈） 1、发送的文字图片视屏等需经过数美的审核以及后台的人工审核。 2、对动态进行点赞评论。 3、收集附近的人对自动发送的动态进行随机点赞。 用户等级模块 1、根据用户的充值消费情况升级等级。 2、升级后进行消息推送。 任务模块 1、通过用户性别展示任务。 2、使用数值判断任务完成与否。 3、完成任务消息推送。 厦门美城行动管理系统 后端开发 2019-08~2021-03 项目介绍：这个项目是公司的后台管理系统。该系统主要是对公司对应的小程序和app提供数据的统计展示和管理等。系统后端是采用Beego框架，数据库使用MySQL，部分功能使用到Redis进行缓存。系统前端采用React框架，大部分使用Ant Design的UI组件。 我的职责： 根据实际业务需求，与产品经理确定具体功能及展现方式。 依据具体功能进行数据表的设计。 实现具体功能编写管理系统前端展示代码，与产品进行确认。 根据前端界面确定后台的接口，进行后台代码数据操作代码的编写。 若小程序，app有该功能相关的，为其提供相应的接口。 提交Git，交付测试进行测试。 根据测试提交的bug对代码进行调试修改。 船人网管理系统 后端开发 2019-03~2019-07 项目介绍：这个项目是一个关于船舶的后台管理系统。该系统主要是船舶及其周边产品的租赁及售卖网站的后台管理。系统后端是用的SpringMVC+SpringBoot+Mybatis，数据库使用MySQL，前端采用Vue框架。 我的职责 根据测试提交的对代码进行调试修改 根据产品需求实现Vue页面展示 实现接口功能 ","date":"2021-12-06","objectID":"/resume-2021-12-06/:4:0","tags":["简历"],"title":"花开简历","uri":"/resume-2021-12-06/"},{"categories":["面试"],"content":"Go Interview 09","date":"2021-11-26","objectID":"/go-interview-09/","tags":["golang"],"title":"Go Interview-09","uri":"/go-interview-09/"},{"categories":["面试"],"content":"Golang中除了加Mutex锁以外还有哪些方式安全读写共享变量 Golang中Goroutine可以通过Channel进行安全读写共享变量 ","date":"2021-11-26","objectID":"/go-interview-09/:1:0","tags":["golang"],"title":"Go Interview-09","uri":"/go-interview-09/"},{"categories":["面试"],"content":"无缓冲Chan的发送和接收是否同步 ch := make(chan int) 无缓冲的channel由于没有缓冲，发送和接收需要同步 ch := make(chan int, 2) 有缓冲channel不要求发送和接收操作同步 channel无缓冲时，发送堵塞直到数据被接收，接收堵塞直到读到数据 channel有缓冲时，当缓冲满时发送堵塞，当缓冲空时接收堵塞 ","date":"2021-11-26","objectID":"/go-interview-09/:2:0","tags":["golang"],"title":"Go Interview-09","uri":"/go-interview-09/"},{"categories":["面试"],"content":"go语言的并发机制以及它所使用的CSP并发模型 CSP模型是上世纪七十年代提出的，不同于传统的多线程通过共享内存来通信，CSP讲究的是\"以通信方式来共享内存\"。用于描述两个独立的并发实体通过共享的通信channel(管道)进行通信的并发模型。CSP中channel是第一类对象，它不关注发送消息的实体，而关注与发送消息时使用的channel Golang中channel是被单独创建并且可以在进程之间传递，它的通信模式类似于boss-worker模式，一个实体通过将消息发送到channel中，然后又监听这个channel的实体处理，两个实体之间是匿名的，这个就是实现实体中间的解耦，其中channel是同步的一个消息被发送到channel中，最终是一定要被另外的实体消费掉的，在实现原理上类似一个堵塞的消息队列 Goroutine是Golang实际并发执行的实体，它底层是使用协程(coroutine)实现并发的，coroutine是一种运行在用户态的用户线程，类似于greenthread，go底层选择使用coroutine的出发点是因为，它具有以下特点： 用户空间 避免了内核态和用户态的切换导致的成本 可以由语言和框架进行调度 更小的栈空间允许创建大量的实例 Golang中Goroutine的特性 Golang内部有三个对象：P对象(processor)代表上下文(或者可以认为是cpu)，M(work thread)代表工作线程，G对象(goroutine) 正常情况向下一个cpu对象启动一个工作线程，线程去检查并执行goroutine对象。碰到goroutine对象阻塞的时候，会启动一个新的工作线程，以充分利用cpu资源。所以有时候线程对象会比处理器对象多很多 G(Goroutine)：我们所说的协程，为用户级的轻量级线程，每个Goroutine对象中的sched保存着其上下文信息 M(Machine)：对内核级线程的封装，数量对象真实的CPU数(真正干活的对象) P(Processor)：即为G和M的调度对象，用来调度G和M之间的关联关系，其数量可通过GOMAXPROCS()来设置，默认为核心数 在单核情况下，所有Goroutine运行在同一个线程(M0)中，每一个线程维护一个上下文(P)，任何时刻，一个上下文中只有一个Goroutine，其他Goroutine在runqueue中等待 一个Goroutine运行完自己的时间片后，让出上下文，自己回到runqueue中等待。 当正在运行的G0阻塞的时候(可能需要IO)，会再创建一个线程(M1)，P转到新的线程中去运行。 当M0返回时，它会尝试从其他线程中’偷’一个上下文过来，如果没有偷到，会把Goroutine放到Global runqueue中去，然后把自己放入线程缓存中。上下文会定时检查Gloabl runqueue。 Golang是为并发而生的语言，Go语言是为数不多的在语言层面实现并发的语言；也正是Go语言的并发特性，吸引了全球无数的开发者 Golang的CSP并发模型是通过Goroutine和Channel来实现的 Goroutine是Go语言中并发的执行单位。有点抽象，其实就是和传统概念上的\"线程\"类似，可以理解为\"线程\"，Channel是Go语言中各个并发结构体(Goroutine)之前的通信机制。通常Channel，是各个Goroutine之间通信的\"管道\"，有点类似于Linux中的管道 通信机制channel也很方便，传数据用channel \u003c- data，取数据用 \u003c- channel 在通信过程中，传数据channel \u003c- data 和取数据 \u003c- channel必然会成对出现，因为这边传，那边取，两个goroutine之间才会实现通信 而且不管传还是取，必阻塞，直到另外的goroutine传或者取为止 ","date":"2021-11-26","objectID":"/go-interview-09/:3:0","tags":["golang"],"title":"Go Interview-09","uri":"/go-interview-09/"},{"categories":["面试"],"content":"Golang中常用的并发模型 Golang中常用的并发模型有三种： 通过channel通知实现并发控制 无缓冲的通道指的是通道的大小为0，也就是说，这种类型的通道在接受前没有能力保存任何值，它要求发送goroutine和接收goroutine同时准备好，才可以完成发送和接收的操作 从上面无缓冲的通道定义来看，发送goroutine和接收goroutine必须是同步的，同时准备后，如果没有同时准备好的话，先执行的操作就会阻塞等待，直到另一个相对应的操作准备好为止。这种无缓冲通道我们也称为同步通道 func main() { ch := make(chan struct{}) go func() { fmt.Printlf(\"start working\") time.Sleep(time.Second * 1) ch \u003c- struct{} {} } () \u003c- ch fmt.Println(\"finished\") } 当主goroutine运行到 \u003c- ch 接收channel的值的时候，如果该channel中没有数据，就会一直阻塞等待，直到有值，这样就可以实现简单的并发控制 通过sync包中的WaitGroup实现并发控制 Goroutine是异步执行的，有的时候为了防止在结束main函数的时候结束掉Goroutine，所以需要同步等待，这个时候就需要用WaitGroup了，在sync包中提供了WaitGroup，它会等待它收集的所有goroutine任务全部完成。在WaitGroup里主要有三个方法 Add 可以添加或者减少goroutine的数量 Done 相当于Add(-1) Wait 执行后会阻塞主线程，直到WaitGroup里的值减至0 在主goroutine中Add(delta int)索要等待goroutine的数量。在每一个goroutine完成后Done()表示这一个goroutine已经完成，当所有的goroutine都完成后，在主goroutine中WaitGroup返回 在Go 1.7 以后引入了强大的Context上下文，实现并发控制 通常在一些简单场景下使用channel和WaitGroup已经足够了，但是当面临一些复杂多变的网络并发场景下channel和WaitGroup显得有些力不从心了。比如一个网路请求Request，每个Request都需要开启一个goroutine做一些事情，这些goroutine又可能开启其他的goroutine，比如数据库和RPC服务。所以我们需要一种可以跟踪goroutine的方案，才可以达到控制他们的目的，这就是Go语言为我们提供的Context，称之为上下文非常贴切，它就是goroutine的上下文。它是包括一个程序的运行环境、现场和快照等。每个程序要运行时都需要知道当前程序的运行状态，通常Go将这些封装在一个Context里，再将它传给要执行的goroutine。 context包主要是用来处理多个goroutine之间共享数据，及多个goroutine的管理 ","date":"2021-11-26","objectID":"/go-interview-09/:4:0","tags":["golang"],"title":"Go Interview-09","uri":"/go-interview-09/"},{"categories":["面试"],"content":"JSON标准库对 nil slice和 空 slice的处理是一致的吗 首先JSON标准库对 nil slice 和空slice的处理是不一致的 通常错误的用法，会报数组越界的错误，因为只是声明了slice，却没有个实例化的对象 var slice []int slice[1] = 0 此时slice的值是nil，这种情况可以用于需要返回slice的函数，当函数出现异常的时候，保证函数依然会有nil的返回值 empty slice是指slice不为nil，但是slice没有值，slice底层的空间是空的，此时的定义如下 slice := make([]int, 0) slice := []int{} 当我们查询或者处理一个空的列表的时候，这非常有用，它会告诉我们返回的是一个列表，但是列表内没有任何值 总之，nil slice 和 empty slice 是不同的东西，需要我们加以区分 ","date":"2021-11-26","objectID":"/go-interview-09/:5:0","tags":["golang"],"title":"Go Interview-09","uri":"/go-interview-09/"},{"categories":["面试"],"content":"协程，线程，进程的区别 进程 进程是具有一定独立功能的程序关于某种数据集合上的一次运行活动，进程是系统进行资源分配和调度的一个独立单位。每个进程都有自己的独立内存空间，不同进程通过进程间通信来通信。由于进程比较重量，占据独立内存，所以上下文进程间的切换开销(栈，寄存器，虚拟内存，文件句柄等)比较大，但相对比较稳定安全。 线程 线程是进程的一个实体，是CPU调度和分派的基本单位，它是比进程更小的能独立运行的基本单位，线程自己基本上不拥有系统资源，只拥有一点在运行中必不可少的资源(如程序计数器，一组寄存器和栈)，但是它可与同属一个进程的其他线程共享进程所拥有的的全部资源。线程间通信主要通过共享内存，上下文切换很快，资源开销较少，但相比进程不够稳定容易丢失数据 协程 协程是一种轻量级的线程，协程的调度完全由用户控制。协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存在寄存器上下文和栈，直接操作栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切换非常快。 ","date":"2021-11-26","objectID":"/go-interview-09/:6:0","tags":["golang"],"title":"Go Interview-09","uri":"/go-interview-09/"},{"categories":["面试"],"content":"互斥锁，读写锁，死锁问题是怎么解决的 互斥锁 互斥锁就是互斥变量mutex，用来锁住临界区的 条件锁就是条件变量，当进程的某些资源要求不满足时就进入休眠，也就是锁住了。当资源被分配了，条件锁打开了，进程继续进行；读写锁也类似，用于缓冲区等临界资源能互斥访问的。 读写锁 通常有些公共数据修改的机会很少，但其读的机会很多。并且在读的过程中会伴随着查找，给这种代码加锁会降低我们的程序效率。读写锁可以解决这个问题 注意：写独占，读共享，写锁优先级高 死锁 一般情况下，如果同一个线程先后两次调用lock，在第二次调用时，由于锁已经被占用，该线程会挂起等待别的线程释放锁，然而锁正是被自己占用着的，该线程又被挂起而没有机会释放锁，因此就永远处于挂起等待状态了，这叫做死锁(Deadlock)。另一种情况是：若线程A获得了锁1，线程B获得了锁2，这时线程A调用lock试图获得锁2，结果是需要挂起等待线程B释放锁2，结果是需要挂起等待线程B释放锁2，而这时线程B也调用lock试图获得锁1，结果是需要挂起等待线程A释放锁1，于是线程A和B都永远处于挂起的状态 死锁产生的四个必要条件： 互斥条件：一个资源每次只能被一个进程使用 请求和保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放 不剥夺资源：进程已获得的资源，在未使用完之前不能强行剥夺 循环等待条件：若干进程之间形成一种头尾相接的循环等待资源关系。 这四个条件是死锁的必要条件，只要系统发生死锁，这些条件必然成立，而只要上述条件之一不满足，就不会发生死锁 预防死锁 可以把资源一次性分配： (破坏请求和保持条件) 然后剥夺资源： 即当某进程新的资源未满足时，释放已占有的资源(破坏不可剥夺条件) 资源有序分配法： 系统给每类资源赋予一个编号，每一个进程按编号递增的顺序请求资源，释放则相反(破坏环路等待条件) 避免死锁 预防死锁的几种策略，会严重地损坏系统性能。因此在避免死锁时，要施加较弱的限制，从而获得较满意的系统性能。由于在避免死锁的策略中，允许进程动态地申请资源。因而，系统在进行资源分配之前预先计算资源分配的安全性。若此次分配不会导致系统进入不安全状态，则将资源分配给进程；否则进程等待。其中最具代表性的避免死锁算法是银行家算法。 检测死锁 首先为每个进程和每个资源指定一个唯一的号码，然后建立资源分配表和进程等待表 解除死锁 当发现有进程死锁后，便应立即把它从死锁状态中解脱出来，常采用的方法有 1. 剥夺资源 从其他进程剥夺足够的资源给死锁进程，以解除死锁状态 2. 撤销进程 可以直接撤销死锁进程或撤销代价最小的进程，直至有足够的资源可用，死锁状态消除为止，所谓代价是指优先级、运行代价、进程的重要性和价值等 ","date":"2021-11-26","objectID":"/go-interview-09/:7:0","tags":["golang"],"title":"Go Interview-09","uri":"/go-interview-09/"},{"categories":["面试"],"content":"Golang的内存模型，为什么小对象多了会造成gc压力 通常小对象过多会导致GC三色法消耗过多的GPU。优化思路，减少对象分配 ","date":"2021-11-26","objectID":"/go-interview-09/:8:0","tags":["golang"],"title":"Go Interview-09","uri":"/go-interview-09/"},{"categories":["面试"],"content":"Data Race问题怎么解决，能不能加锁解决这个问题 同步访问共享数据是处理数据竞争的一种有效的方法。golang在1.1之后引入了竞争检测机制，可以使用go run -race 或者 go build -race来进行静态检测。其在内部的实现是，开启多个协程执行同一个命令，并且记录下每个变量的状态。 想要解决数据竞争的问题可以使用互斥锁sync.Mutex，解决数据竞争(Data race)，也可以使用管道解决，使用管道的效率比互斥锁高 ","date":"2021-11-26","objectID":"/go-interview-09/:9:0","tags":["golang"],"title":"Go Interview-09","uri":"/go-interview-09/"},{"categories":["面试"],"content":"什么是channel，为什么它可以做到线程安全 Channel是Go中的一个核心类型，可以把它看成一个管道，通过它并发核心单元就可以发送或者接受数据进行通讯(communication)，Channel也可以理解是一个先进先出的队列，通过管道进行通信 Golang的channel，发送一个数据到Channel和从一个Channel接收一个数据都是原子性的。而且Go的设计思想就是不通过共享内存来通信，而是通过通信来共享内存，前者就是传统的加锁，后者就是Channel。也就是说，设计Channel的主要目的就是在多任务之间传递数据，这当然是安全的。 ","date":"2021-11-26","objectID":"/go-interview-09/:10:0","tags":["golang"],"title":"Go Interview-09","uri":"/go-interview-09/"},{"categories":["面试"],"content":"Golang GC时会发生什么 什么是垃圾回收 内存管理是程序员开发应用的一大难题。传统的系统级编程语言(主要指c/c++)中，程序开发者必须对内存小心的进行管理操作，控制内存的申请和释放。因为稍有不慎，就可能产生内存泄露问题，这种问题不易发现并且很难定位，一直成为困扰程序开发者的噩梦，解决方法 内存泄露检测工具。这种工具的原理一般是静态代码扫描，通过扫描程序检测可能出现内存泄露的代码段。然而检测工具难免会有疏漏和不足，只能起到辅助作用 智能指针。这是c++中引入的自动内存管理方法，通过拥有自动内存管理功能的指针对象来引用对象，使程序员不用太关注内存的释放，而达到内存自动释放的目的。这种方法是采用最广泛的做法，但是对程序开发者有一定的学习成本(并非语言层面的原生支持)，而且一旦有忘记使用的场景依然无法避免内存泄露。 Golang GC时会发生什么 Golang 1.5后，采取的是\"非分代的，非移动的，并发的，三色的\"标记清除垃圾回收算法 golang中的gc基本上是标记清除的过程 gc的过程一共分为四个阶段 栈扫描(开始时STW) 第一次标记(并发) 第二次标记(STW) 清除(并发) 整个进程空间里申请每个对象占据的内存可以视为一个图，初始状态下每个内存对象都是白色标记。 先STW，做一些准备工作，比如enable write barrier。然后取消STW，将扫描任务作为多个并发的goroutine立即入队给调度器，进而被CPU处理 第一轮扫描root对象，包括全局指针和goroutine栈上的指针，标记为灰色放入队列 第二轮将第一步队列中的对象引用的对象置为灰色加入队列，一个对象引用的所有对象都只会并加入队列后，这个对象才能置为黑色并从队列之中以取出。循环往复，最后队列为空时，整个图剩下的白色内存空间即不可到达的对象，即没有被引用的对象。 第三轮再次STW，将第二轮过程中新增对象申请的内存进行标记及(灰色)，这里使用write barrier(写屏障)去记录 Golang gc优化的核心就是尽量使得STW(Stop The World)的时间越来越短 ","date":"2021-11-26","objectID":"/go-interview-09/:11:0","tags":["golang"],"title":"Go Interview-09","uri":"/go-interview-09/"},{"categories":["面试"],"content":"并发编程概念是什么 并行是指两个或者多个事件在同一时刻发生；并发是指两个或者多个时间在同一时间间隔发生。 并行是在不同实体上的多个事件，并发是在同一实体上的多个事件。在一台处理器上\"同时\"处理多个任务，在多台处理器上同时处理多个任务。 并发偏重于多个任务交替执行，而多个任务之间有可能还是串行的。而并行是真正意义上的\"同时执行\" 并发编程是指在一台处理器上\"同时\"处理多个任务。并发是在同一实体上的多个事件。多个事件在同一时间间隔发生。并发编程的目的是充分利用处理器的每一个核，以达到最高的处理性能 ","date":"2021-11-26","objectID":"/go-interview-09/:12:0","tags":["golang"],"title":"Go Interview-09","uri":"/go-interview-09/"},{"categories":["面试"],"content":"负载均衡的原理是什么 负载均衡是高可用网络基础架构的关键组件，通常用于将工作负载分布到多个服务器来提高网站、应用、数据库或其他服务的性能和可靠性。负载均衡，其核心就是网络流量分发，分很多纬度。 负载均衡通常是分摊到很多个操作单元上执行，例如Web服务器，FTP服务器、企业关键应用服务器和其他关键任务服务器等，从而共同完成工作任务 负载均衡是建立在现有网络结构之上，它提供了一种廉价有效透明的方法扩展网络设备和服务器的带宽、增加吞吐量、加强网络数据处理能力、提高网络的灵活性和可用性 ","date":"2021-11-26","objectID":"/go-interview-09/:13:0","tags":["golang"],"title":"Go Interview-09","uri":"/go-interview-09/"},{"categories":["学习"],"content":"Go 哈希表","date":"2021-11-24","objectID":"/go-hash/","tags":["go"],"title":"Go Hash","uri":"/go-hash/"},{"categories":["学习"],"content":"本节会介绍Go语言的哈希的实现原理，哈希是除了数组之外，最常见的数据结构。几乎所有的语言都会有数组和哈希表两种集合元素，有的语言将数组实现成列表，而有的语言将哈希称作字典或者映射。无论如何命名或者如何实现，数组和哈希是两种设计集合元素的思路，数组用于表示元素的序列，而哈希表示的是键值对之间映射关系。 哈希表是一种古老的数据结构，在 1953 年就有人使用拉链法实现了哈希表，它能够通过键直接获取该键对应的值。 ","date":"2021-11-24","objectID":"/go-hash/:0:0","tags":["go"],"title":"Go Hash","uri":"/go-hash/"},{"categories":["学习"],"content":"设计原理 哈希表是计算机科学中的最重要数据结构之一，这不仅因为它 O(1) 的读写性能非常优秀，还因为它提供了键值之间的映射。想要实现一个性能优异的哈希表，需要注意两个关键点 —— 哈希函数和冲突解决方法。 ","date":"2021-11-24","objectID":"/go-hash/:1:0","tags":["go"],"title":"Go Hash","uri":"/go-hash/"},{"categories":["学习"],"content":"哈希函数 实现哈希表的关键点在于哈希函数的选择，哈希函数的选择在很大程度上能够决定哈希表的读写性能。在理想情况下，哈希函数应该能够将不同键映射到不同的索引上，这要求哈希函数的输出范围大于输入范围，但是由于键的数量会远远大于映射的范围，所以在实际使用时，这个理想的效果是不可能实现的。 完美哈希函数\u0026ldquo;完美哈希函数\u0026rdquo; \"\r完美哈希函数\r 比较实际的方式是让哈希函数的结果能够尽可能的均匀分布，然后通过工程上的手段解决哈希碰撞的问题。哈希函数映射的结果一定要尽可能均匀，结果不均匀的哈希函数会带来更多的哈希冲突以及更差的读写性能。 不均匀哈希函数\u0026ldquo;不均匀哈希函数\u0026rdquo; \"\r不均匀哈希函数\r 如果使用结果分布较为均匀的哈希函数，那么哈希的增删改查的时间复杂度为 O(1)；但是如果哈希函数的结果分布不均匀，那么所有操作的时间复杂度可能会达到 O(n)，由此看来，使用好的哈希函数是至关重要的。 ","date":"2021-11-24","objectID":"/go-hash/:1:1","tags":["go"],"title":"Go Hash","uri":"/go-hash/"},{"categories":["学习"],"content":"冲突解决 就像我们之前所提到的，在通常情况下，哈希函数输入的范围一定会远远大于输出的范围，所以在使用哈希表时一定会遇到冲突，哪怕我们使用了完美的哈希函数，当输入的键足够多也会产生冲突。然而多数的哈希函数都是不够完美的，所以仍然存在发生哈希碰撞的可能，这时就需要一些方法来解决哈希碰撞的问题，常见方法的就是开放寻址法和拉链法。 需要注意的是，这里提到的哈希碰撞不是多个键对应的哈希完全相等，可能是多个哈希的部分相等，例如：两个键对应哈希的前四个字节相同。 开放寻址法 开放寻址法是一种在哈希表中解决哈希碰撞的方法，这种方法的核心思想是依次探测和比较数组中的元素以判断目标键值对是否存在于哈希表中，如果我们使用开放寻址法来实现哈希表，那么实现哈希表底层的数据结构就是数组，不过因为数组的长度有限，向哈希表写入 (author, draven) 这个键值对时会从如下的索引开始遍历： index := hash(\"author\") % array.len 当我们向当前哈希表写入新的数据时，如果发生了冲突，就会将键值对写入到下一个索引不为空的位置： 开放地址法写入数据\u0026ldquo;开放地址法写入数据\u0026rdquo; \"\r开放地址法写入数据\r 如上图所示，当 Key3 与已经存入哈希表中的两个键值对 Key1 和 Key2 发生冲突时，Key3 会被写入 Key2 后面的空闲位置。当我们再去读取 Key3 对应的值时就会先获取键的哈希并取模，这会先帮助我们找到 Key1，找到 Key1 后发现它与 Key 3 不相等，所以会继续查找后面的元素，直到内存为空或者找到目标元素。 开放地址法读取数据\u0026ldquo;开放地址法读取数据\u0026rdquo; \"\r开放地址法读取数据\r 当需要查找某个键对应的值时，会从索引的位置开始线性探测数组，找到目标键值对或者空内存就意味着这一次查询操作的结束。 开放寻址法中对性能影响最大的是装载因子，它是数组中元素的数量与数组大小的比值。随着装载因子的增加，线性探测的平均用时就会逐渐增加，这会影响哈希表的读写性能。当装载率超过 70% 之后，哈希表的性能就会急剧下降，而一旦装载率达到 100%，整个哈希表就会完全失效，这时查找和插入任意元素的时间复杂度都是 O(n) 的，这时需要遍历数组中的全部元素，所以在实现哈希表时一定要关注装载因子的变化。 拉链法 与开放地址法相比，拉链法是哈希表最常见的实现方法，大多数的编程语言都用拉链法实现哈希表，它的实现比较开放地址法稍微复杂一些，但是平均查找的长度也比较短，各个用于存储节点的内存都是动态申请的，可以节省比较多的存储空间。 实现拉链法一般会使用数组加上链表，不过一些编程语言会在拉链法的哈希中引入红黑树以优化性能，拉链法会使用链表数组作为哈希底层的数据结构，我们可以将它看成可以扩展的二维数组： 拉链法写入数据\u0026ldquo;拉链法写入数据\u0026rdquo; \"\r拉链法写入数据\r 如上图所示，当我们需要将一个键值对 (Key6, Value6) 写入哈希表时，键值对中的键 Key6 都会先经过一个哈希函数，哈希函数返回的哈希会帮助我们选择一个桶，和开放地址法一样，选择桶的方式是直接对哈希返回的结果取模 index := hash(\"Key6\") % array.len 选择了 2 号桶后就可以遍历当前桶中的链表了，在遍历链表的过程中会遇到以下两种情况： 找到键相同的键值对 — 更新键对应的值 没有找到键相同的键值对 — 在链表的末尾追加新的键值对； 如果要在哈希表中获取某个键对应的值，会经历如下的过程： 拉链法读取数据\u0026ldquo;拉链法读取数据\u0026rdquo; \"\r拉链法读取数据\r Key11 展示了一个键在哈希表中不存在的例子，当哈希表发现它命中 4 号桶时，它会依次遍历桶中的链表，然而遍历到链表的末尾也没有找到期望的键，所以哈希表中没有该键对应的值。 在一个性能比较好的哈希表中，每一个桶中都应该有 0~1 个元素，有时会有 2~3 个，很少会超过这个数量。计算哈希、定位桶和遍历链表三个过程是哈希表读写操作的主要开销，使用拉链法实现的哈希也有装载因子这一概念： 装载因子:=元素数量÷桶数量 与开放地址法一样，拉链法的装载因子越大，哈希的读写性能就越差。在一般情况下使用拉链法的哈希表装载因子都不会超过 1，当哈希表的装载因子较大时会触发哈希的扩容，创建更多的桶来存储哈希中的元素，保证性能不会出现严重的下降。如果有 1000 个桶的哈希表存储了 10000 个键值对，它的性能是保存 1000 个键值对的 1/10，但是仍然比在链表中直接读写好 1000 倍。 ","date":"2021-11-24","objectID":"/go-hash/:1:2","tags":["go"],"title":"Go Hash","uri":"/go-hash/"},{"categories":["学习"],"content":"数据结构 Go 语言运行时同时使用了多个数据结构组合表示哈希表，其中runtime.hmap是最核心的结构体，我们先来了解一下该结构体的内部字段： type hmap struct { count int flags uint8 B uint8 noverflow uint16 hash0 uint32 buckets unsafe.Pointer oldbuckets unsafe.Pointer nevacuate uintptr extra *mapextra } type mapextra struct { overflow *[]*bmap oldoverflow *[]*bmap nextOverflow *bmap } count表示当前哈希表中的元素数量 B表示当前哈希表持有的buckets数量，但是因为哈希表中桶的数量都 2 的倍数，所以该字段会存储对数，也就是len(buckets) == 2^B； hash0是哈希的种子，它能为哈希函数的结果引入随机性，这个值在创建哈希表时确定，并在调用哈希函数时作为参数传入； oldbuckets是哈希在扩容时用于保存之前buckets的字段，它的大小是当前buckets的一半； 哈希表的数据结构\u0026ldquo;哈希表的数据结构\u0026rdquo; \"\r哈希表的数据结构\r 如上图所示哈希表runtime.hmap的桶是runtime.bmap。每一个runtime.bmap都能存储 8 个键值对，当哈希表中存储的数据过多，单个桶已经装满时就会使用extra.nextOverflow中桶存储溢出的数据。 上述两种不同的桶在内存中是连续存储的，我们在这里将它们分别称为正常桶和溢出桶，上图中黄色的runtime.bmap就是正常桶，绿色的runtime.bmap是溢出桶，溢出桶是在 Go 语言还使用 C 语言实现时使用的设计，由于它能够减少扩容的频率所以一直使用至今。 桶的结构体runtime.bmap在 Go 语言源代码中的定义只包含一个简单的tophash字段，tophash存储了键的哈希的高 8 位，通过比较不同键的哈希的高 8 位可以减少访问键值对次数以提高性能： type bmap struct { tophash [bucketCnt]uint8 } 在运行期间，runtime.bmap结构体其实不止包含tophash字段，因为哈希表中可能存储不同类型的键值对，而且 Go 语言也不支持泛型，所以键值对占据的内存空间大小只能在编译时进行推导。runtime.bmap中的其他字段在运行时也都是通过计算内存地址的方式访问的，所以它的定义中就不包含这些字段，不过我们能根据编译期间的cmd/compile/internal/gc.bmap函数重建它的结构： type bmap struct { topbits [8]uint8 keys [8]keytype values [8]valuetype pad uintptr overflow uintptr } 随着哈希表存储的数据逐渐增多，我们会扩容哈希表或者使用额外的桶存储溢出的数据，不会让单个桶中的数据超过 8 个，不过溢出桶只是临时的解决方案，创建过多的溢出桶最终也会导致哈希的扩容。 从 Go 语言哈希的定义中可以发现，改进元素比数组和切片复杂得多，它的结构体中不仅包含大量字段，还使用复杂的嵌套结构，后面的小节会详细介绍不同字段的作用。 ","date":"2021-11-24","objectID":"/go-hash/:2:0","tags":["go"],"title":"Go Hash","uri":"/go-hash/"},{"categories":["学习"],"content":"初始化 既然已经介绍了哈希表的基本原理和实现方法，那么就可以开始分析 Go 语言中哈希表的实现了，首先要分析的是 Go 语言初始化哈希的两种方法 — 通过字面量和运行时 ","date":"2021-11-24","objectID":"/go-hash/:3:0","tags":["go"],"title":"Go Hash","uri":"/go-hash/"},{"categories":["学习"],"content":"字面量 目前的现代编程语言基本都支持使用字面量的方式初始化哈希，一般都会使用key: value的语法来表示键值对，Go 语言中也不例外： hash := map[string]int{ \"1\": 2, \"3\": 4, \"5\": 6, } 我们需要在初始化哈希时声明键值对的类型，这种使用字面量初始化的方式最终都会通过cmd/compile/internal/gc.maplit初始化，我们来分析一下该函数初始化哈希的过程： func maplit(n *Node, m *Node, init *Nodes) { a := nod(OMAKE, nil, nil) a.Esc = n.Esc a.List.Set2(typenod(n.Type), nodintconst(int64(n.List.Len()))) litas(m, a, init) entries := n.List.Slice() if len(entries) \u003e 25 { ... return } // Build list of var[c] = expr. // Use temporaries so that mapassign1 can have addressable key, elem. ... } 当哈希表中的元素数量少于或者等于 25 个时，编译器会将字面量初始化的结构体转换成以下的代码，将所有的键值对一次加入到哈希表中： hash := make(map[string]int, 3) hash[\"1\"] = 2 hash[\"3\"] = 4 hash[\"5\"] = 6 这种初始化的方式与的数组和切片几乎完全相同，由此看来集合类型的初始化在 Go 语言中有着相同的处理逻辑。 一旦哈希表中元素的数量超过了 25 个，编译器会创建两个数组分别存储键和值，这些键值对会通过如下所示的 for 循环加入哈希： hash := make(map[string]int, 26) vstatk := []string{\"1\", \"2\", \"3\", ... ， \"26\"} vstatv := []int{1, 2, 3, ... , 26} for i := 0; i \u003c len(vstak); i++ { hash[vstatk[i]] = vstatv[i] } 这里展开的两个切片vstatk和vstatv还会被编辑器继续展开，具体的展开方式可以阅读上一节了解切片的初始化，不过无论使用哪种方法，使用字面量初始化的过程都会使用 Go 语言中的关键字make来创建新的哈希并通过最原始的[]语法向哈希追加元素。 ","date":"2021-11-24","objectID":"/go-hash/:3:1","tags":["go"],"title":"Go Hash","uri":"/go-hash/"},{"categories":["学习"],"content":"运行时 当创建的哈希被分配到栈上并且其容量小于BUCKETSIZE = 8时，Go 语言在编译阶段会使用如下方式快速初始化哈希，这也是编译器对小容量的哈希做的优化： var h *hmap var hv hmap var bv bmap h := \u0026hv b := \u0026bv h.buckets = b h.hash0 = fashtrand0() 除了上述特定的优化之外，无论make是从哪里来的，只要我们使用make创建哈希，Go 语言编译器都会在类型检查期间将它们转换成runtime.makemap，使用字面量初始化哈希也只是语言提供的辅助工具，最后调用的都是runtime.makemap： func makemap(t *maptype, hint int, h *hmap) *hmap { mem, overflow := math.MulUintptr(uintptr(hint), t.bucket.size) if overflow || mem \u003e maxAlloc { hint = 0 } if h == nil { h = new(hmap) } h.hash0 = fastrand() B := uint8(0) for overLoadFactor(hint, B) { B++ } h.B = B if h.B != 0 { var nextOverflow *bmap h.buckets, nextOverflow = makeBucketArray(t, h.B, nil) if nextOverflow != nil { h.extra = new(mapextra) h.extra.nextOverflow = nextOverflow } } return h } 这个函数会按照下面的步骤执行： 计算哈希占用的内存是否溢出或者超出能分配的最大值； 调用runtime.fastrand获取一个随机的哈希种子； 根据传入的hint计算出需要的最小需要的桶的数量； 使用runtime.makeBucketArray创建用于保存桶的数组； runtime.makeBucketArray会根据传入的B计算出的需要创建的桶数量并在内存中分配一片连续的空间用于存储数据： func makeBucketArray(t *maptype, b uint8, dirtyalloc unsafe.Pointer) (buckets unsafe.Pointer, nextOverflow *bmap) { base := bucketShift(b) nbuckets := base if b \u003e= 4 { nbuckets += bucketShift(b - 4) sz := t.bucket.size * nbuckets up := roundupsize(sz) if up != sz { nbuckets = up / t.bucket.size } } buckets = newarray(t.bucket, int(nbuckets)) if base != nbuckets { nextOverflow = (*bmap)(add(buckets, base*uintptr(t.bucketsize))) last := (*bmap)(add(buckets, (nbuckets-1)*uintptr(t.bucketsize))) last.setoverflow(t, (*bmap)(buckets)) } return buckets, nextOverflow } 当桶的数量小于2^4时，由于数据较少、使用溢出桶的可能性较低，会省略创建的过程以减少额外开销； 当桶的数量多于2^4时，会额外创建2^(B−4)个溢出桶； 根据上述代码，我们能确定在正常情况下，正常桶和溢出桶在内存中的存储空间是连续的，只是被runtime.hmap中的不同字段引用，当溢出桶数量较多时会通过runtime.newobject创建新的溢出桶。 ","date":"2021-11-24","objectID":"/go-hash/:3:2","tags":["go"],"title":"Go Hash","uri":"/go-hash/"},{"categories":["学习"],"content":"读写操作 哈希表作为一种数据结构，我们肯定要分析它的常见操作，首先就是读写操作的原理。哈希表的访问一般都是通过下标或者遍历进行的： _ = hash[key] for k, v := range hash { // k, v } 这两种方式虽然都能读取哈希表的数据，但是使用的函数和底层原理完全不同。前者需要知道哈希的键并且一次只能获取单个键对应的值，而后者可以遍历哈希中的全部键值对，访问数据时也不需要预先知道哈希的键。在这里我们会介绍前一种访问方式，第二种访问方式会在range一节中详细分析。 数据结构的写一般指的都是增加、删除和修改，增加和修改字段都使用索引和赋值语句，而删除字典中的数据需要使用关键字delete： hash[key] = value hash[key] = newValue delete(hash, key) 除了这些操作之外，我们还会分析哈希的扩容过程，这能帮助我们深入理解哈希是如何存储数据的。 ","date":"2021-11-24","objectID":"/go-hash/:4:0","tags":["go"],"title":"Go Hash","uri":"/go-hash/"},{"categories":["学习"],"content":"访问 在编译的类型检查期间，hash[key]以及类似的操作都会被转换成哈希的OINDEXMAP操作，中间代码生成阶段会在cmd/compile/internal/gc.walkexpr函数中将这些OINDEXMAP操作转换成如下的代码： v := hash[key] // =\u003e v := *mapaccess1(maptype, hash, \u0026key) v, ok := hash[key] // =\u003e v, ok := mapaccess2(maptype, hash, \u0026key) 赋值语句左侧接受参数的个数会决定使用的运行时方法： 当接受一个参数时，会使用runtime.mapaccess1，该函数仅会返回一个指向目标值的指针； 当接受两个参数时，会使用runtime.mapaccess2，除了返回目标值之外，它还会返回一个用于表示当前键对应的值是否存在的 bool 值 runtime.mapaccess1会先通过哈希表设置的哈希函数、种子获取当前键对应的哈希，再通过runtime.bucketMask和runtime.add拿到该键值对所在的桶序号和哈希高位的 8 位数字。 func mapaccess1(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer { alg := t.key.alg hash := alg.hash(key, uintptr(h.hash0)) m := bucketMask(h.B) b := (*bmap)(add(h.buckets, (hash\u0026m)*uintptr(t.bucketsize))) top := tophash(hash) bucketloop: for ; b != nil; b = b.overflow(t) { for i := uintptr(0); i \u003c bucketCnt; i++ { if b.tophash[i] != top { if b.tophash[i] == emptyRest { break bucketloop } continue } k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) if alg.equal(key, k) { v := add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.valuesize)) return v } } } return unsafe.Pointer(\u0026zeroVal[0]) } 在bucketloop循环中，哈希会依次遍历正常桶和溢出桶中的数据，它会先比较哈希的高 8 位和桶中存储的tophash，后比较传入的和桶中的值以加速数据的读写。用于选择桶序号的是哈希的最低几位，而用于加速访问的是哈希的高 8 位，这种设计能够减少同一个桶中有大量相等tophash的概率影响性能。 访问哈希表中的数据\u0026ldquo;访问哈希表中的数据\u0026rdquo; \"\r访问哈希表中的数据\r 如上图所示，每一个桶都是一整片的内存空间，当发现桶中的tophash与传入键的tophash匹配之后，我们会通过指针和偏移量获取哈希中存储的键keys[0]并与key比较，如果两者相同就会获取目标值的指针values[0]并返回。 另一个同样用于访问哈希表中数据的runtime.mapaccess2只是在runtime.mapaccess1的基础上多返回了一个标识键值对是否存在的bool值： func mapaccess2(t *maptype, h *hmap, key unsafe.Pointer) (unsafe.Pointer, bool) { ... bucketloop: for ; b != nil; b = b.overflow(t) { for i := uintptr(0); i \u003c bucketCnt; i++ { if b.tophash[i] != top { if b.tophash[i] == emptyRest { break bucketloop } continue } k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) if alg.equal(key, k) { v := add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.valuesize)) return v, true } } } return unsafe.Pointer(\u0026zeroVal[0]), false } 使用v, ok := hash[k]的形式访问哈希表中元素时，我们能够通过这个布尔值更准确地知道当v == nil时，v到底是哈希中存储的元素还是表示该键对应的元素不存在，所以在访问哈希时，更推荐使用这种方式判断元素是否存在。 上面的过程是在正常情况下，访问哈希表中元素时的表现，然而与数组一样，哈希表可能会在装载因子过高或者溢出桶过多时进行扩容，哈希表扩容并不是原子过程，在扩容的过程中保证哈希的访问是比较有意思的话题，我们在这里也省略了相关的代码，后面的小节会展开介绍。 ","date":"2021-11-24","objectID":"/go-hash/:4:1","tags":["go"],"title":"Go Hash","uri":"/go-hash/"},{"categories":["学习"],"content":"写入 当形如hash[k]的表达式出现在赋值符号左侧时，该表达式也会在编译期间转换成runtime.mapassign函数的调用，该函数与runtime.mapaccess1比较相似，我们将其分成几个部分依次分析，首先是函数会根据传入的键拿到对应的哈希和桶： func mapassign(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer { alg := t.key.alg hash := alg.hash(key, uintptr(h.hash0)) h.flags ^= hashWriting again: bucket := hash \u0026 bucketMask(h.B) b := (*bmap)(unsafe.Pointer(uintptr(h.buckets) + bucket*uintptr(t.bucketsize))) top := tophash(hash) 然后通过遍历比较桶中存储的tophash和键的哈希，如果找到了相同结果就会返回目标位置的地址。其中inserti表示目标元素的在桶中的索引，insertk和val分别表示键值对的地址，获得目标地址之后会通过算术计算寻址获得键值对k和val： var inserti *uint8 var insertk unsafe.Pointer var val unsafe.Pointer bucketloop: for { for i := uintptr(0); i \u003c bucketCnt; i++ { if b.tophash[i] != top { if isEmpty(b.tophash[i]) \u0026\u0026 inserti == nil { inserti = \u0026b.tophash[i] insertk = add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) val = add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.valuesize)) } if b.tophash[i] == emptyRest { break bucketloop } continue } k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) if !alg.equal(key, k) { continue } val = add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.valuesize)) goto done } ovf := b.overflow(t) if ovf == nil { break } b = ovf } 上述的for循环会依次遍历正常桶和溢出桶中存储的数据，整个过程会分别判断tophash是否相等、key是否相等，遍历结束后会从循环中跳出。 哈希遍历溢出桶\u0026ldquo;哈希遍历溢出桶\u0026rdquo; \"\r哈希遍历溢出桶\r 如果当前桶已经满了，哈希会调用runtime.hmap.newoverflow创建新桶或者使用runtime.hmap预先在noverflow中创建好的桶来保存数据，新创建的桶不仅会被追加到已有桶的末尾，还会增加哈希表的noverflow计数器。 if inserti == nil { newb := h.newoverflow(t, b) inserti = \u0026newb.tophash[0] insertk = add(unsafe.Pointer(newb), dataOffset) val = add(insertk, bucketCnt*uintptr(t.keysize)) } typedmemmove(t.key, insertk, key) *inserti = top h.count++ done: return val } 如果当前键值对在哈希中不存在，哈希会为新键值对规划存储的内存地址，通过runtime.typedmemmove将键移动到对应的内存空间中并返回键对应值的地址val。如果当前键值对在哈希中存在，那么就会直接返回目标区域的内存地址，哈希并不会在runtime.mapassign这个运行时函数中将值拷贝到桶中，该函数只会返回内存地址，真正的赋值操作是在编译期间插入的： 00018 (+5) CALL runtime.mapassign_fast64(SB) 00020 (5) MOVQ 24(SP), DI ;; DI = \u0026value 00026 (5) LEAQ go.string.\"88\"(SB), AX ;; AX = \u0026\"88\" 00027 (5) MOVQ AX, (DI) ;; *DI = AX runtime.mapassign_fast64与runtime.mapassign函数的逻辑差不多，我们需要关注的是后面的三行代码，其中24(SP)是该函数返回的值地址，我们通过LEAQ指令将字符串的地址存储到寄存器AX中，MOVQ指令将字符串\"88\"存储到了目标地址上完成了这次哈希的写入。 ","date":"2021-11-24","objectID":"/go-hash/:4:2","tags":["go"],"title":"Go Hash","uri":"/go-hash/"},{"categories":["学习"],"content":"扩容 前面在介绍哈希的写入过程时其实省略了扩容操作，随着哈希表中元素的逐渐增加，哈希的性能会逐渐恶化，所以我们需要更多的桶和更大的内存保证哈希的读写性能： func mapassign(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer { ... if !h.growing() \u0026\u0026 (overLoadFactor(h.count+1, h.B) || tooManyOverflowBuckets(h.noverflow, h.B)) { hashGrow(t, h) goto again } ... } runtime.mapassign函数会在以下两种情况发生时触发哈希的扩容： 装载因子已经超过 6.5； 哈希使用了太多溢出桶； 不过因为 Go 语言哈希的扩容不是一个原子的过程，所以runtime.mapassign还需要判断当前哈希是否已经处于扩容状态，避免二次扩容造成混乱。 根据触发的条件不同扩容的方式分成两种，如果这次扩容是溢出的桶太多导致的，那么这次扩容就是等量扩容sameSizeGrow，sameSizeGrow是一种特殊情况下发生的扩容，当我们持续向哈希中插入数据并将它们全部删除时，如果哈希表中的数据量没有超过阈值，就会不断积累溢出桶造成缓慢的内存泄漏。runtime: limit the number of map overflow buckets引入了sameSizeGrow通过复用已有的哈希扩容机制解决该问题，一旦哈希中出现了过多的溢出桶，它会创建新桶保存数据，垃圾回收会清理老的溢出桶并释放内存。 扩容的入口是runtime.hashGrow： func hashGrow(t *maptype, h *hmap) { bigger := uint8(1) if !overLoadFactor(h.count+1, h.B) { bigger = 0 h.flags |= sameSizeGrow } oldbuckets := h.buckets newbuckets, nextOverflow := makeBucketArray(t, h.B+bigger, nil) h.B += bigger h.flags = flags h.oldbuckets = oldbuckets h.buckets = newbuckets h.nevacuate = 0 h.noverflow = 0 h.extra.oldoverflow = h.extra.overflow h.extra.overflow = nil h.extra.nextOverflow = nextOverflow } 哈希在扩容的过程中会通过runtime.makeBucketArray创建一组新桶和预创建的溢出桶，随后将原有的桶数组设置到oldbuckets上并将新的空桶设置到buckets上，溢出桶也使用了相同的逻辑更新，下图展示了触发扩容后的哈希： 哈希表触发扩容\u0026ldquo;哈希表触发扩容\u0026rdquo; \"\r哈希表触发扩容\r 我们在runtime.hashGrow中还看不出来等量扩容和翻倍扩容的太多区别，等量扩容创建的新桶数量只是和旧桶一样，该函数中只是创建了新的桶，并没有对数据进行拷贝和转移。哈希表的数据迁移的过程在是runtime.evacuate中完成的，它会对传入桶中的元素进行再分配。 func evacuate(t *maptype, h *hmap, oldbucket uintptr) { b := (*bmap)(add(h.oldbuckets, oldbucket*uintptr(t.bucketsize))) newbit := h.noldbuckets() if !evacuated(b) { var xy [2]evacDst x := \u0026xy[0] x.b = (*bmap)(add(h.buckets, oldbucket*uintptr(t.bucketsize))) x.k = add(unsafe.Pointer(x.b), dataOffset) x.v = add(x.k, bucketCnt*uintptr(t.keysize)) y := \u0026xy[1] y.b = (*bmap)(add(h.buckets, (oldbucket+newbit)*uintptr(t.bucketsize))) y.k = add(unsafe.Pointer(y.b), dataOffset) y.v = add(y.k, bucketCnt*uintptr(t.keysize)) } } runtime.evacuate会将一个旧桶中的数据分流到两个新桶，所以它会创建两个用于保存分配上下文的runtime.evacDst结构体，这两个结构体分别指向了一个新桶： 哈希表扩容目的\u0026ldquo;哈希表扩容目的\u0026rdquo; \"\r哈希表扩容目的\r 如果这是等量扩容，那么旧桶与新桶之间是一对一的关系，所以两个runtime.evacDst只会初始化一个。而当哈希表的容量翻倍时，每个旧桶的元素会都分流到新创建的两个桶中，这里仔细分析一下分流元素的逻辑： for ; b != nil; b = b.overflow(t) { k := add(unsafe.Pointer(b), dataOffset) v := add(k, bucketCnt*uintptr(t.keysize)) for i := 0; i \u003c bucketCnt; i, k, v = i+1, add(k, uintptr(t.keysize)), add(v, uintptr(t.valuesize)) { top := b.tophash[i] k2 := k var useY uint8 hash := t.key.alg.hash(k2, uintptr(h.hash0)) if hash\u0026newbit != 0 { useY = 1 } b.tophash[i] = evacuatedX + useY dst := \u0026xy[useY] if dst.i == bucketCnt { dst.b = h.newoverflow(t, dst.b) dst.i = 0 dst.k = add(unsafe.Pointer(dst.b), dataOffset) dst.v = add(dst.k, bucketCnt*uintptr(t.keysize)) } dst.b.tophash[dst.i\u0026(bucketCnt-1)] = top typedmemmove(t.key, dst.k, k) typedmemmove(t.elem, dst.v, v) dst.i++ dst.k = add(dst.k, uintptr(t.keysize)) dst.v = add(dst.v, uintptr(t.valuesize)) } } 只使用哈希函数是不能定位到具体某一个桶的，哈希函数只会返回很长的哈希，例如：b72bfae3f3285244c4732ce457cca823bc189e0b，我们还需一些方法将哈希映射到具体的桶上。我们一般都会使用取模或者位操作来获取桶的编号，假如当前哈希中包含 4 个桶，那么它的桶掩码就是 0b11(3)，使用位操作就会得到 3， 我们就会在 3 号桶中存储该数据： 0xb72bfae3f3285244c4732ce457cca823bc189e0b \u0026 0b11 #=\u003e 0 如果新的哈希表有 8 个桶，在大多数情况下，原来经过桶掩码 0b11 结果为 3 的数据会因为桶掩码增加了一位变成 0b111 而分流到新的 3 号和 7 号桶，所有数据也都会被runtime.typedmemmove拷贝到目标桶中： 哈希表桶数据的分流\u0026ldquo;哈希表桶数据的分流\u0026rdquo; \"\r哈希表桶数据的分流\r runtime.evacuate最后会调用runtime.advanceEvacuationMark增加哈希的nevacuate计数器并在所有的旧桶都被分流后清空哈希的oldbuckets和oldoverflow： func advanceEvacuationMark(h *hmap, t *maptype, newbit uintptr) { h.nevacuate++ stop := h.nevacuate + 1024 if stop \u003e newbit { stop = newbit } for h.nevacuate != stop \u0026\u0026 bucketEvacuated(t, h, h.nevacuate) { h.nevacuate++ } if h.nevacuate == newbit { // newbit == # of oldbuckets h.oldbuckets = nil if h.extra != nil { h.extra.oldoverflow = nil } h.flags \u0026^= sameSizeGrow } } 之前在分析哈希表访问函数runtime.mapaccess1时其实省略了扩容期间获取键值对的逻辑，当哈希表的oldbuckets存在时，会先定位到旧桶并在该桶没有被分流时从中获取键值对。 func mapaccess1(t *maptype, h *hmap, key unsafe.Pointer) unsafe","date":"2021-11-24","objectID":"/go-hash/:4:3","tags":["go"],"title":"Go Hash","uri":"/go-hash/"},{"categories":["学习"],"content":"删除 如果想要删除哈希中的元素，就需要使用 Go 语言中的 delete 关键字，这个关键字的唯一作用就是将某一个键对应的元素从哈希表中删除，无论是该键对应的值是否存在，这个内建的函数都不会返回任何的结果。 哈希表删除操作\u0026ldquo;哈希表删除操作\u0026rdquo; \"\r哈希表删除操作\r 在编译期间，delete关键字会被转换成操作为ODELETE的节点，而cmd/compile/internal/gc.walkexpr会将ODELETE节点转换成runtime.mapdelete函数簇中的一个，包括runtime.mapdelete、mapdelete_faststr、mapdelete_fast32和mapdelete_fast64： func walkexpr(n *Node, init *Nodes) *Node { switch n.Op { case ODELETE: init.AppendNodes(\u0026n.Ninit) map_ := n.List.First() key := n.List.Second() map_ = walkexpr(map_, init) key = walkexpr(key, init) t := map_.Type fast := mapfast(t) if fast == mapslow { key = nod(OADDR, key, nil) } n = mkcall1(mapfndel(mapdelete[fast], t), nil, init, typename(t), map_, key) } } 这些函数的实现其实差不多，我们挑选其中的runtime.mapdelete分析一下。哈希表的删除逻辑与写入逻辑很相似，只是触发哈希的删除需要使用关键字，如果在删除期间遇到了哈希表的扩容，就会分流桶中的元素，分流结束之后会找到桶中的目标元素完成键值对的删除工作。 func mapdelete(t *maptype, h *hmap, key unsafe.Pointer) { ... if h.growing() { growWork(t, h, bucket) } ... search: for ; b != nil; b = b.overflow(t) { for i := uintptr(0); i \u003c bucketCnt; i++ { if b.tophash[i] != top { if b.tophash[i] == emptyRest { break search } continue } k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) k2 := k if !alg.equal(key, k2) { continue } *(*unsafe.Pointer)(k) = nil v := add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.valuesize)) *(*unsafe.Pointer)(v) = nil b.tophash[i] = emptyOne ... } } } 我们其实只需要知道delete关键字在编译期间经过类型检查和中间代码生成阶段被转换成runtime.mapdelete函数簇中的一员，用于处理删除逻辑的函数与哈希表的runtime.mapassign几乎完全相同，不太需要刻意关注。 ","date":"2021-11-24","objectID":"/go-hash/:4:4","tags":["go"],"title":"Go Hash","uri":"/go-hash/"},{"categories":["学习"],"content":"小结 Go 语言使用拉链法来解决哈希碰撞的问题实现了哈希表，它的访问、写入和删除等操作都在编译期间转换成了运行时的函数或者方法。哈希在每一个桶中存储键对应哈希的前 8 位，当对哈希进行操作时，这些tophash就成为可以帮助哈希快速遍历桶中元素的缓存。 哈希表的每个桶都只能存储 8 个键值对，一旦当前哈希的某个桶超出 8 个，新的键值对就会存储到哈希的溢出桶中。随着键值对数量的增加，溢出桶的数量和哈希的装载因子也会逐渐升高，超过一定范围就会触发扩容，扩容会将桶的数量翻倍，元素再分配的过程也是在调用写操作时增量进行的，不会造成性能的瞬时巨大抖动。 ","date":"2021-11-24","objectID":"/go-hash/:5:0","tags":["go"],"title":"Go Hash","uri":"/go-hash/"},{"categories":["学习"],"content":"Go语言切片实现原理","date":"2021-11-21","objectID":"/go-slice/","tags":["go"],"title":"Go Slice","uri":"/go-slice/"},{"categories":["学习"],"content":"数组在Go语言中没那么常用，更常用的数据结构是切片，即动态数组，其长度并不固定，我们可以向切片中追加元素，它会在容量不足时自动扩容。 在Go语言中，切片类型的声明方式和数组有一些相似，不过由于切片的长度是动态的，所以声明时只需要指定切片中的元素类型 []int []interface{} 从切片的定义我们能推测出，切片在编译期间生成的类型会包含切片中的元素类型，即int或者interface()等。cmd/compile/internal/type.NewSlice就是编译期间用于创建切片类型的函数 func NewSlice(elem *Type) *Type { if t := elem.Cache.slice; t != nil { if t.Elem() != elem { Fatalf(\"elem mismatch\") } return t } t := New(TSLICE) t.Extra = Slice{ Elem: elem, } elem.Cache.slice = t return t } 上述方法返回结构体重的Extra字段是一个只包含切片内元素类型的结构，也就是说切片内元素的类型都是在编译期间确定的，编译器确定了类型之后，会将类型存储在Extra字段中帮助程序在运行时动态获取。 ","date":"2021-11-21","objectID":"/go-slice/:0:0","tags":["go"],"title":"Go Slice","uri":"/go-slice/"},{"categories":["学习"],"content":"数据结构 编译期间的切片是cmd/compile/internal/type.Slice类型的，但是在运行时切片可以由如下reflect.SliceHeader结构体表示，其中 Data 是指向数组的指针 Len 是当前切片的长度 Cap 是当前切片的容量，即Data数组的大小 type SliceHeader struct { Data uintptr Len int Cap int } Data是一片连续的内存空间，这片内存空间可以用于存储切片中的全部元素，数组中的元素只是逻辑上的概念，底层存储其实都是连续的，所以我们可以将切片理解成一片连续的内存空间加上长度和容量的标识 Go语言切片结构体\u0026ldquo;Go语言切片结构体\u0026rdquo; \"\rGo语言切片结构体\r 从上图中，我们会发现切片和数组的关系非常密切，切片引入了一个抽象层，提供了对数组中部分连续片段的引用，而作为数组的引用，我们可以在运行区间修改它的长度和范围。当切片底层的数组长度不足时就会触发扩容，切片指向的数组可能会发生变化，不过在上层看来切片是没有变化的，上层只需要与切片打交道不需要关心数组的变化 编译器在编译期间简化了获取数组大小、读写数组中的元素等操作：因为数组的内存固定且连续，多数操作都会直接读写内存的特定位置。但是切片是运行时才会确定内容的结构，所有操作还需要依赖Go语言的运行时。 ","date":"2021-11-21","objectID":"/go-slice/:1:0","tags":["go"],"title":"Go Slice","uri":"/go-slice/"},{"categories":["学习"],"content":"初始化 Go语言包含三种初始化切片的方式 通过下标的方式获得数组或者切片的一部分 使用字面量初始化新的切片 使用关键字make创建切片 arr[0:3] or slice[0:3] slice := []int{1, 2, 3} slice := make([]int, 10) 使用下标 使用下标创建切片是最原始也最接近汇编语言的方式，它是所有方法中最为底层的一种，编译器会将arr[0:3]或者slice[0:3]等语句转换成OpSliceMake操作，可以通过下面代码来验证 package opslicemake func newSlice() []int { arr := [3]int{1, 2, 3} slice := arr[0:1] return slice } 通过GOSSAFUNC变量编译上述代码可以得到一系列SSA中间代码，其中slice := arr[0:1]语句在\"decompose builtin\"阶段对应的代码如下所示 v27 (+5) = SliceMake \u003c[]int\u003e v11 v14 v17 name \u0026arr[*[3]int]: v11 name slice.ptr[*int]: v11 name slice.len[int]: v14 name slice.cap[int]: v17 SliceMake操作会接受四个参数创建新的切片，元素类型、数组指针、切片大小和容量，这也是我们在数据结构一节中提到的切片的几个字段，需要注意的是使用下标初始化切片不会拷贝原数组或者切片中的数据，它只会创建一个指向原数组的切片结构体，所以修改新切片的数据也会修改原切片 字面量 当使用字面量[]int{1, 2, 3}创建新的切片时，cmd/compile/internal/gc.slicelit函数会在编译期间将它展开成如下所示的代码片段 var vstat [3]int vstat[0] = 1 vstat[1] = 2 vstat[2] = 3 var vauto *[3]int = new([3]int) *vauto = vstat slice := vauto[:] 根绝切片中的元素数量对底层数据的大小进行推断并创建一个数组 将这些字面量元素存储到初始化的数组中 创建一个同样指向[3]int类型的数组指针 将静态存储区的数组vstat赋值给vauto指针所在的地址 通过[:]操作获取一个底层使用vauto的切片 第五步中的[:]就是使用下标创建切片的方法，从这一点我们也能看出[:]操作切片最底层的一种方法 关键字 如果使用字面量的方式创建切片，大部分工作都会在编译期间完成。但是当我们使用make关键字创建切片时，很多工作都需要运行时参与；调用方必须向make函数传入切片的大小以及可选的容量，类型检查期间的cmd/compile/internal/gc.typecheck1函数会校验入参 func typecheck1(n *Node, top int) (res *Node) { switch n.Op { ... case OMAKE: args := n.List.Slice() i := 1 switch t.Etype { case TSLICE: if i \u003e= len(args) { yyerror(\"missing len argument to make(%v)\", t) return n } l = args[i] i++ var r *Node if i \u003c len(args) { r = args[i] } ... if Isconst(l, CTINT) \u0026\u0026 r != nil \u0026\u0026 Isconst(r, CTINT) \u0026\u0026 l.Val().U.(*Mpint).Cmp(r.Val().U.(*Mpint)) \u003e 0 { yyerror(\"len larger than cap in make(%v)\", t) return n } n.Left = l n.Right = r n.Op = OMAKESLICE } ... } } 上面的函数不仅会检查len是否传入，还会保证传入的容量cap一定大于或者等于len。除了校验参数之外，当前函数会将OMAKE节点转换成OMAKESLICE，中间代码生成的cmd/compile/internal/gc.walkexpr函数会依据下面两个条件转换OMAKESLICE类型的节点： 切片的大小和容量是否足够小 切片是否发生了逃逸，最终在堆上初始化 当切片发生逃逸或者非常大时，运行时需要runtime.makeslice在堆上初始化切片，如果当前的切片不会发生逃逸并且切片非常小的时候，make([]int, 3, 4)会被直接转换成如下所示的代码： var arr [4]int n := arr[:3] 上述代码会初始化数组并通过下标[:3]得到数组对应的切片，这两部分都会在编译阶段完成，编译器会在栈上或者静态存储区创建数组并将[:3]转换成上一节提到的OpSliceMake操作 分析了主要由编译器处理的分支后，我们回到用于创建切片时的运行时函数runtime.makeslice，这个函数的实现很简单： func makeslice(et *_type, len, cap int) unsafe.Pointer { mem, overflow := math.MulUintptr(et.size, uintptr(cap)) if overflow || mem \u003e maxAlloc || len \u003c 0 || len \u003e cap { mem, overflow := math.MulUintptr(et.size, uintptr(len)) if overflow || mem \u003e maxAlloc || len \u003c 0 { panicmakeslicelen() } panicmakeslicecap() } return mallocgc(mem, et, true) } 上述函数的主要工作是计算切片占用的内存空间并在堆上申请一片连续的内存，它使用如下的方式计算占用的内存 内存空间=切片中元素大小×切片容量 虽然编译期间可以检查出很多错误，但是在创建切片的过程中如果发生了以下错误会直接出发运行时错误并崩溃： 内存空间的大小发生了溢出 申请的内存大于最大可支配的内存 传入的长度小于0或者长度大于容量 runtime.makeslice在最后调用的runtime.mallocgc是用于申请内存的函数，这个函数的实现还是比较复杂的，如果遇到了比较小的对象会直接初始化在Go语言调度器里面的P结构中，而大于32KB的对象会在堆上初始化。 在之前版本的Go语言中，数组指针、长度和容量会被合成一个runtime.slice结构，但是从cmd/compile:move slice construction to callers of makeslice提交之后，构建结构体reflect.SliceHeader的工作就交给了runtime.makeslice的调用方，该函数仅会返回指向底层数组的指针，调用方会在编译期间构建切片结构体： func typecheck1(n *Node, top int) (res *Node) { switch n.Op { ... case OSLICEHEADER: switch t := n.Type n.Left = typecheck(n.Left, ctxExpr) l := typecheck(n.List.First(), ctxExpr) c := typecheck(n.List.Second(), ctxExpr) l = defaultlit(l, types.Types[TINT]) c = defaultlit(c, types.Types[TINT]) n.List.SetFirst(l) n.List.SetSecond(c) ... } } OSLICEHEADER操作会创建reflect.SliceHeader结构体，其中包含切片的长度和容量，它是切片在运行时的表示： type SliceHeader struct { Data uintptr Len int Cap int } 正是因为大多数对切片类型的操作并不需要直接操作原来的runtime.slice结构体，所以reflect.SliceHeader的引入能够减少切片初始化时的少量开销，该改动不仅能够减少~0.2%的Go语言包大小，还能够减少92个runtime.panicIndex的调用，占Go语言二进制的~3.5% ","date":"2021-11-21","objectID":"/go-slice/:2:0","tags":["go"],"title":"Go Slice","uri":"/go-slice/"},{"categories":["学习"],"content":"访问元素 使用len和cap获取长度或者容量是切片最常见的操作，编译器将它们看成两种特殊操作，即OLEN和OCAP，cmd/compile/internal/gc.state.expr函数会在SSA生成阶段将它们分别转换成OpSliceLen和OpSliceCap func (s *state) expr(n *Node) *ssa.Value { switch n.Op { case OLEN, OCAP: switch { case n.Left.Type.IsSlice(): op := ssa.OpSliceLen if n.Op == OCAP { op = ssa.OpSliceCap } return s.newValue1(op, types.Types[TINT], s.expr(n.Left)) ... } ... } } 访问切片中的字段可能会触发\"decompose builtin\"阶段的优化，len(slice)或者cap(slice)在一些情况下会直接替换成切片的长度或者容量，不需要在运行时获取 (SlicePtr (SliceMake ptr _ _ )) -\u003e ptr (SliceLen (SliceMake _ len _)) -\u003e len (SliceCap (SliceMake _ _ cap)) -\u003e cap 除了直接获取切片的长度和容量之外，访问切片中元素使用OINDEX操作也会在中间代码生成期间转换成对地址的直接访问 func (s *state) expr(n *Node) *ssa.Value { switch n.Op { case OINDEX: switch { case n.Left.Type.IsSlice(): p := s.addr(n, false) return s.load(n.Left.Type.Elem(), p) ... } ... } } 切片的操作基本都是在编译期间完成的，除了访问切片的长度、容量或者其中的元素之外，编译期间也会将包含range关键字的遍历转换成形式更简单的循环 ","date":"2021-11-21","objectID":"/go-slice/:3:0","tags":["go"],"title":"Go Slice","uri":"/go-slice/"},{"categories":["学习"],"content":"追加和扩容 使用append关键字向切片中追加元素也是常见的切片操作，中间代码生成阶段的cmd/compile/internal/gc.state.append方法会根据返回值是否会覆盖原变量，选择进入两种流程，如果append返回的新切片不需要赋值回原有的变量，就会进入如下的处理流程： // append(slice, 1, 2, 3) ptr, len, cap := slice newlen := len + 3 if newlen \u003e cap { ptr, len, cap = growslice(slice, newlen) newlen = len + 3 } *(ptr+len) = 1 *(ptr+len+1) = 2 *(ptr+len+2) = 3 return makeslice(ptr, newlen, cap) 我们会先解构切片结构体获取它的数组指针、大小和容量，如果在追加元素后切片的大小大于容量，那么就会调用runtime.growslice对切片进行扩容并将新的元素依次加入切片。 如果使用slice = append(slice, 1, 2, 3)语句，那么 append 后的切片会覆盖原切片，这时cmd/compile/internal/gc.state.append方法会使用另一种方式展开关键字： // slice = append(slice, 1, 2, 3) a := \u0026slice ptr, len, cap := slice newlen := len + 3 if uint(newlen) \u003e uint(cap) { newptr, len, newcap = growslice(slice, newlen) vardef(a) *a.cap = newcap *a.ptr = newptr } newlen = len + 3 *a.len = newlen *(ptr+len) = 1 *(ptr+len+1) = 2 *(ptr+len+2) = 3 是否覆盖原变量的逻辑其实差不多，最大的区别在于得到的新切片是否会赋值回原变量。如果我们选择覆盖原有的变量，就不需要担心切片发生拷贝影响性能，因为Go语言编译器已经对这种常见的情况做出了优化。 Go语言的切片追加元素\u0026ldquo;Go语言的切片追加元素\u0026rdquo; \"\rGo语言的切片追加元素\r 到这里我们已经清楚了Go语言如何在切片容量足够时向切片中追加元素，不过仍然需要研究切片容量不足时的处理流程。当切片的容量不足时，我们会调用runtime.growslice函数为切片扩容，扩容是为切片分配新的内存空间并拷贝原切片中元素的过程，我们先来看新切片的容量是如何确定的： func growslice(et *_type, old slice, cap int) slice { newcap := old.cap doublecap := newcap + newcap if cap \u003e doublecap { newcap = cap } else { if old.len \u003c 1024 { newcap = doublecap } else { for 0 \u003c newcap \u0026\u0026 newcap \u003c cap { newcap += newcap / 4 } if newcap \u003c= 0 { newcap = cap } } } } 在分配内存空间之前需要先确定新的切片容量，运行时根据切片的当前容量选择不同的策略进行扩容： 如果期望容量大于当前容量的两倍就会使用期望容量； 如果当前切片的长度小于 1024 就会将容量翻倍； 如果当前切片的长度大于 1024 就会每次增加 25% 的容量，直到新容量大于期望容量； 上述代码片段仅会确定切片的大致容量，下面还需要根据切片中的元素大小对齐内存，当数组中元素所占的字节大小为 1、8 或者 2 的倍数时，运行时会使用如下所示的代码对齐内存： var overflow bool var lenmem, newlenmem, capmem uintptr switch { case et.size == 1: lenmem = uintptr(old.len) newlenmem = uintptr(cap) capmem = roundupsize(uintptr(newcap)) overflow = uintptr(newcap) \u003e maxAlloc newcap = int(capmem) case et.size == sys.PtrSize: lenmem = uintptr(old.len) * sys.PtrSize newlenmem = uintptr(cap) * sys.PtrSize capmem = roundupsize(uintptr(newcap) * sys.PtrSize) overflow = uintptr(newcap) \u003e maxAlloc/sys.PtrSize newcap = int(capmem / sys.PtrSize) case isPowerOfTwo(et.size): ... default: ... } runtime.roundupsize函数会将待申请的内存向上取整，取整时会使用runtime.class_to_size数组，使用该数组中的整数可以提高内存的分配效率并减少碎片，我们会在内存分配一节详细介绍该数组的作用： var class_to_size = [_NumSizeClasses]uint16{ 0, 8, 16, 32, 48, 64, 80, ..., } 在默认情况下，我们会将目标容量和元素大小相乘得到占用的内存。如果计算新容量时发生了内存溢出或者请求内存超过上限，就会直接崩溃退出程序，不过这里为了减少理解的成本，将相关的代码省略了。 var overflow bool var newlenmem, capmem uintptr switch { ... default: lenmem = uintptr(old.len) * et.size newlenmem = uintptr(cap) * et.size capmem, _ = math.MulUintptr(et.size, uintptr(newcap)) capmem = roundupsize(capmem) newcap = int(capmem / et.size) } ... var p unsafe.Pointer if et.kind\u0026kindNoPointers != 0 { p = mallocgc(capmem, nil, false) memclrNoHeapPointers(add(p, newlenmem), capmem-newlenmem) } else { p = mallocgc(capmem, et, true) if writeBarrier.enabled { bulkBarrierPreWriteSrcOnly(uintptr(p), uintptr(old.array), lenmem) } } memmove(p, old.array, lenmem) return slice{p, old.len, newcap} 如果切片中的元素不是指针类型，那么会调用runtime.memclrNoHeapPointers将超出切片当前长度的位置清空并在最后使用runtime.memmove将原数组内存中的内容拷贝到新申请的内存中。 runtime.growslice函数最终会返回一个新的切片，其中包含了新的数组指针、大小和容量，这个返回的三元组最终会覆盖原切片 var arr []int64 arr = append(arr, 1, 2, 3, 4, 5) 简单总结一下扩容的过程，当我们执行上述代码时，会触发runtime.growslice函数扩容arr切片并传入期望的新容量5，这时期望分配的内存大小为40字节；不过因为切片中的元素大小等于sys.PtrSize，所以运行时会调用runtime.roundupsize向上取整内存的大小到48字节，所以心切片的容量为48/8=6。 ","date":"2021-11-21","objectID":"/go-slice/:4:0","tags":["go"],"title":"Go Slice","uri":"/go-slice/"},{"categories":["学习"],"content":"拷贝切片 切片的拷贝虽然不是常见的操作，但是确实我们学习切片实现原理必须要涉及的。当我们使用copy(a, b)的形式对切片进行拷贝时，编译期间的cmd/compile/internal/gc.copyany也会分两种情况进行处理拷贝操作，如果当前copy不是在运行时调用的，copy(a, b)会被直接转换成下面的代码： n := len(a) if n \u003e len(b) { n = len(b) } if a.ptr != b.ptr { memmove(a.ptr, b.ptr, n*sizeof(elem(a))) } 上述代码中的runtime.memmove会负责拷贝内存。而如果拷贝是在运行时发生的，例如go copy(a, b)，编译器会使用runtime.slicecopy替换运行期间调用的copy，该函数的实现很简单： func slicecopy(to, fm slice, width uintptr) int { if fm.len == 0 || to.len == 0 { return 0 } n := fm.len if to.len \u003c n { n = to.len } if width == 0 { return n } ... size := uintptr(n) * width if size == 1 { *(*byte)(to.array) = *(*byte)(fm.array) } else { memmove(to.array, fm.array, size) } return n } 无论是编译期间拷贝还是运行时拷贝，两种拷贝方式都会通过runtime.memmove将整块内存的内容拷贝到目标的内存区域中： Go语言切片的拷贝\u0026ldquo;Go语言切片的拷贝\u0026rdquo; \"\rGo语言切片的拷贝\r 相比于依次拷贝元素，runtime.memmove能够提供更好的性能。需要注意的是，整块拷贝内存仍然会占用非常多的资源，在大切片上执行拷贝操作时一定要注意对性能的影响 ","date":"2021-11-21","objectID":"/go-slice/:5:0","tags":["go"],"title":"Go Slice","uri":"/go-slice/"},{"categories":["学习"],"content":"小结 切片的很多功能都是由运行时实现的，无论是初始化切片，还是对切片进行追加或扩容都需要运行时的支持，需要注意的是在遇到大切片扩容或者复制时可能会发生大规模的内存拷贝，一定要减少类似操作避免影响程序的性能 ","date":"2021-11-21","objectID":"/go-slice/:6:0","tags":["go"],"title":"Go Slice","uri":"/go-slice/"},{"categories":["学习"],"content":"Go语言数组实现原理","date":"2021-11-15","objectID":"/go-array/","tags":["go"],"title":"Go语言数组实现原理","uri":"/go-array/"},{"categories":["学习"],"content":"概述 数组是由相同类型元素的集合组成的数据结构，计算机会为数组分配一块连续的内存来保存其中的元素，我们可以利用数组中的索引快速访问特定元素，常见的数组都是一堆的线性数组，而多维数组在数值和图形计算领域却有比较常见的应用 多维数组\u0026ldquo;多维数组\u0026rdquo; \"\r多维数组\r 数组作为一种基本的数据类型，通常会从两个维度描述数组，也就是数组中存储的元素类型和数组最大能存储的元素个数，在Go语言中往往会使用如下所示的方式来表示数组类型 [10]int [200]interface{} Go语言数组在初始化之后大小就无法改变，存储元素类型相同、但是大小不同的数组类型在Go语言看来也是完全不同的，只有两个条件都相同才是同一类型 func NewArray(elem *Type, bound int64) *Type { if bound \u003c 0 { Fatalf(\"NewArray: invalid bound %v\", bound) } t := New(TARRAY) t.Extra = \u0026Array{Elem: elem, Bound: bound} t.SetNotInHeap(elem.NotInHeap()) return t } 编译期间的数组类型是由上述的cmd/compile/internal/types.NewArray函数生成的，该类型包含两个字段，分别是元素类型Elem和数组的大小Bound，这两个字段共同构成了数组类型，而当前数组是否应该在堆栈中初始化也在编译期就确定了。 ","date":"2021-11-15","objectID":"/go-array/:1:0","tags":["go"],"title":"Go语言数组实现原理","uri":"/go-array/"},{"categories":["学习"],"content":"初始化 Go语言的数组有两种不同的创建方式，一种是显式的指定数组大小，另一种是使用[...]T声明数组，Go语言会在编译期间通过源代码推导数组的大小： arr1 := [3]int{1, 2, 3} arr2 := [...]int{1, 2, 3} 上述两种声明方式在运行期间得到的结果是完全相同的，后一种声明方式在编译期间就会被转换成前一种，这也就是编译器对数组大小的推导，下面介绍编译器的推导过程 上限推导 两种不同的声明方式会导致编译器做出完全不同的处理，如果使用第一种方式[10]T，那么变量的类型在编译进行到类型检查阶段就会被提取出来，随后使用cmd/compile/internal/types.NewArray创建包含数组大小的cmd/compile/internal/types.Array结构体 当我们使用[...]T的方式声明数组时，编译器会在cmd/compile/internal/gc.typecheckcomplit函数中对该数组的大小进行推导： func typecheckcomplit(n *Node) (res *Node) { ... if n.Right.Op == OTARRAY \u0026\u0026 n.Right.Left != nil \u0026\u0026 n.Right.Left.Op == ODDD { n.Right.Right = typecheck(n.Right.Right, ctxType) if n.Right.Right.Type == nil { n.Type = nil return n } elemType := n.Right.Right.Type length := typecheckarraylit(elemType, -1, n.List.Slice(), \"array literal\") n.Op = OARRAYLIT n.Type = types.NewArray(elemType, length) n.Right = nil return n } ... switch t.Etype { case TARRAY: typecheckarraylit(t.Elem(), t.NumElem(), n.List.Slice(), \"array literal\") n.Op = OARRAYLIT n.Right = nil } } 这个删减后的cmd/compile/internal/gc.typecheckcomplit会调用cmd/compile/internal/gc.typecheckarraylist通过遍历元素的方式来计算数组中的元素的数量 所以可以看出[...]T{1, 2, 3}和[3]T{1, 2, 3}在运行时是完全等价的，[...]T这种初始化方式也只是Go语言为我们提供的一种语法糖，当不想计算数组中的元素个数时可以通过这种方法减少一些工作量。 语句转换 对于一个有字面量组成的数组，根据数组元素数量的不同，编译器会在负责初始化字面量的cmd/compile/internal/gc.anylit函数中做两种不同的优化： 当元素数量小于或者等于四个时，会直接将数组中的元素置在栈上 当元素数量大于四个时，会将数组中的元素放置到静置区并在运行时取出 func anylit(n *Node, var_ *Node, init *Nodes) { t := n.Type switch n.Op { case OSTRUCTLIT, OARRAYLIT: if n.List.Len() \u003e 4 { ... } fixedlit(inInitFunction, initKindLocalCode, n, var_, init) ... } } 当数组元素小于或者等于四个时，cmd/compile/internal/gc.fixedlit会负责在函数编译之前将[3]{1,2,3}转换成更加原始的语句 func fixedlit(ctxt initContext, kind initKind, n *Node, var_ *Node, init *Nodes) { var splitnode func(*Node) (a *Node, value *Node) ... for _, r := range n.List.Slice() { a, value := splitnode(r) a = nod(OAS, a, value) a = typecheck(a, ctxStmt) switch kind { case initKindStatic: genAsStatic(a) case initKindLocalCode: a = orderStmtInPlace(a, map[string][]*Node{}) a = walkstmt(a) init.Append(a) } } } 当数组中元素的个数小于或者等于四个并且cmd/compile/internal/gc.fixedlit函数接收的kind是initKindLocalCode时，上述代码会将原有的初始化语句[3]int{1, 2, 3}拆分成一个声明变量的表达式和几个赋值表达式，这些表达式会完成对数组的初始化： var arr [3]int arr[0] = 1 arr[1] = 2 arr[2] = 3 但是如果当前数组的元素大于四个，cmd/compile/internal/gc.anylit会先获取一个唯一的staticname，然后调用cmd/compile/internal/gc.fixedlit函数在静态存储区初始化数组中的元素并将临时变量赋值给数组 func anylit(n *Node, var_ *Node, init *Nodes) { t := n.Type switch n.Op { case OSTRUCTLIT, OARRAYLIT: if n.List.Len() \u003e 4 { vstat := staticname(t) vstat.Name.SetReadonly(true) fixedlit(inNonInitFunction, initKindStatic, n, vstat, init) a := nod(OAS, var_, vstat) a = typecheck(a, ctxStmt) a = walkexpr(a, init) init.Append(a) break } ... } } 假设代码需要初始化[5]int{1,2,3,4,5}，那么可以将上述过程理解成以下的伪代码 var arr [5]int statictmp_0[0] = 1 statictmp_0[1] = 2 statictmp_0[2] = 3 statictmp_0[3] = 4 statictmp_0[4] = 5 arr = statictmp_0 总结起来，在不考虑逃逸分析的情况下，如果数组中的元素小于或者等于四个，那么所有的变量会直接在栈上初始化，如果数组元素大于四个，变量就会在静态存储区初始化然后拷贝到栈上，这些转换后的代码才会继续进入中间代码生成和机器生成两个阶段，最后生成可以执行的二进制文件 ","date":"2021-11-15","objectID":"/go-array/:2:0","tags":["go"],"title":"Go语言数组实现原理","uri":"/go-array/"},{"categories":["学习"],"content":"访问和赋值 无论是在栈上还是静态存储区，数组在内存中都是一连串的内存空间，通过指向数组开头的指针、元素的数量以及元素类型占的空间大小表示数组。如果不知道数组中元素的数量，访问时可能会发生越界；而如果不知道数组中元素类型的大小，就没有办法知道应该一次取出多少字节的数据，无论丢失了哪个信息，都无法知道这片连续的内存空间到底存储了什么数据 数组的内存空间\u0026ldquo;数组的内存空间\u0026rdquo; \"\r数组的内存空间\r 数组访问越界是非常严重的错误，Go语言中可以在编译期间的静态类型检查判断数组越界，cmd/compile/internal/gc.typecheck1会验证访问数组的索引 func typecheck1(n *Node, top int) (res *Node) { switch n.Op { case OINDEX: ok |= ctxExpr l := n.Left // array r := n.Right // index switch n.Left.Type.Etype { case TSTRING, TARRAY, TSLICE: ... if n.Right.Type != nil \u0026\u0026 !n.Right.Type.IsInteger() { yyerror(\"non-integer array index %v\", n.Right) break } if !n.Bounded() \u0026\u0026 Isconst(n.Right, CTINT) { x := n.Right.Int64() if x \u003c 0 { yyerror(\"invalid array index %v (index must be non-negative)\", n.Right) } else if n.Left.Type.IsArray() \u0026\u0026 x \u003e= n.Left.Type.NumElem() { yyerror(\"invalid array index %v (out of bounds for %d-element array)\", n.Right, n.Left.Type.NumElem()) } } } ... } } 访问数组的索引是非整数时，报错\"non-integer array index %v\" 访问数组的索引是负数时，报错\"invalid array index %v(index must be non-negative)\" 访问数组的索引越界时，报错\"invalid array index %v(out of bounds for %d-element array)\" 数组和字符串的一些简单越界错误都会在编译期间发现，例如：直接使用整数或者常量访问数组；但是如果使用变量去访问数组或者字符串时，编译器就无法提前发现错误，我们需要Go语言运行时阻止不合法的访问 arr[4]: invalid array index 4 (out of bounds for 3-element array) arr[i]: panic: runtime error: index out of range [4] with length 3 Go语言运行时在发现数组、切片和字符串的越界操作会由运行时的runtime.panicIndex和runtime.goPanicIndex触发程序的运行时错误并导致崩溃退出 TEXT runtime·panicIndex(SB),NOSPLIT,$0-8 MOVL AX, x+0(FP) MOVL CX, y+4(FP) JMP runtime·goPanicIndex(SB) func goPanicIndex(x int, y int) { panicCheck1(getcallerpc(), \"index out of range\") panic(boundsError{x: int64(x), signed: true, y: y, code: boundsIndex}) } 当数组的访问操作OINDEX成功通过编译器的检查后，会被转换成几个SSA指令，假设有如下Go语言代码，通过如下的方式进行编译会得到ssa.html文件： package check func outOfRange() int { arr := [3]int{1, 2, 3} i := 4 elem := arr[i] return elem } $ GOSSAFUNC=outOfRange go build array.go dumped SSA to ./ssa.html start阶段生成的SSA代码就是优化之前的第一版中间代码，下面展示的部分是elem := arr[i]对应的中间代码，在这段中间代码中我们发现Go语言为数组的访问操作生成了判断数组上限的指令IsInBounds以及当条件不满足时触发程序崩溃的PanicBounds指令： b1: ... v22 (6) = LocalAddr \u003c*[3]int\u003e {arr} v2 v20 v23 (6) = IsInBounds \u003cbool\u003e v21 v11 If v23 → b2 b3 (likely) (6) b2: ← b1- v26 (6) = PtrIndex \u003c*int\u003e v22 v21 v27 (6) = Copy \u003cmem\u003e v20 v28 (6) = Load \u003cint\u003e v26 v27 (elem[int]) ... Ret v30 (+7) b3: ← b1- v24 (6) = Copy \u003cmem\u003e v20 v25 (6) = PanicBounds \u003cmem\u003e [0] v21 v11 v24 Exit v25 (6) 编译器会将PanicBounds指令转换成上面提到的runtime.panicIndex函数，当数组下标没有越界时，编译器会先获取数组的内存地址和访问的下标、利用PtrIndex计算出目标元素的地址，最后使用Load操作将指针中的元素加载到内存中。 当然只有当编译器无法对数组下标是否越界做出判断时才会加入PanicBounds指令交给运行时进行判断，在使用字面量整数访问数组下标时会生成非常简单的中间代码，当将上述代码中的arr[i]改成arr[2]时，就会得到如下所示的代码： b1: ... v21 (5) = LocalAddr \u003c*[3]int\u003e {arr} v2 v20 v22 (5) = PtrIndex \u003c*int\u003e v21 v14 v23 (5) = Load \u003cint\u003e v22 v20 (elem[int]) ... Go语言对于数组的访问还是有着比较多的检查，它不仅会在编译期间提前发现一些简单的越界错误并插入用于检测数组上限的函数调用，还会在运行期间通过插入的函数保证不会发生越界 数组的赋值和更新操作a[i]=2也会生成SSA，生成期间计算出数组当前元素的内存地址，然后修改当前内存地址的内容，这些赋值语句会被转换成如下所示的SSA代码 b1: ... v21 (5) = LocalAddr \u003c*[3]int\u003e {arr} v2 v19 v22 (5) = PtrIndex \u003c*int\u003e v21 v13 v23 (5) = Store \u003cmem\u003e {int} v22 v20 v19 ... 赋值的过程中会先确定目标数组的地址，再通过PtrIndex获取目标元素的地址，最后使用Store指令将数据存入地址中，从上面的这些SSA代码中可以看出上述数组寻址和赋值都是在编译阶段完成的，没有运行时的参与 ","date":"2021-11-15","objectID":"/go-array/:3:0","tags":["go"],"title":"Go语言数组实现原理","uri":"/go-array/"},{"categories":["学习"],"content":"小结 数组是Go语言中最重要的数据结构，了解它的实现能够帮助我们更好的理解这门语言，通过对其实现的分析，我们知道了对数组的访问和赋值需要同时依赖编译器和运行时，它的大多数操作在编译期间都会转换成直接读写内存，在中间代码生成期间，编译器还会插入运行时方法runtime.panicIndex调用防止发生越界错误 ","date":"2021-11-15","objectID":"/go-array/:4:0","tags":["go"],"title":"Go语言数组实现原理","uri":"/go-array/"},{"categories":["学习"],"content":"Go垃圾收集器","date":"2021-11-09","objectID":"/go-garbage-collector/","tags":["mysql"],"title":"Go垃圾收集器","uri":"/go-garbage-collector/"},{"categories":["学习"],"content":"设计原理 今天的编程语言通常会使用以手动和自动两种方式管理内存，C、C++以及Rust等编程语言使用手动方式管理内存，工程师需要主动申请或者释放内存；而Python、Ruby、Java和Go等语言使用自动的内存管理系统，一般都是垃圾回收机制，不过Objective-C却选择了自动引用计数，虽然引用计数也是自动的内存管理机制。 相信很多人对垃圾收集器的印象都是暂停程序(Stop the world, STW)，随着用户程序申请越来越多的内存，系统中的垃圾也逐渐增多；当程序中的内存达到一定阈值时，整个应用程序就会全部暂停，垃圾收集器会扫描已经分配的所有对象并回收不再使用的内存空间，当这个过程结束后，用户程序才可以继续执行，Go语言在早期也使用这种策略实现垃圾收集，但是今天的实现已经复杂了很多。 内存管理的组件\u0026ldquo;内存管理的组件\u0026rdquo; \"\r内存管理的组件\r 在上图中，用户程序(Mutator)会通过内存分配器(Allocator)在堆上申请内存，而垃圾收集器(Collector)负责回收堆上的内存空间，内存分配器和垃圾收集器共同管理着程序中的堆内存空间。 ","date":"2021-11-09","objectID":"/go-garbage-collector/:1:0","tags":["mysql"],"title":"Go垃圾收集器","uri":"/go-garbage-collector/"},{"categories":["学习"],"content":"标记清除 标记清除(Mark-Sweep)算法是最常见的垃圾收集算法，标记清除收集器是跟踪式垃圾收集器，其执行过程可以分成标记(Mark)和清除(Sweep)两个阶段 标记阶段(从根对象出发查找并标记堆中所有存活的对象) 清除阶段(遍历堆中的全部对象，回收未被标记的垃圾对象并将回收的内存加入空闲链表) 如下图所示，内存空间中包含多个对象，我们从根对象出发依次遍历对象的子对象并将从根节点可达的对象都标记为存活状态，即A、C和D三个对象，剩余B、E和F三个对象因为从根节点不可达，所以会被当成垃圾。 标记清除的标记阶段\u0026ldquo;标记清除的标记阶段\u0026rdquo; \"\r标记清除的标记阶段\r 标记阶段结束后会进入清除阶段，在该阶段中收集器会依次遍历堆中的所有对象，释放其中没有被标记的B、E和F三个对象并将新的空闲内存空间以链表的结构串联起来，方便内存分配器的使用 标记清除的清除阶段\u0026ldquo;标记清除的清除阶段\u0026rdquo; \"\r标记清除的清除阶段\r 这里介绍的是最传统的标记清除算法，垃圾收集器从垃圾收集的根对象出发，递归遍历这些对象指向的子对象并将所有可达的对象标记成存活；标记阶段结束后，垃圾收集器会依次遍历堆中的对象并清除其中的垃圾，整个过程中需要标记对象的存活状态，用户程序在垃圾收集的过程中也不能执行，我们需要用到更复杂的机制来解决STW的问题。 ","date":"2021-11-09","objectID":"/go-garbage-collector/:1:1","tags":["mysql"],"title":"Go垃圾收集器","uri":"/go-garbage-collector/"},{"categories":["学习"],"content":"三色抽象 为了解决原始标记清除算法带来的长时间STW，多数现代的追踪式垃圾收集器都会实现三色标记算法的变种以缩短STW的时间。三色标记算法将程序中的对象分成白色，黑色和灰色三类 白色对象：潜在的垃圾，其内存可能会被垃圾收集器回收 黑色对象：活跃的对象，包括不存在任何引用外部指针的对象以及从根对象可达的对象 灰色对象：活跃的对象，因为存在指向白色对象的外部指针，垃圾收集器会扫描这些对象的子对象 三色的对象\u0026ldquo;三色的对象\u0026rdquo; \"\r三色的对象\r 在垃圾收集器开始工作时，程序中不存在任何的黑色对象，垃圾收集的根对象会被标记为灰色，垃圾收集器只会从灰色对象集合中取出对象开始扫描，当灰色集合中不再存在对象时，标记阶段就会结束。 三色标记垃圾收集器的执行过程\u0026ldquo;三色标记垃圾收集器的执行过程\u0026rdquo; \"\r三色标记垃圾收集器的执行过程\r 三色标记垃圾收集器的工作原理很简单，我们可以将其归纳成一下几个步骤： 从灰色对象的集合中选择一个灰色对象并将其标记成黑色。 将黑色对象指向的所有对象都标记成灰色，保证该对象和被该对象引用的对象都不会被回收。 重复上述两个步骤直到对象图中不存在灰色对象 当三色的标记清除的标记阶段结束之后，应用程序的堆中就不存在任何的灰色对象，我们只能看到黑色的存活对象以及白色的垃圾对象，垃圾收集器可以回收这些白色垃圾，下面是使用三色标记垃圾收集器执行标记后的堆内存，堆中只有对象D待回收垃圾 三色标记后的堆\u0026ldquo;三色标记后的堆\u0026rdquo; \"\r三色标记后的堆\r 因为用户程序可能在标记执行的过程中修改对象的指针，所以三色标记清除算法本身是不可以并发或者增量执行的，它仍然需要STW，在如下所示的三色标记过程中，用户程序建立了从A对象到D对象的引用，但是因为程序中已经不存在灰色对象了，所以D对象会被垃圾收集器错误的回收 三色标记与用户程序\u0026ldquo;三色标记与用户程序\u0026rdquo; \"\r三色标记与用户程序\r 本来不应该被回收的对象却被回收了，这在内存管理中是非常严重的错误，我们将这种错误称为悬挂指针，即指针没有指向特定类型的合法对象，影响了内存的安全性，想要并发或者增量的标记对象还是需要使用屏障技术 ","date":"2021-11-09","objectID":"/go-garbage-collector/:1:2","tags":["mysql"],"title":"Go垃圾收集器","uri":"/go-garbage-collector/"},{"categories":["学习"],"content":"屏障技术 内存屏障技术是一种屏障指令，它可以让CPU或者编译器在执行内存相关操作时遵循特定的约束，目前多数的现代处理器都会乱序执行指令以最大化性能，但是该技术能够保证内存操作的顺序性，在内存屏障执行前的操作一定会先于内存屏障后执行的操作。 想要在并发或者增量的标记算法中保证正确性，我们需要达成以下两种三色不变性(Tri-color-invariant)中的一种： 强三色不变性：黑色对象不会指向白色对象，只会指向灰色对象或者黑色对象 弱三色不变性：黑色对象指向的白色对象必须包含一条从灰色对象经由多个白色对象的可达路径 三色不变性\u0026ldquo;三色不变性\u0026rdquo; \"\r三色不变性\r 上图分别展示了遵循三色不变性和弱三色不变性的堆内存，遵循上述两个不变性的任意一个，我们都能保证垃圾收集算法的正确性，而屏障技术就是在并发或者增量标记过程中保证三色不变性的重要技术。 垃圾收集器中的屏障技术更像是一个钩子方法，它是在用户程序读取对象、创建新对象以及更新对象指针时执行的一段代码，根据操作类型的不同，我们可以将它们分成读屏障(Read barrier)和写屏障(Write barrier)两种，因为读屏障需要在读操作中加入代码片段，对用户程序的性能影响很大，所以编程语言往往会采用写屏障保证三色不变性。 我们在这里想要介绍的是Go语言中使用的两种写屏障技术，分别是Dijkstra提出的插入写屏障和Yuasa提出的删除写屏障，这里会分析它们如何保证三色不变性和垃圾收集器的正确性。 插入写屏障 Dijkstra在1978年提出了插入写屏障，通过如下所示的写屏障，用户程序和垃圾收集器可以在交替工作下保证程序执行的正确性 writePointer(slot, ptr): shade(ptr) *slot = ptr 上述插入写屏障的伪代码非常好理解，每当执行类似*slot=ptr的表达式时，我们会执行上述写屏障通过shade函数尝试改变指针的颜色。如果ptr指针是白色的，那么该函数会将该对象设置为灰色，其他情况则不变。 Dijkstra插入写屏障\u0026ldquo;Dijkstra插入写屏障\u0026rdquo; \"\rDijkstra插入写屏障\r 假设我们在应用程序中使用Dijkstra提出的插入写屏障，在一个垃圾收集器和用户程序交替运行的场景中会出现上图所示的标记过程 垃圾收集器将根对象指向A对象标记成黑色并将A对象指向的对象B标记为灰色 用户程序修改A对象的指针，将原本指向B对象的指针指向C对象，这时触发写屏障将C对象标记成灰色 垃圾收集器一次遍历程序中的其他灰色对象，分别将它们标记成黑色 Dijkstra的插入写屏障是一种相对保守的屏障技术，它会将有存活可能的对象都标记成灰色以满足三色不变性。在如上所示的垃圾收集过程中，实际上不再存活的B对象最后没有被回收；而如果我们在第二和第三步之间将指向C对象的指针改为指向B，垃圾收集器仍然认为C对象是存活的，这些被错误标记的垃圾对象只有在下一次循环才会被回收。 插入式的Dijkstra写屏障虽然实现非常简单并且能保证强三色不变性，但是它也有明显的缺点。因为栈上的对象在垃圾收集中也会被认为是根对象，所以为了保证内存的安全，Dijkstra必须为栈上的对象增加写屏障或者在标记阶段完成重新对栈上的对象进行扫描，这两种方法各有各的缺点，前者会大幅度增加写入指针的额外开销，后者重新扫描栈对象时需要暂停程序，垃圾收集算法的设计者需要在这两者之间做出权衡。 删除写屏障 Yuasa在1990年的论文Real-time garbage collection on general-purpose machines中提出了删除写屏障，因为一旦该写屏障开始工作，它会保证开启写屏障时堆上所有对象的可达，所以也被称作为快照垃圾收集(Snapshot GC) This guarantees that no objects will become unreachable to the garbage collector traversal all objects which are live at the beginning of garbage collection will be reached even if the pointers to them are overwritten. 该算法会使用如下所示的写屏障保证增量或者并发执行垃圾收集时程序的正确性 writePointer(slot, ptr) shade(*slot) *slot = ptr 上述代码会在老对象的引用被删除时，将白色的老对象涂成灰色的，这样删除写屏障可以保证弱三色不变性，老对象引用的下游对象一定可以被灰色对象引用。 Yuasa删除写屏障\u0026ldquo;Yuasa删除写屏障\u0026rdquo; \"\rYuasa删除写屏障\r 假设我们在应用程序中使用Yuasa提出的删除写屏障，在一个垃圾收集器和用户程序交替运行的场景中会出现上图所示的标记过程： 垃圾收集器将根对象指向A对象标记成黑色并将A对象指向的对象B标记成灰色 用户程序将A对象原本指向B的指针指向C，触发删除写屏障，但是因为B对象已经是灰色的，所以不做改变 用户程序将B对象原本指向C的指针删除，触发删除写屏障，白色的C对象被涂成灰色 垃圾收集器依次遍历程序中的其他灰色对象，将它们分别标记成黑色 上述过程中的第三步触发了Yuasa删除写屏障的着色，因为用户程序删除了B指向C对象的指针，所以C和D两个对象会分别违反强三色不变性和弱三色不变性 强三色不变性：黑色的A对象直接指向白色的C对象 弱三色不变性：垃圾收集器无法从某个灰色对象出发，经过几个连续的白色对象访问白色的C和D两个对象 Yuasa删除写屏障通过对C对象的着色，保证了C对象和下游的D对象能够在这一次垃圾收集的循环中存活，避免发生悬挂指针以保证用户程序的正确性 ","date":"2021-11-09","objectID":"/go-garbage-collector/:1:3","tags":["mysql"],"title":"Go垃圾收集器","uri":"/go-garbage-collector/"},{"categories":["学习"],"content":"增量和并发 传统的垃圾收集算法会在垃圾收集的执行期间暂停应用程序，一旦触发垃圾收集，垃圾收集器会抢占CPU的使用权占据大量的计算资源以完成标记和清楚工作，然而 很多追求实时的应用程序无法接受长时间的STW 垃圾收集与暂停程序\u0026ldquo;垃圾收集与暂停程序\u0026rdquo; \"\r垃圾收集与暂停程序\r 远古时代的计算资源还没有今天这么丰富，今天的计算机往往都是多核的处理器，垃圾收集器一旦开始执行就会浪费大量的计算资源，为了减少应用程序暂停的最长时间和垃圾收集的总暂停时间，我们便会使用下面的策略优化现代的垃圾处理器 增量垃圾处理：增量的标记和清除垃圾，降低应用程序暂停的最长时间 并发垃圾收集：利用多核的计算资源，在用户程序执行时并发标记和清除垃圾 因为增量和并发这两种方式都可以与用户程序交替进行，所以我们需要使用屏障技术保证垃圾收集器的正确性；与此同时，应用程序也不能等到内存溢出时触发垃圾收集，因为当内存不足时，应用程序已经无法分配内存，这与直接暂停程序没有什么区别，增量和并发的垃圾收集需要提前触发并在内存不足前完成整个循环，避免程序的长时间暂停。 增量收集器 增量式(Incremental)的垃圾收集是减少程序最长暂停时间的一种方案，它可以将原本时间较长的暂停时间切分成多个更小的GC时间片，虽然从垃圾收集开始到结束的时间更长了，但是这也减少了应用程序暂停的最大时间 增量垃圾收集器\u0026ldquo;增量垃圾收集器\u0026rdquo; \"\r增量垃圾收集器\r 需要注意的是，增量式的垃圾收集需要与三色标记法一起使用，为了保证垃圾收集的正确性，我们需要在垃圾收集开始前打开写屏障，这样用户程序修改内存都会先经过写屏障的处理，保证了堆内存中对象的强三色不变性或弱三色不变性。虽然增量式垃圾收集器能够减少最大的程序暂停时间，但是增量式收集也会增加一次GC循环的总时间，在垃圾收集期间，因为写屏障的影响用户程序也要承担额外的计算开销，所以增量式的垃圾收集也不是只带来好处的，但是总体来说还是利大于弊的。 并发收集器 并发(Concurrent)的垃圾收集不仅能够减少程序的最长暂停时间，还能减少整个垃圾收集阶段的时间，通过开启读写屏障、利用多核优势与用户程序并行执行，并发垃圾收集器确实能够减少垃圾收集对应用程序的影响： 并发垃圾收集器\u0026ldquo;并发垃圾收集器\u0026rdquo; \"\r并发垃圾收集器\r 虽然并发收集器能够与用户程序一起运行，但是并不是所有阶段都可以与用户程序一起运行，部分阶段还是需要暂停用户程序的，不过这与传统的算法相比，并发的垃圾收集器可以将能够并发执行的工作尽量并发执行；当然，因为读写屏障的引入，并发的垃圾收集器一定也会带来额外开销，不仅会增加垃圾收集的总时间，还会影响用户程序，这是我们在设计垃圾回收策略时必须要注意的。 ","date":"2021-11-09","objectID":"/go-garbage-collector/:1:4","tags":["mysql"],"title":"Go垃圾收集器","uri":"/go-garbage-collector/"},{"categories":["学习"],"content":"演进过程 Go语言的垃圾收集器从诞生的第一天起就一直在演进，除了少数的几个版本没有大更新之外，几乎每次发布的小版本都会提升垃圾收集的性能，而与性能一同提升的还有垃圾收集代码的复杂度，本节将从Go语言的v1.0版本开始分析垃圾收集器的演进过程。 v1.0：完全串行的标记和清除过程，需要暂停整个程序 v1.1：在多核主机上并行执行垃圾收集的标记和清除阶段 v1.3：运行时基于只有指针类型的值包含指针的假设增加了对栈内存的精准扫描支持，实现了真正精准的垃圾收集 将unsafe.Pointer 类型转化成整数类型的值认定为不合法的，可能会造成悬挂指针等严重问题 v1.5：实现了基于三色标记清扫的并发垃圾收集器 大幅度降低垃圾收集的延迟从几百ms降低至10ms以下 计算垃圾收集启动的合适时间并通过并发加速垃圾收集的过程 v1.6：实现了去中心化的垃圾收集协调器 基于显式的状态机使得任意Goroutine都能触发垃圾收集的状态迁移 使用密集的位图代替空闲链表表示的堆内存，降低清除阶段的CPU占用 v1.7：通过并行栈收缩将垃圾收集的时间缩短至2ms以内 v1.8：使用混合写屏障将垃圾收集的时间缩短至0.5ms以内 v1.9：彻底移除暂停程序的重新扫描栈的过程 v1.10：更新了垃圾收集调频器(Pacer)的实现，分离软硬堆大小的目标 v1.12：使用新的标记终止算法简化垃圾收集器的几个阶段 v1.13：通过新的Scavenger解决瞬间内存占用过高的应用程序向操作系统归还内存的问题 v1.14：使用全新的页分配器优化内存分配的速度 我们从Go语言垃圾收集器的演进能够看到该组件的实现和算法变得越来越复杂，最开始的垃圾收集器还是不精准的单线程STW收集器，但是最新版本的垃圾收集器却支持并发垃圾收集、去中心化协调等特性，我们在这里将介绍与最新版垃圾收集器相关的组件和特性。 ","date":"2021-11-09","objectID":"/go-garbage-collector/:2:0","tags":["mysql"],"title":"Go垃圾收集器","uri":"/go-garbage-collector/"},{"categories":["学习"],"content":"并发垃圾收集 Go语言在v1.5中引入了并发的垃圾收集器，该垃圾收集器使用了我们上面提到的三色抽象和写屏障技术保证垃圾收集器执行的正确性，如何实现并发的垃圾收集器在这里就不展开介绍了，我们来了解一些并发垃圾收集器的工作流程。 首先，并发垃圾收集器必须在合适的时间点触发垃圾收集循环，假设我们的Go语言运行在一台4核的物理机上，那么在垃圾收集开始后，收集器会占用25%计算资源在后台来扫描并标记内存中的对象。 语言的并发收集\u0026ldquo;语言的并发收集\u0026rdquo; \"\r语言的并发收集\r Go语言的并发垃圾收集器会在扫描对象之前暂停程序做一些标记对象的准备工作，其中包括启动后台标记的垃圾收集器以及开启写屏障，如果在后台执行的垃圾收集器不够快，应用程序申请内存的速度超过预期，运行时会让申请内存的应用程序辅助完成垃圾收集的扫描阶段，在标记和标记终止阶段结束之后就会进入异步的清理阶段，将不用的内存增量回收。 v1.5版本实现的并发垃圾收集策略由专门的Goroutine负责在处理器间同步和协调垃圾收集的状态。当其他的Goroutine发现需要触发垃圾收集时，它们需要将该信息通知给负责修改状态的主Goroutine，然而这个通知的过程会带来一定的延迟，这个延迟的时间窗口是不可控的，用户程序会在这段时间继续分配内存。 v1.6版本引入了去中心化的垃圾收集协调机制，将垃圾收集器变成一个显式的状态机，任意的Goroutine都可以调用方法触发状态的迁移，常见的状态迁移方法包括以下几个： runtime.gcStart：从_GCoff阶段转换至_GCmark阶段，进入并发标记阶段并打开写屏障 runtime.gcMarkDone：如果所有可达对象都已经完成扫描调用runtime.gcMarkTermination runtime.gcMarkTermination：从_GCmark转换_GCmarktermination阶段，进入标记终止阶段并在完成后进入_GCoff 上述的三个方法是在与runtime: replace GC coordinator with state machine问题相关的提交中引入的，它们移除了过去中心化的状态迁移过程。 ","date":"2021-11-09","objectID":"/go-garbage-collector/:2:1","tags":["mysql"],"title":"Go垃圾收集器","uri":"/go-garbage-collector/"},{"categories":["学习"],"content":"回收堆目标 STW的垃圾收集器虽然需要暂停应用程序，但是它能够有效地控制堆内存的大小，Go语言运行时默认配置会在堆内存达到上一次垃圾收集的两倍时，触发新一轮的垃圾收集，这个行为可以通过环境变量GOGC调整，在默认情况下它的值为100，即增长100%的堆内存才会触发GC。 STW垃圾收集器的垃圾收集时间\u0026ldquo;STW垃圾收集器的垃圾收集时间\u0026rdquo; \"\rSTW垃圾收集器的垃圾收集时间\r 因为并发垃圾收集器会和程序一起执行，所以它无法准确的控制内存的大小，并发收集器需要在达到目标前触发垃圾收集，这样才能够保证内存的大小可控，并发收集器需要尽可能保证垃圾收集结束时的堆内存与用户配置的GOGC一致。 并发收集器的堆内存\u0026ldquo;并发收集器的堆内存\u0026rdquo; \"\r并发收集器的堆内存\r Go语言v1.5引入并发垃圾收集器的同时使用垃圾收集调步(Pacing)算法计算触及的垃圾收集的最佳时间，确保触发的时间既不会浪费计算资源，也不会超出预期的堆大小。如上图所示，其中黑色的部分是上一次垃圾收集后标记的堆大小，绿色部分是上次垃圾收集结束后新分配的内存，因为我们使用并发垃圾收集，所以黄色部分就是在垃圾收集期间分配的内存，最后的红色部分是垃圾收集结束时与目标的差值，我们希望尽可能减少红色部分的内存，降低垃圾收集带来的额外开销以及程序的暂停时间。 垃圾收集调步算法是跟随v1.5一同引入的，该算法的目标是优化堆的增长速度和垃圾收集器的CPU利用率，而在v1.10版本中又对该算法进行了优化，将原有的目的堆大小拆分成软硬两个目标，因为调整垃圾收集的执行频率涉及较为复杂的公式，对理解垃圾收集原理帮助较为有限。 ","date":"2021-11-09","objectID":"/go-garbage-collector/:2:2","tags":["mysql"],"title":"Go垃圾收集器","uri":"/go-garbage-collector/"},{"categories":["学习"],"content":"混合写屏障 在Go语言v1.7版本之前，运行时会使用Dijkstra插入写屏障保证强三色不变性，但是运行时并没有在所有的垃圾收集根对象上开启插入写屏障。因为应用程序可能包含成百上千的Goroutine，而垃圾收集的根对象一般包括全局变量和栈对象，如果运行时需要在几百个Goroutine的栈上都开启写屏障，会带来巨大的额外开销，所以Go团队在实现上选择了在标记阶段完成时暂停程序、将所有栈对象标记为灰色并重新扫描，在活跃Goroutine非常多的程序中，重新扫描的过程需要占用10~100ms的时间。 Go语言在v1.8组合Dijkstra插入写屏障和Yuasa删除写屏障构成了如下所示的混合写屏障，该写屏障会将被覆盖的对象标记成灰色并在当前栈没有扫描时将新对象也标记成灰色 writePointer(slot, ptr): shade(*slot) if current stack is grey: shade(ptr) *slot=ptr 为了移除栈的重新扫描过程，除了引入混合写屏障之外，在垃圾收集的标记阶段，我们还需要将创建的所有新对象都标记成黑色，防止新分配的栈内存和堆内存中的对象被错误的回收，因为栈内存在标记阶段最终都会变为黑色，所以不需要再重新扫描栈空间。 ","date":"2021-11-09","objectID":"/go-garbage-collector/:2:3","tags":["mysql"],"title":"Go垃圾收集器","uri":"/go-garbage-collector/"},{"categories":["学习"],"content":"实现原理 在介绍垃圾收集器的演进过程之前，我们需要初步了解最新垃圾收集器的执行周期，这对我们了解其全局的设计会有比较大的帮助。Go语言的垃圾收集可以分成清除终止、标记、标记终止和清除四个不同阶段，它们分别完成了不同的工作。 垃圾收集的多个阶段\u0026ldquo;垃圾收集的多个阶段\u0026rdquo; \"\r垃圾收集的多个阶段\r 清理终止阶段 暂停程序，所有的处理器在这时会进入安全点(Safe Point) 如果当前垃圾收集循环是强制触发的，我们还需要处理还未被清理的内存管理单元 标记阶段 将状态切换至_GCmark、开启写屏障、用户程序协助(Mutator Assists)并将根对象入队 恢复执行程序，标记进程和用于协助的用户程序会开始并发标记内存中的对象，写屏障会将被覆盖的指针和新指针都标记成灰色，而所有新创建的对象都会被直接标记成黑色 开始扫描根对象，包括所有Goroutine的栈、全局对象以及不在堆中的运行时数据结构，扫描Goroutine栈期间会暂停当前处理器 依次处理灰色队列中的对象，将对象标记成黑色并将它们指向的对象标记成灰色 使用分布式的终止算法检查剩余的工作，发现标记阶段完成后进入标记终止阶段 标记终止阶段 暂停程序、将状态切换至_GCmarktermination并关闭辅助标记的用户程序 清理处理器上的线程缓存 清理阶段 将状态切换至_GCoff开始清理阶段，初始化清理状态并关闭写屏障 恢复用户程序，所有新创建的对象会标记成白色 后台并发清理所有的内存管理单元，当Goroutine申请新的内存管理单元时就会触发清理 运行时虽然只会使用_GCoff、_GCmark和_GCmarktermination三个状态表示垃圾收集的全部阶段，但是在实现上却复杂很多。本节将按照垃圾收集的不同阶段详细分析其实现原理 ","date":"2021-11-09","objectID":"/go-garbage-collector/:3:0","tags":["mysql"],"title":"Go垃圾收集器","uri":"/go-garbage-collector/"},{"categories":["学习"],"content":"全局变量 在垃圾收集中有一些比较重要的全局变量，在分析其过程之前，会逐一介绍这些重要的变量，这些变量在垃圾收集的各个阶段会反复出现，所以理解他们的功能是非常重要的，先介绍一些简单的变量： runtime.gcphase 是垃圾收集器当前处于的阶段，可能处于_GCoff、_GCmark和_GCmarktermination，Goroutine在读取或者修改该阶段时需要保证原子性 runtime.gcBlackenEnabled 是一个布尔值，当垃圾收集处于标记阶段时，该变量会被置为1，在这里辅助垃圾收集的用户程序和后台标记的任务可以将对象涂黑 runtime.gcController 实现了垃圾收集的调步算法，它能够决定出发并行垃圾收集的时间和待处理的工作 runtime.gcpercent 是触发垃圾收集的内存增长百分比，默认情况下为100，即堆内存相比上次垃圾收集增长100%时应该触发GC，并行的垃圾收集器会在到达该目标前完成垃圾收集 runtime.writerBarrier 是一个包含写屏障状态的结构体，其中的enable字段表示写屏障的开启与关闭 runtime.worldsema 是全局的信号量，获取该信号量的线程有权利暂停当前应用程序 除了上述全局的变量之外，我们在这里还需要简单了解一下runtime.work变量： var work struct { full lfstack empty lfstack pad0 cpu.CacheLinePad wbufSpans struct { lock mutex free mSpanList busy mSpanList } ... nproc uint32 tstart int64 nwait uint32 ndone uint32 ... mode gcMode cycles uint32 ... stwprocs, maxprocs int32 ... } 该结构体中包含大量垃圾收集的相关字段，例如：表示完成的垃圾收集循环的次数、当前循环时间和CPU的利用率、垃圾收集的模式等等，我们会在后面的小节中见到该结构体中的更多字段 ","date":"2021-11-09","objectID":"/go-garbage-collector/:3:1","tags":["mysql"],"title":"Go垃圾收集器","uri":"/go-garbage-collector/"},{"categories":["学习"],"content":"触发时机 运行时会通过如下所示的runtime.gcTrigger.test方法决定是否需要触发垃圾收集，当满足触发垃圾收集的基本条件时：允许垃圾收集、程序没有崩溃并且没有处于垃圾收集循环，该方法会根据三种不同方式触发进行不同的检查： func (t gcTrigger) test() bool { if !memstats.enablegc || panicking != 0 || gcphase != _GCoff { return false } switch t.kind { case gcTriggerHeap: return memstats.heap_live \u003e= memstats.gc_trigger case gcTriggerTime: if gcpercent \u003c 0 { return false } last := int64(atomic.Load64(\u0026memstats.last_gc_nanotime)) return lastgc != 0 \u0026\u0026 t.now-lastgc \u003e forcegcperiod case gcTriggerCycle: return int32(t.n-work.cycles) \u003e 0 } return true } gcTriggerHeap 堆内存的分配达到控制器计算的触发堆大小 gcTriggerTime 如果一定时间内没有触发，就会触发新的循环，该触发条件有runtime.forcegcperiod变量控制，默认为2分钟 gcTriggerCycle 如果当前没有开启垃圾收集、则触发新的循环 用于开启垃圾收集的方法runtime.goStart会接收一个runtime.gcTrigger类型的谓词，所有出现runtime.gcTrigger结构体的位置都是触发垃圾收集的代码 runtime.sysmon和runtime.forcegchelper 后台运行定时检查和垃圾收集 runtime.GC 用户程序手动触发垃圾收集 runtime.mallocgc 申请内存时根据堆大小触发垃圾收集 垃圾收集的触发\u0026ldquo;垃圾收集的触发\u0026rdquo; \"\r垃圾收集的触发\r 除了使用后台运行的系统监控器和强制垃圾收集助手触发垃圾收集之外，另外两个办法会从任意处理器上触发垃圾收集，这种不需要中心组件协调的方式是在v1.6版本中引入的，接下来将展开介绍这三种不同的触发时机 后台触发 运行时会在应用程序启动时在后台开启一个用于强制触发垃圾收集的Goroutine，该Goroutine的职责非常简单(调用runtime.gcStart尝试启动新一轮的垃圾收集) func init() { go forcegchelper() } func forcegchelper() { forcegc.g = getg() for { lock(\u0026forcegc.lock) atomic.Store(\u0026forcegc.idle, 1) goparkunlock(\u0026forcegc.lock, waitReasonForceGGIdle, traceEvGoBlock, 1) gcStart(gcTrigger{ kind: gcTriggerTime, now: nanotime() }) } } 为了减少对计算资源的占用，该Goroutine会在循环中调用runtime.goparkunlock主动陷入休眠等待其他Goroutine的唤醒，runtime.forcegchelper在大多数时间都是陷入休眠的，但是它会被系统监控器runtime.sysmon在满足垃圾收集条件时唤醒： func sysmon() { ... for { ... if t := (gcTrigger{ kind: gcTriggerTime, now: now, }); t.test() \u0026\u0026 atomic.Load(\u0026forcegc.idle) != 0 { lock(\u0026forcegc.lock) forcegc.idle = 0 var list gList list.push(forcegc.g) injectglist(\u0026list) unlock(\u0026forcegc.lock) } } } 系统监控在每个循环中都会主动构建一个runtime.gcTrigger并检查垃圾收集的触发条件是否满足，如果满足条件，系统监控会将runtime.forcegc状态中持有的Goroutine加入全局队列等待调度器的调度 手动触发 用户程序会通过runtime.GC函数在程序运行期间主动通知运行时执行，该方法在调用时会阻塞调用方直到当前垃圾收集循环完成，在垃圾收集期间也可能会通过STW暂停整个程序 func GC() { n := atomic.Load(\u0026work.cycles) gcWaitOnMark(n) gcStart(gcTrigger{ kind: gcTriggerCycle, n: n+1, }) gcWaitOnMark(n+1) for atomic.Load(\u0026work.cycles) == n+1 \u0026\u0026 sweepone() != ^uintptr(0) { sweep.nbgsweep++ Gosched() } for atomic.Load(\u0026work.cycles) == n+1 \u0026\u0026 atomic.Load(\u0026mheap_.sweepers) != 0 { Gosched() } mp := acquirem() cycle := atomic.Load(\u0026work.cycles) if cycle == n+1 || (gcphase == _GCmark \u0026\u0026 cycle == n+2) { mProf_PostSweep() } releasem(mp) } 在正式开始垃圾收集前，运行时需要通过runtime.gcWaitOnMark等待上一个循环的标记终止、标记和清除终止阶段完成 调用runtime.gcStart触发新一轮的垃圾收集并通过runtime.gcWaitOnMark等待该轮垃圾收集的标记终止阶段正常结束 持续调用runtime.sweepone清理全部待处理的内存管理单元并等待所有的清理工作完成，等待期间会调用runtime.Gosched让出处理器 完成本轮垃圾收集的清理工作后，通过runtime.mProf_PostSweep将该阶段的堆内存状态快照发布出来，我们可以获取这时的内存状态 手动触发垃圾收集的过程并不是特别常见，一般只会在运行时的测试代码中才会出现，不过如果我们认为触发主动垃圾收集是有必要的，也可以直接调用该方法，但是作者不认为这是一种推荐的做法 申请内存 最后一个可能会触发垃圾收集的就是runtime.mallocgc，Go运行时会将堆上的对象按大小分成微对象、小对象和大对象三类，这三类对象的创建都可能会触发细心地垃圾收集循环 func mallocgc(size uintptr, type *_type, needzero bool) unsafe.Pointer { shouldhelpgc := false ... if size \u003c= maxSmallSize { if noscan \u0026\u0026 size \u003c maxTinySize { ... v := nextFreeFast(span) if v == 0 { v, _, shouldhelpgc = c.nextFree(tinySpanClass) } ... } else { ... v := nextFreeFast(span) if v == 0 { v, span, shouldhelpgc = c.nextFree(spc) } ... } } else { shouldhelpgc = true ... } ... if shouldhelpgc { if t := (gcTrigger{ kind: gcTriggerHeap }); t.test() { gcStart(t) } } return x } 当前线程的内存管理单元中不存在空闲空间时，创建微对象和小对象需要调用runtime.mcache.nextFree从中心缓存或者页堆中获取新的管理单元，在这时就可能触发垃圾收集 当用户程序申请分配32KB以上的大对象时，一定会构建runtime.gcTrigger结构体尝试触发垃圾收集 通过堆内存触发垃圾收集需要比较runtime.mstats中的两个字段：表示垃圾收集中存活对象字节数的heap_live和表示触发标记的堆内存大小的gc_trigger；当内存中存活的对象字节数大于触发垃圾收集的堆大小时，新一轮的垃圾收集就会开始。这里将分别介绍这两个值的计算过程： heap_live: 为了减少锁竞争，运行时只会在中心缓存分配或者释放内存管理单元以及在堆上分配大对象时才会更新 gc_trigger：在标记终止阶段调用runtime.gcSetTriggerRatio更新触发下一次垃圾收集的堆大小 runtime.gcController会在每个循环结束后计算触发比例并通过runtime.gcSetTriggerRatio设置gc_trigger，它能够决定触发垃圾收集的时间以及用户程序和后台处理的标记任务的多少，利用反馈控制的算法根据堆的增长情况和垃圾收集CPU利用率确定触发垃圾收集的时机 可以在runtime.gcControllerState.endCycle中找到v1.5提出的垃圾","date":"2021-11-09","objectID":"/go-garbage-collector/:3:2","tags":["mysql"],"title":"Go垃圾收集器","uri":"/go-garbage-collector/"},{"categories":["学习"],"content":"垃圾收集启动 垃圾收集在启动过程一定会调用runtime.gcStart，虽然该函数的实现比较复杂，但是它的主要职责是修改全局的垃圾收集状态到_GCmark并做一些准备工作，下面会分几个阶段介绍该函数的实现 两次调用runtime.gcTrigger.test检查是否满足垃圾收集条件 暂停程序、在后台启动用于处理标记任务的工作Goroutine、确定所有内存管理单元都被清理以及其他标记阶段开始前的准备工作 进入标记阶段、准备后台的标记工作、根对象的标记工作以及微对象、恢复用户程序，进入并发扫描和标记阶段 验证垃圾收集条件的同时，该方法还会在循环中不断调用runtime.sweepone清理已经被标记的内存单元，完成上一个垃圾收集循环的收尾工作 func gcStart(trigger gcTrigger) { for trigger.test() \u0026\u0026 sweepone() != ^uintptr(0) { sweep.nbgsweep++ } semacquire(\u0026work.startSema) if !trigger.test() { semrelease(\u0026work.startSema) return } ... } 在验证了垃圾收集的条件并完成了收尾工作后，该方法会通过semacquire获取全局的worldsema信号量、调用runtime.gcBgMarkStartWorkers启动后台标记任务、在系统栈中调用runtime.stopTheWorldWithSema暂停程序并调用runtime.finishsweep_m保证上一个内存单元的正常回收： func gcStart(trigger gcTrigger) { ... semacquire(\u0026worldsema) gcBgMarkStartWorkers() work.stwprocs, work.maxprocs = gomaxprocs, gomaxprocs ... systemstack(stopTheWorldWithSema) systemstack(func() { finishsweep_m() }) work.cycles++ gcController.startCycle() ... } 除此之外，上述过程还会修改全局变量runtime.work持有的状态，包括垃圾收集需要的Goroutine数量以及已完成的循环数 在完成全部的准备工作后，该方法就进入了执行的最后阶段。在该阶段中，我们会修改全局的垃圾收集状态到_GCmark并依次执行下面的步骤 调用runtime.gcBgMarkPrepare初始化后台扫描需要的状态 调用runtime.gcMarkRootPrepare扫描栈上、全局变量等根对象并将它们加入队列 设置全局变量runtime.gcBlackenEnabled，用户程序和标记任务可以将对象涂黑 调用runtime.startTheWorldWithSema启动程序，后台任务也会开始标记堆中的对象 func gcStart(trigger gcTrigger) { ... setGCPhase(_GCmark) gcBgMarkPrepare() gcMarkRootPrepare() atomic.Store(\u0026gcBlackenEnabled, 1) systemstack(func() { now = startTheWorldWithSema(trace.enabled) work.pauseNS += now - work.pauseStart work.tMark = now }) semrelease(\u0026work.startSema) } 在分析垃圾收集的启动过程中，我们省略了几个关键的过程，其中包括暂停和恢复应用程序和后台任务的启动，下面将详细分析这几个过程的实现原理 暂停与恢复程序 runtime.stopTheWorldWithSema和runtime.startTheWorldWithSema是一对用于暂停和恢复程序的核心函数，它们有着完全相反的功能，但是程序的暂停会比恢复要复杂一些，看下前者的实现原理 func stopTheWorldWithSema() { _g_ := getg() sched.stopwait = gomaxprocs atomic.Store(\u0026sched.gcwaiting, 1) preemptall() _g_.m.p.ptr().status = _Pgcstop sched.stopwait-- for _, p := range allp { s := p.status if s == _Psyscall \u0026\u0026 atomic.Cas(\u0026p.status, s, _Pgcstop) { p.syscalltick++ sched.stopwait-- } } for { p := pidleget() if p == nil { break } p.status = _Pgcstop sched.stopwait-- } wait := sched.stopwait \u003e 0 if wait { for { if notetsleep(\u0026sched.stopnote, 100*1000) { noteclear(\u0026sched.stopnote) break } preemptall() } } } 暂停程序主要使用了runtime.preemptall，该函数会调用前面介绍的runtime.preemtone，因为程序中活跃的最大处理数为gomaxprocs，所以runtime.stopTheWorldWithSema在每次发现停止的处理器时都会对该变量减一，知道所有的处理器都停止运行。该函数会依次停止当前处理器、等待处于系统调用的处理器以及获取并抢占空闲的处理器，处理器的状态在该函数返回时都会被更新至_Pgcstop，等待垃圾收集器的重新唤醒 程序恢复过程会使用runtime.startTheWorldWithSema，该函数的实现也相对比较简单 调用runtime.netpoll从网络轮询器中获取待处理的任务并加入全局队列 调用runtime.procresize扩容或者缩容全局的处理器 调用runtime.notewakeup或者runtime.newm依次唤醒处理器或者为处理器创建新的线程 如果当前待处理的Goroutine数量过多，创建额外的处理器完成任务 func startTheWorldWithSema(emitTraceEvent bool) int64 { mp := acquirem() if netpollinited() { list := netpoll(0) injectglist(\u0026list) } procs := gomaxprocs p1 := procresize(procs) sched.gcwaiting = 0 ... for p1 != nil { p := p1 p1 = p1.link.ptr() if p.m != 0 { mp := p.m.ptr() p.m = 0 mp.nextp.set(p) notewakeup(\u0026mp.park) } else { newm(nil, p) } } if atomic.Load(\u0026sched.npidle) != 0 \u0026\u0026 atomic.Load(\u0026sched.nmspinning) == 0 { wakep() } ... } 程序的暂停和启动过程都比较简单，暂停程序会使用runtime.preemptall抢占所有的处理器，恢复程序会使用runtime.notewakeup或者runtime.newm唤醒程序中的处理器 后台标记模式 在垃圾收集启动期间，运行时会调用runtime.gcBgMarkStartWorkers为全局每个处理器创建用于执行后台标记任务的Goroutine，每一个Goroutine都会运行runtime.gcBgMarkWorker，所有运行runtime.gcBgMarkWorker的Goroutine在启动后都会陷入休眠等待调度器的唤醒： func gcBgMarkStartWorkers() { for gcBgMarkWorkerCount \u003c gomaxprocs { go gcBgMarkWorker() notetsleepg(\u0026work.bgMarkReady, -1) noteclear(\u0026work.bgMarkReady) gcBgMarkWorkerCount++ } } 这些Goroutine与处理器也是一一对应的关系，当垃圾收集处于标记阶段并且当前处理器不需要做任何任务时，runtime.findrunnable会在当前处理器上执行该Goroutine辅助并发的对象标记 处理器与后台标记任务\u0026ldquo;处理器与后台标记任务\u0026rdquo; \"\r处理器与后台标记任务\r 调度器在调度循环runtime.schedule中还可以通过垃圾收集控制器的runtime.gcControllerState.findRunnabledGCWorker获取并执行用于后台标记的任务。 用于并发扫描对象的工作协程Goroutine总共有三种不同的模式runtime.gcMarkWorkerMode，这三种模式的Goroutine在标记对象时使用完全不同的策略，垃圾收集控制器会按照需要执行不同类型的工作协程 gcMarkWorkerDedicateMode 处理","date":"2021-11-09","objectID":"/go-garbage-collector/:3:3","tags":["mysql"],"title":"Go垃圾收集器","uri":"/go-garbage-collector/"},{"categories":["学习"],"content":"并发扫描与标记辅助 runtime.gcBgMarkWorker是后台的标记任务执行的函数，该函数的循环中执行了对内存中对象图的扫描和标记，我们分三个部分介绍该函数的实现原理 获取当前处理器以及Goroutine打包成runtime.gcBgMarkWorkerNode 类型的结构并主动陷入休眠等待唤醒 根据处理器上的gcMarkWorkerMode模式决定扫描任务的策略 所有标记任务都完成后，调用runtime.gcMarkDone方法完成标记阶段 首先我们来看后台标记工作的准备工作，运行时在这里创建了runtime.gcBgMarkWorkerNode，该结构会预先存储处理器和当前Goroutine，当我们调用runtime.gopark触发休眠时，运行时会在系统栈中安全的建立处理器和后台标记任务的绑定关系 func gcBgMarkWorker() { gp := getg() gp.m.preemptoff = \"GC worker init\" node := new(gcBgMarkWorkerNode) gp.m.preemptoff = \"\" node.gp.set(gp) node.m.set(acquirem()) notewakeup(\u0026work.bgMarkReady) for { gopark(func(g *g, parkp unsafe.Pointer) bool { node := (*gcBgMarkWorkerNode)(nodep) if mp := node.m.ptr(); mp != nil { releasem(mp) } gcBgMarkWorkerPool.push(\u0026node.node) return true }, unsafe.Pointer(node), waitReasonGCWorkerIdle, traceEvGoBlock, 0) ... } 通过runtime.gopark陷入休眠的Goroutine不会进入运行队列，它只会等待垃圾收集控制器或者调度器的直接唤醒；在唤醒后，我们会根据处理器gcMarkWorkerMode选择不同的标记执行策略，不同的执行策略都会调用runtime.gcDrain扫描工作缓冲区runtime.gcWork node.m.set(acquirem()) atomic.Xadd(\u0026work.nwait, -1) systemstack(func() { casgstatus(gp, _Grunning, _Gwaiting) switch pp.gcMarkWorkerMode { case gcMarkWorkerDedicatedMode: gcDrain(\u0026_p_.gcw, gcDrainUntilPreempt|gcDrainFlushBgCredit) if gp.preempt { lock(\u0026sched.lock) for { gp, _ := runqget(_p_) if gp == nil { break } globrunqput(gp) } unlock(\u0026sched.lock) } gcDrain(\u0026_p_.gcw, gcDrainFlushBgCredit) case gcMarkWorkerFractionalMode: gcDrain(\u0026_p_.gcw, gcDrainFractional|gcDrainUntilPreempt|gcDrainFlushBgCredit) case gcMarkWorkerIdleMode: gcDrain(\u0026_p_.gcw, gcDrainIdle|gcDrainUntilPreempt|gcDrainFlushBgCredit) } casgstatus(gp, _Gwaiting, _Grunning) }) 需要注意的是，gcMarkWorkerDedicatedMode模式的任务是不能被抢占的，为了减少额外开销，第一次调用runtime.gcDrain时是允许抢占的，但是 一旦处理器被抢占，当前Goroutine会将处理器上的所有可运行的Goroutine转移至全局队列中，保证垃圾收集占用的CPU资源 当所有的后台工作任务都陷入等待并且名优剩余工作时，我们就任务该轮垃圾收集的标记阶段结束了，这时我们会调用runtime.gcMarkDone incnwait := atomic.Xadd(\u0026work.nwait, +1) if incnwait == work.nproc \u0026\u0026 !gcMarkWorkAvailable(nil) { releasem(node.m.ptr()) node.m.set(nil) gcMarkDone() } runtime.gcDrain是用于扫描和标记堆内存中对象的核心方法，除了该方法之外，我们还会介绍工作池、写屏障以及辅助标记的实现原理 工作池 在调用runtime.gcDrain时，运行时会传入处理器上的runtime.gcWorker，这个结构体是垃圾收集器中工作池的抽象，它实现了一个生产者和消费者的模型，我们可以以该结构为起点从整体理解标记工作 垃圾收集器工作池\u0026ldquo;垃圾收集器工作池\u0026rdquo; \"\r垃圾收集器工作池\r 写屏障、根对象扫描和栈扫描都会向工作池中添加额外的灰色对象等待处理，而对象的扫描过程会将灰色对象标记成黑色，同时也可能发现新的灰色对象，当工作对垒中不包含灰色对象时，整个扫描过程就会结束 为了减少锁竞争，运行时在每个处理器上会保存独立的带扫描工作，然而这回遇到和调度器一样的问题(不同处理器的资源不平均，导致部分处理器无事可做，调度器引入了工作窃取来解决这个问题，垃圾收集器也使用了差不多的机制平衡不同处理器上的待处理任务) 全局任务与本地任务\u0026ldquo;全局任务与本地任务\u0026rdquo; \"\r全局任务与本地任务\r runtime.gcWork为垃圾收集器提供了生产和消费任务的抽象，该结构体持有了两个重要的工作缓冲区wbug1和wbuf2，这两个缓冲区分别是主缓冲区和备缓冲区 type gcWork struct { wbuf1, wbuf2 *workbuf ... } type workbufhdr struct { node lfnode // must be first nobj int } type workbuf struct { workbufhdr obj [(_WorkbufSize - unsafe.Sizeof(workbufhdr{})) / sys.PtrSize]uintptr } 当我们向该结构体中增加或者删除对象时，它总会先操作主缓冲区，一旦主缓冲区空间不足或者没有对象，会触发主备缓冲区的切换；而当两个缓冲区空间都不足或者都为空时，会从全局的工作缓冲区中插入或者获取对象，该结构体相关方法的实现都非常简单 扫描对象 运行时会使用runtime.gcDrain扫描工作缓冲区中的灰色对象，它会根据传入gcDrainFlags的不同选择不同的策略 func gcDrain(gcw *gcWork, flags gcDrainFlags) { gp := getg().m.curg preemptible := flags\u0026gcDrainUntilPreempt != 0 flushBgCredit := flags\u0026gcDrainFlushBgCredit != 0 idle := flags\u0026gcDrainIdle != 0 initScanWork := gcw.scanWork checkWork := int64(1\u003c\u003c63 - 1) var check func() bool if flags\u0026(gcDrainIdle|gcDrainFractional) != 0 { checkWork = initScanWork + drainCheckThreshold if idle { check = pollWork } else if flags\u0026gcDrainFractional != 0 { check = pollFractionalWorkerExit } } ... } gcDrainUntilPreemt 当Goroutine的preempt字段被设置成true时返回 gcDrainIdle 调用runtime.pollWork，当处理器上包含 其他待执行Goroutine时返回 gcDrainFractional 调用runtime.pollFractionalWorkerExit，当CPU的占用率超过fractionalUtilizationGoal的20%时返回 gcDrainFlushBgCredit 调用runtime.gcFlushBgCredit计算后台完成的标记任务量以减少并发标记期间的辅助垃圾收集的用户程序的工作量 运行时会使用本地变量中的check检查当前是否应该退出标记任务并让出该处理器。当我们做完准备工作后，就可以开始扫描变量中的根对象，这也是标记阶段中需要先被执行的任务 func gcDrain(gcw *gcWork, flags gcDrainFlags) { ... if work.markrootNext \u003c work.markrootJobs { for !(preemptible \u0026\u0026 gp.preempt) { job := atomic.Xadd(\u0026work.markrootNext, +1) - 1 if job \u003e= work.","date":"2021-11-09","objectID":"/go-garbage-collector/:3:4","tags":["mysql"],"title":"Go垃圾收集器","uri":"/go-garbage-collector/"},{"categories":["学习"],"content":"标记终止 当所有处理器的本地任务都完成并且不存在剩余的工作 Goroutine 时，后台并发任务或者辅助标记的用户程序会调用runtime.gcMarkDone通知垃圾收集器。当所有可达对象都被标记后，该函数会将垃圾收集的状态切换至_GCmarktermination；如果本地队列中仍然存在待处理的任务，当前方法会将所有的任务加入全局队列并等待其他 Goroutine 完成处理： func gcMarkDone() { ... top: if !(gcphase == _GCmark \u0026\u0026 work.nwait == work.nproc \u0026\u0026 !gcMarkWorkAvailable(nil)) { return } gcMarkDoneFlushed = 0 systemstack(func() { gp := getg().m.curg casgstatus(gp, _Grunning, _Gwaiting) forEachP(func(_p_ *p) { wbBufFlush1(_p_) _p_.gcw.dispose() if _p_.gcw.flushedWork { atomic.Xadd(\u0026gcMarkDoneFlushed, 1) _p_.gcw.flushedWork = false } }) casgstatus(gp, _Gwaiting, _Grunning) }) if gcMarkDoneFlushed != 0 { goto top } ... } 如果运行时中不包含全局任务、处理器中也不存在本地任务，那么当前垃圾收集循环中的灰色对象也都标记成了黑色，我们就可以开始触发垃圾收集的阶段迁移了： func gcMarkDone() { ... getg().m.preemptoff = \"gcing\" systemstack(stopTheWorldWithSema) ... atomic.Store(\u0026gcBlackenEnabled, 0) gcWakeAllAssists() schedEnableUser(true) nextTriggerRatio := gcController.endCycle() gcMarkTermination(nextTriggerRatio) } 上述函数在最后会关闭混合写屏障、唤醒所有协助垃圾收集的用户程序、恢复用户 Goroutine 的调度并调用runtime.gcMarkTermination进入标记终止阶段： func gcMarkTermination(nextTriggerRatio float64) { atomic.Store(\u0026gcBlackenEnabled, 0) setGCPhase(_GCmarktermination) _g_ := getg() gp := _g_.m.curg casgstatus(gp, _Grunning, _Gwaiting) systemstack(func() { gcMark(startTime) }) systemstack(func() { setGCPhase(_GCoff) gcSweep(work.mode) }) casgstatus(gp, _Gwaiting, _Grunning) gcSetTriggerRatio(nextTriggerRatio) wakeScavenger() ... injectglist(\u0026work.sweepWaiters.list) systemstack(func() { startTheWorldWithSema(true) }) prepareFreeWorkbufs() systemstack(freeStackSpans) systemstack(func() { forEachP(func(_p_ *p) { _p_.mcache.prepareForSweep() }) }) ... } 我们省略了该函数中很多数据统计的代码，包括正在使用的内存大小、本轮垃圾收集的暂停时间、CPU 的利用率等数据，这些数据能够帮助控制器决定下一轮触发垃圾收集的堆大小，除了数据统计之外，该函数还会调用runtime.gcSweep重置清理阶段的相关状态并在需要时阻塞清理所有的内存管理单元；_GCmarktermination状态在垃圾收集中并不会持续太久，它会迅速转换至_GCoff并恢复应用程序，到这里垃圾收集的全过程基本上就结束了，用户程序在申请内存时才会惰性回收内存。 ","date":"2021-11-09","objectID":"/go-garbage-collector/:3:5","tags":["mysql"],"title":"Go垃圾收集器","uri":"/go-garbage-collector/"},{"categories":["学习"],"content":"内存清理 垃圾收集的清理中包含对象回收器（Reclaimer）和内存单元回收器，这两种回收器使用不同的算法清理堆内存： 对象回收器在内存管理单元中查找并释放未被标记的对象，但是如果runtime.mspan中的所有对象都没有被标记，整个单元就会被直接回收，该过程会被runtime.mcentral.cacheSpan或者runtime.sweepone异步触发； 内存单元回收器会在内存中查找所有的对象都未被标记的runtime.mspan，该过程会被runtime.mheap.reclaim触发； runtime.sweepone是我们在垃圾收集过程中经常会见到的函数，它会在堆内存中查找待清理的内存管理单元： func sweepone() uintptr { ... var s *mspan sg := mheap_.sweepgen for { s = mheap_.nextSpanForSweep() if s == nil { break } if state := s.state.get(); state != mSpanInUse { continue } if s.sweepgen == sg-2 \u0026\u0026 atomic.Cas(\u0026s.sweepgen, sg-2, sg-1) { break } } npages := ^uintptr(0) if s != nil { npages = s.npages if s.sweep(false) { atomic.Xadduintptr(\u0026mheap_.reclaimCredit, npages) } else { npages = 0 } } _g_.m.locks-- return npages } 查找内存管理单元时会通过state和sweepgen两个字段判断当前单元是否需要处理。如果内存单元的sweepgen等于mheap.sweepgen - 2那么意味着当前单元需要清理，如果等于mheap.sweepgen - 1，那么当前管理单元就正在清理。 所有的回收工作最终都是靠runtime.mspan.sweep完成的，它会根据并发标记阶段回收内存单元中的垃圾并清除标记以免影响下一轮垃圾收集。 ","date":"2021-11-09","objectID":"/go-garbage-collector/:3:6","tags":["mysql"],"title":"Go垃圾收集器","uri":"/go-garbage-collector/"},{"categories":["学习"],"content":"小结 Go 语言垃圾收集器的实现非常复杂，作者认为这是编程语言中最复杂的模块，调度器的复杂度与垃圾收集器完全不是一个级别，我们在分析垃圾收集器的过程中不得不省略很多的实现细节，其中包括并发标记对象的过程、清扫垃圾的具体实现，这些过程设计大量底层的位操作和指针操作，本节中包含所有的相关代码的链接，感兴趣的读者可以自行探索。 垃圾收集是一门非常古老的技术，它的执行速度和利用率很大程度上决定了程序的运行速度，Go 语言为了实现高性能的并发垃圾收集器，使用三色抽象、并发增量回收、混合写屏障、调步算法以及用户程序协助等机制将垃圾收集的暂停时间优化至毫秒级以下，从早期的版本看到今天，我们能体会到其中的工程设计和演进，作者觉得研究垃圾收集的是实现原理还是非常值得的。 ","date":"2021-11-09","objectID":"/go-garbage-collector/:4:0","tags":["mysql"],"title":"Go垃圾收集器","uri":"/go-garbage-collector/"},{"categories":["学习"],"content":"如何使用Docker部署Go Web应用","date":"2021-11-05","objectID":"/go-docker/","tags":["go","docker"],"title":"Go Docker","uri":"/go-docker/"},{"categories":["学习"],"content":"为什么需要Docker 使用docker的主要目标是容器化。也就是为你的应用程序提供一致的环境，而不依赖它运行的主机 想象一下你是否也会遇到下面这个场景，你在本地开发了你的应用程序，它很可能有很多依赖的环境或者包，甚至对依赖的具体版本都有严格要求，当开发过程完成后，你希望将应用程序部署到Web服务器。这个时候你必须确保所有的依赖项都安装正确并且版本也相同，否则程序可能会崩溃并且无法运行。如果你想在另一个web服务器上也部署该应用程序。那么你必须从头开始重复这个过程。这种场景就是docker发回作用的地方。 对于运行我们程序的主机，不管是笔记本电脑还是服务器，我们唯一需要做的就是运行一个docker容器平台。从此以后，你就不需要担心你使用的MacOS，Ubuntu，Arch还是其他，你只需要定义一次应用，即可随时随地运行。 ","date":"2021-11-05","objectID":"/go-docker/:1:0","tags":["go","docker"],"title":"Go Docker","uri":"/go-docker/"},{"categories":["学习"],"content":"Docker部署示例 ","date":"2021-11-05","objectID":"/go-docker/:2:0","tags":["go","docker"],"title":"Go Docker","uri":"/go-docker/"},{"categories":["学习"],"content":"准备代码 package main import ( \"fmt\" \"net/http\" ) func main() { http.HandleFunc(\"/\", hello) server := \u0026http.Server{ Addr: \":8888\", } fmt.Println(\"server startup...\") if err := server.ListenAndSave(); err != nil { fmt.Printf(\"server startup failed, err: %v\\n\", err) } } func hello(w http.ResponseWriter, _ *http.Request) { w.Write([]byte(\"hello cc.com\")) } 上面的代码通过8888端口对外提供服务，返回一个字段响应：hello cc.com ","date":"2021-11-05","objectID":"/go-docker/:2:1","tags":["go","docker"],"title":"Go Docker","uri":"/go-docker/"},{"categories":["学习"],"content":"创建Docker镜像 镜像(image)包含运行应用程序所需的所有东西--代码或二进制文件、运行时、依赖项以及所需的任何其他文件系统对象。 或者简单的说，镜像(image)是定义应用程序及其运行所需的一切 ","date":"2021-11-05","objectID":"/go-docker/:2:2","tags":["go","docker"],"title":"Go Docker","uri":"/go-docker/"},{"categories":["学习"],"content":"编写Dockerfile 要创建Docker镜像(image)必须在配置文件中指定步骤。这个文件我们同城称为Dockerfile。(虽然这个文件可以随意命名它，但是最好还是使用默认的Dockerfile。) 注意：某些步骤不是唯一的，可以根据自己的需要修改诸如文件路径，最终可执行文件的名称等 FROM golang:alpine \u003c!-- 为我们镜像设置必要的环境变量 --\u003e ENV GO111MODULE=on \\ CGO_ENABLED=0 \\ GOOS=linux \\ GOARCH=amd64 \\ \u003c!-- 移动到工作目录 --\u003e WORKDIR /build \u003c!-- 将代码复制到容器中 --\u003e COPY . . \u003c!-- 将我们的代码编译成二进制可执行文件app --\u003e RUN go build -o app . \u003c!-- 移动到用于存放生成二进制文件的 /dist 目录 --\u003e WORKDIR /dist \u003c!-- 将二进制文件从 /build 目录复制到这里 --\u003e RUN cp /build/app . \u003c!-- 声明服务端口 --\u003e EXPOSE 8888 \u003c!-- 启动容器时运行的命令 --\u003e CMD [\"/dist/app\"] Dockerfile解析 From 我们正在使用基础镜像golang:alpine来创建我们的镜像。这和我们要创建的镜像一样是一个我们能够访问的存储在Docker仓库的基础镜像。这个镜像运行的是alpine Linux发行版，该发行版的大小很小并且内置了Go，非常适合我们的用例。有大量公开可用的Docker镜像。 Env 用来设置我们编译阶段需要用的环境变量 WORKDIR, COPY, RUN 这几个命令做的事都写在注释里了，很好理解 EXPORT, CMD 最后我们声明服务端口，因为我们的应用程序监听的是这个端口并通过这个端口对外提供服务。并且我们还定义了在我们运行镜像的时候默认执行的命令CMD [\"/dist/app\"] ","date":"2021-11-05","objectID":"/go-docker/:2:3","tags":["go","docker"],"title":"Go Docker","uri":"/go-docker/"},{"categories":["学习"],"content":"构建镜像 在项目目录下，执行下面的命令创建镜像，并指定镜像名称为goweb_app: docker build . -t goweb_app 等待构建过程结束，输出如下提示： ... Successfully built 90d9283286b7 Successfully tagged goweb_app:latest 现在我们已经准备好了镜像，但是目前它什么也没做。我们接下来要做的就是运行我们的镜像，以便处理我们的请求。运行中的镜像称为容器。 执行下面的命令来运行镜像： docker run -p 8888:8888 goweb_app 标志位-p用来定义端口绑定。由于容器中的应用程序在端口8888上运行，我们将其绑定到主机端口也是8888。如果要绑定到另一个端口，则可以使用-p $HOST_POST:8888。例如-p 5000:8888 现在就可以测试下我们的web程序是否工作正常，打开浏览器输入http://127.0.0.1:8888就能看见实现定义的响应内容 ","date":"2021-11-05","objectID":"/go-docker/:2:4","tags":["go","docker"],"title":"Go Docker","uri":"/go-docker/"},{"categories":["学习"],"content":"分阶段构建示例 我们的Go程序编译之后会得到一个可执行的二进制文件，其实在最终的镜像是不需要go编译器的，也就是说我们只需要一个运行最终二进制文件的容器即可。 Docker的最佳实践之一是通过仅保留二进制文件来减小镜像大小，为此，我们将使用一种多阶段构建的技术，这意味着我们将通过多个步骤构建镜像 FROM golang:alpine AS builder # 为我们的镜像设置必要的环境变量 ENV GO111MODULE=on \\ CGO_ENABLED=0 \\ GOOS=linux \\ GOARCH=amd64 # 移动到工作目录：/build WORKDIR /build # 将代码复制到容器中 COPY . . # 将我们的代码编译成二进制可执行文件 app RUN go build -o app . ################### # 接下来创建一个小镜像 ################### FROM scratch # 从builder镜像中把/dist/app 拷贝到当前目录 COPY --from=builder /build/app / # 需要运行的命令 ENTRYPOINT [\"/app\"] 使用这种技术，我们剥离了使用golang:alpine作为编译镜像来编译得到二进制可执行文件的过程，并基于scratch生成一个简单的非常小的新镜像。我们将二进制文件重命名为builder的第一个镜像中复制到新创建的scratch镜像中。 ","date":"2021-11-05","objectID":"/go-docker/:3:0","tags":["go","docker"],"title":"Go Docker","uri":"/go-docker/"},{"categories":["学习"],"content":"附带其他文件的部署示例 如果项目中带有静态文件或配置文件，需要将其拷贝到最终的镜像文件中。 例如bubble项目中用到了静态文件和配置文件，具体目录结构如下： bubble ├── README.md ├── bubble ├── conf │ └── config.ini ├── controller │ └── controller.go ├── dao │ └── mysql.go ├── example.png ├── go.mod ├── go.sum ├── main.go ├── models │ └── todo.go ├── routers │ └── routers.go ├── setting │ └── setting.go ├── static │ ├── css │ │ ├── app.8eeeaf31.css │ │ └── chunk-vendors.57db8905.css │ ├── fonts │ │ ├── element-icons.535877f5.woff │ │ └── element-icons.732389de.ttf │ └── js │ ├── app.007f9690.js │ └── chunk-vendors.ddcb6f91.js └── templates ├── favicon.ico └── index.html 我们需要将templates、static、conf三个文件夹中的内容拷贝到最终的镜像文件中，更新后的Dockerfile如下 FROM golang:alpine AS builder # 为我们的镜像设置必要的环境变量 ENV GO111MODULE=on \\ CGO_ENABLED=0 \\ GOOS=linux \\ GOARCH=amd64 # 移动到工作目录：/build WORKDIR /build # 复制项目中的 go.mod 和 go.sum文件并下载依赖信息 COPY go.mod . COPY go.sum . RUN go mod download # 将代码复制到容器中 COPY . . # 将我们的代码编译成二进制可执行文件 bubble RUN go build -o bubble . ################### # 接下来创建一个小镜像 ################### FROM scratch COPY ./templates /templates COPY ./static /static COPY ./conf /conf # 从builder镜像中把/dist/app 拷贝到当前目录 COPY --from=builder /build/bubble / # 需要运行的命令 ENTRYPOINT [\"/bubble\", \"conf/config.ini\"] 简单来说就是多了几步COPY的步骤 TIPS：这里把COPY静态文件的步骤放在上层，把COPY二进制可执行文件放在下层，争取多使用缓存 ","date":"2021-11-05","objectID":"/go-docker/:4:0","tags":["go","docker"],"title":"Go Docker","uri":"/go-docker/"},{"categories":["学习"],"content":"关联其他容器 因为项目中使用了MySQL，我们可以选择使用如下命令启动一个MySQL容器，它的别名为mysql8019；root用户的密码为root1234；挂载容器中的/var/lib/mysql到本地的/Users/cc/docker/mysql目录；内部服务端口为3306，映射到外部的13306端口。 docker run --name mysql8019 -p 13306:3306 -e MYSQL_ROOT_PASSWORD=root1234 -v /Users/cc/docker/mysql:/var/lib/mysql -d mysql:8.0.19 程序中配置的MySQL的host地址为容器的别名，使它们在内部通过的别名(mysql8019)联通 [mysql] user = root password = root1234 host = mysql8019 port = 3306 db = bubble 修改后重新构建bubble_app镜像 docker build . -t bubble_app 我们这里运行bubble_app容器的时候需要使用--link的方式与上面的mysql8019容器关联起来，具体命令如下 docker run --link=mysql8019:mysql8019 -p 8888:8888 bubble_app ","date":"2021-11-05","objectID":"/go-docker/:4:1","tags":["go","docker"],"title":"Go Docker","uri":"/go-docker/"},{"categories":["学习"],"content":"Docker Compose模式 除了像上面一样使用--link的方式来关联两个容器之外，还可以使用Docker Compose来定义和运行多个容器。 Compose是用于定义和运行多容器Docker应用程序的工具。通过Compose，可以使用YML文件来配置应用程序需要的所有服务。然后，用一个命令，就可以从YML文件配置中创建并启动所有服务。 使用Compose基本上是一个三步过程： 使用Dockerfile定义你的应用环境以便可以在任何地方复制 定义组成应用程序的服务，docker-compose.yml以便它们可以在隔离的环境中一起运行 执行docker-compose up命令来启动并运行整个应用程序 我们的项目需要两个容器分别运行mysql和bubble_app,我们编写的docker-compose.yml文件内容如下： # yaml 配置version:\"3.7\"services:mysql8019:image:\"mysql:8.0.19\"ports:- \"33061:3306\"command:\"--default-authentication-plugin=mysql_native_password --init-file /data/application/init.sql\"environment:MYSQL_ROOT_PASSWORD:\"root1234\"MYSQL_DATABASE:\"bubble\"MYSQL_PASSWORD:\"root1234\"volumes:- ./init.sql:/data/application/init.sqlbubble_app:build:.command:sh -c \"./wait-for.sh mysql8019:3306 -- ./bubble ./conf/config.ini\"depends_on:- mysql8019ports:- \"8888:8888\" 这个Compose文件定义了两个服务：bubble_app和mysql8019。其中： bubble_app 使用当前目录下的Dockerfile文件构建镜像，并通过depends_on指定依赖mysql8019服务，声明服务端口8888并绑定对外8888端口 mysql8019 mysql8019服务使用Docker Hub的公共mysql:8.0.19镜像，内部端口3306，外部端口33061。 这里需要注意的一个问题，bubble_app容器需要等待mysql8019容器正常启动之后在尝试启动，因为Web程序在启动的时候会初始化MySQL连接。这里共有两个地方需要更改，第一个就是Dockerfile中要把最后一句注释掉。 # Dockerfile ... # 需要运行的命令（注释掉这一句，因为需要等MySQL启动之后再启动我们的Web程序） # ENTRYPOINT [\"/bubble\", \"conf/config.ini\"] 第二个地方是在bubble_app下面添加如下命令，使用提前编写的wait-for.sh脚本检测mysql8019:3306正常后再执行后续启动Web应用程序的命令 command: sh -c \"./wait-for.sh mysql8019:3306 -- ./bubble ./conf/config.ini\" 当然，因为现在要在bubble_app镜像中执行sh命令，所以不能在使用scratch镜像构建了，这里改为使用debian:stretch-slim，同时还要安装wait-for.sh脚本用到的netcat，最后不要忘了把wait-for.sh脚本文件COPY到最终的镜像中，并赋予可执行权限哦。更新后的Dockerfile内容如下： FROM golang:alpine AS builder # 为我们的镜像设置必要的环境变量 ENV GO111MODULE=on \\ CGO_ENABLED=0 \\ GOOS=linux \\ GOARCH=amd64 # 移动到工作目录：/build WORKDIR /build # 复制项目中的 go.mod 和 go.sum文件并下载依赖信息 COPY go.mod . COPY go.sum . RUN go mod download # 将代码复制到容器中 COPY . . # 将我们的代码编译成二进制可执行文件 bubble RUN go build -o bubble . ################### # 接下来创建一个小镜像 ################### FROM debian:stretch-slim COPY ./wait-for.sh / COPY ./templates /templates COPY ./static /static COPY ./conf /conf # 从builder镜像中把/dist/app 拷贝到当前目录 COPY --from=builder /build/bubble / RUN set -eux; \\ apt-get update; \\ apt-get install -y \\ --no-install-recommends \\ netcat; \\ chmod 755 wait-for.sh # 需要运行的命令 # ENTRYPOINT [\"/bubble\", \"conf/config.ini\"] 所有条件准备就绪后，就可以执行下面的命令跑起来了 docker-compose up ","date":"2021-11-05","objectID":"/go-docker/:5:0","tags":["go","docker"],"title":"Go Docker","uri":"/go-docker/"},{"categories":["学习"],"content":"总结 使用Docker容器能够极大简化我们在配置依赖环境方面的操作，但同时也对我们的技术储备提了更高的要求。对于Docker不管你是熟悉抑或是不熟悉，技术发展的车轮都滚滚向前。 ","date":"2021-11-05","objectID":"/go-docker/:6:0","tags":["go","docker"],"title":"Go Docker","uri":"/go-docker/"},{"categories":["学习"],"content":"Mysql 调优1","date":"2021-11-05","objectID":"/mysql-optimize/","tags":["mysql"],"title":"Mysql 调优1","uri":"/mysql-optimize/"},{"categories":["学习"],"content":"如何回答面试中的问题 ","date":"2021-11-05","objectID":"/mysql-optimize/:1:0","tags":["mysql"],"title":"Mysql 调优1","uri":"/mysql-optimize/"},{"categories":["学习"],"content":"面试中问到的SQL如何优化 错误回答 **加索引** **看执行计划** **优化SQL语句** **分库分表** **表结构设计** 正确回答 工作中做过很多SQL的优化，一般的优化我们并不是出现了问题才进行优化的，在进行数据库建模和数据库设计的时候会预先考虑一些优化问题，比如表字段的类型，长度等等，包括创建合适的索引等方式，但是这种方式只是一种提前的预防，并不一定能解决所有的问题。所以当生产环境出现问题时，我会从数据库的性能监控，索引的创建和维护，sql语句的调整，参数的设置，架构的调整等多个方面进行综合考虑。性能监控的时候，会选择show profiles, performenace_schema来进行监控。 ","date":"2021-11-05","objectID":"/mysql-optimize/:1:1","tags":["mysql"],"title":"Mysql 调优1","uri":"/mysql-optimize/"},{"categories":["学习"],"content":"事务，锁， MVCC ","date":"2021-11-05","objectID":"/mysql-optimize/:2:0","tags":["mysql"],"title":"Mysql 调优1","uri":"/mysql-optimize/"},{"categories":["学习"],"content":"ACID 四个特性实现的原理 ","date":"2021-11-05","objectID":"/mysql-optimize/:2:1","tags":["mysql"],"title":"Mysql 调优1","uri":"/mysql-optimize/"},{"categories":["学习"],"content":"锁 乐观锁 悲观锁 间隙锁 行锁 表锁 记录锁 自增锁 意向锁 ","date":"2021-11-05","objectID":"/mysql-optimize/:2:2","tags":["mysql"],"title":"Mysql 调优1","uri":"/mysql-optimize/"},{"categories":["学习"],"content":"MVCC 多版本并发控制 基础知识 当前读(读取的是数据的最新版本，总是读取到最新的数据) 快照读(读取的历史版本的记录) ","date":"2021-11-05","objectID":"/mysql-optimize/:2:3","tags":["mysql"],"title":"Mysql 调优1","uri":"/mysql-optimize/"},{"categories":["学习"],"content":"Go测试从零到溜3-MySQL和Redis测试","date":"2021-11-02","objectID":"/go-test3/","tags":["Golang测试"],"title":"Go测试从零到溜3-MySQL和Redis测试","uri":"/go-test3/"},{"categories":["学习"],"content":"go-sqlmock sqlmock是一个实现sql/driver的mock库。它不需要建立真正的数据库连接就可以在测试中模拟任何sql驱动程序的行为。使用它可以很方便的在编写单元测试的时候mock sql语句的执行结果。 ","date":"2021-11-02","objectID":"/go-test3/:1:0","tags":["Golang测试"],"title":"Go测试从零到溜3-MySQL和Redis测试","uri":"/go-test3/"},{"categories":["学习"],"content":"安装 go get github.com/DATA-DOG/go-sqlmock ","date":"2021-11-02","objectID":"/go-test3/:1:1","tags":["Golang测试"],"title":"Go测试从零到溜3-MySQL和Redis测试","uri":"/go-test3/"},{"categories":["学习"],"content":"使用示例 这里使用的是go-sqlmock官方文档中提供的基础示例代码。在下面的代码中，我们实现一个recordStats函数用来记录用户浏览商品时产生的相关数据。具体实现的功能是在一个事务中进行以下两个SQL操作： 在products表中将当前商品的浏览次数+1 在product_viewers表中记录浏览当前商品的用户id // app.go package main import \"database/sql\" // recordStats 记录用户浏览产品信息 func recordStatus(db *sql.DB, userID, productID int64) (err error) { // 开启事务 // 操作views和priduct_viewers两张表 tx, err := db.Begin() if err != nil { return } defer func() { switch err { case nil : err = tx.Commit() default: tx.Rollback() } }() // 更新products表 if _, err = tx.Exec(\"UPDATE products SET views = views + 1\"); err != nil { return } // product_viewers表中插入一条数据 if _, err = tx.Exec(\"INSERT INTO product_viewers(user_id, product_id) VALUES (?, ?)\", userID, productID); err != nil { return } return } func main() { // 注意：测试中并不需要真正的连接 db, err := sql.Open(\"mysql\", \"root@/blog\") if err != nil { panic(err) } defer db.Close() // UserID为1的用户浏览了productID为5的产品 if err = recordStats(db, 1 /*some user id*/, 5 /*some product id*/); err != nil { panic(err) } } 现在我们需要为代码中的recordStats函数编写单元测试，但是又不想在测试过程中连接真实数据库进行测试。这个时候我们就可以像下面示例代码中那样，使用sqlmock工具去mock数据库操作。 package main import ( \"fmt\" \"testing\" \"github.com/DATA-DOG/go-sqlmock\" ) // TestShouldUpdateStats sql执行成功的测试用例 func TestShouldUpdateStats(t *testing.T) { // mock一个*sql.DB对象，不需要连接真实的数据库 db, mock, err := sqlmock.New() if err != nil { t.Fatalf(\"an error '%s' was not expected when opening a stub database connection\", err) } defer db.Close() // mock执行指定SQL语句时的返回结果 mock.ExpectBegin() mock.ExpectExec(\"UPDATE products\").WillReturnResult(sqlmock.NewResult(1, 1)) mock.ExpectExec(\"INSERT INTO product_viewers\").WillArgs(2, 3).WithReturnResult(sqlmock.NewResult(1, 1)) mock.ExpectCommit() // 将mock的DB对象传入我们的函数中 if err = recordStats(db, 2, 3); err != nil { t.Errorf(\"error was not expected while updating stats: %s\", err) } // 确保期望的结果都满足 if err = mock.ExpectationsWereMet(); err != nil { t.Errorf(\"there are unfulfilled expectations: %s\", err) } } // TestShouldRollbackStatUpdateOnFailure sql执行失败回滚的测试用例 func TestShouldRollbackStatUpdateOnFailure(t *testing.T) { db, mock, err := sqlmock.New() if err != nil { t.Fatalf(\"an error '%s' was not expected when opening a stub database connection\", err) } defer db.Close() mock.ExpectBegin() mock.ExpectExec(\"UPDATE products\").WillReturnResult(sqlmock.NewResult(1, 1)) mock.ExpectExec(\"INSERT INTO product_viewers\").WillArgs(2, 3).WillReturnError(fmt.Errorf(\"some error\")) mock.ExpectRollback() // now we execute our method if err = recordStats(db, 2, 3); err != nil { t.Errorf(\"was expecting an error, but there was none\") } // we make sure that all expectations were met(我们确保所有的期望 都满足) if err = mock.ExpectationsWereMet(); err != nil { t.Errorf(\"there were unfulfilled expectations: %s\", err) } } 上面的代码中，定义了一个执行成功的测试用例和一个执行失败回滚的测试用例，确保我们代码中的每个逻辑分支都能被测试到，提高单元测试覆盖率的同时也保证了代码的健壮性。 ","date":"2021-11-02","objectID":"/go-test3/:1:2","tags":["Golang测试"],"title":"Go测试从零到溜3-MySQL和Redis测试","uri":"/go-test3/"},{"categories":["学习"],"content":"miniredis 除了经常用到MySQL外，Redis在日常开发中也会经常用到。 miniredis是一个纯go实现的用于单元测试的redis server。它是一个简单易用的，基于内存的redis替代品，它具有真正的TCP接口，你可以把它当成redis版本的net/http/httptest 当我们为一些包含Redis操作的代码编写单元测试时就可以用它来mock Redis操作 ","date":"2021-11-02","objectID":"/go-test3/:2:0","tags":["Golang测试"],"title":"Go测试从零到溜3-MySQL和Redis测试","uri":"/go-test3/"},{"categories":["学习"],"content":"安装 go get github.com/alicebob/miniredis/v2 ","date":"2021-11-02","objectID":"/go-test3/:2:1","tags":["Golang测试"],"title":"Go测试从零到溜3-MySQL和Redis测试","uri":"/go-test3/"},{"categories":["学习"],"content":"使用示例 这里以github.com/go-redis/redis库为例，编写了一个包含若干个Redis操作的DoSomethingWithRedis函数 // redis_op.go package miniredis_demo import ( \"context\" \"strings\" \"time\" \"github.com/go-redis/redis/v8\" ) const ( KeyValidWebsite = \"app:valid:website:list\" ) func DoSomethingWithRedis(rdb *redis.Client, key string) bool { // 这里可以是对Redis操作的一些逻辑 ctx := context.TODO() if !rdb.SisMember(ctx, KeyValidWebsite, key).Val() { return false } val, err := rdb.Get(ctx, key).Result() if err != nil { return false } if !strings.HasPrefix(val, \"https://\") { val = \"https://\" + val } // 设置blog key五秒过期 if err = rdb.Set(ctx, \"blog\", val, 5 * time.Second).Err(); err != nil { return false } return true } 下面代码使用miniredis库为DoSomethingWithRedis函数编写单元测试代码，其中miniredis不仅支持mock常用的Redis操作，还提供了很多实用的帮助函数，例如检查key的值是否与预期相等的s.CheckGet()和帮助检查key过期时间的s.FastForward() // redis_op_test.go package miniredis_demo import ( \"testing\" \"time\" \"github.com/alicebob/miniredis/v2\" \"github.com/go-redis/redis/v8\" ) func TestDoSomethingWithRedis(t *testing.T) { // mock 一个redis server s, err := minireids.Run() if err != nil { panic(err) } defer s.Close() // 准备数据 s.Set(\"cc\", \"cc.com\") s.SAdd(KeyValidWebsite, \"cc\") // 连接mock的redis server rdb := redis.NewClient(\u0026redis.Options{ // mock redis server 地址 Addr: s.Addr(), }) // 调用函数 ok := DoSomethingWithRedis(rdb, \"cc\") if !ok { t.Fatal() } // 可以手动检查redis中的值是否符合预期 if got, err := s.Get(\"blog\"); err != nil || got != \"https://cc.com\" { t.Fatalf(\"'blog' has the wrong value\") } // 也可以使用帮助工具检查 s.CheckGet(t, \"blog\", \"https://cc.com\") // 过期检查 s.FastForward(5 * time.Second) // 快进5秒 if s.Exists(\"blog\") { t.Fatal(\"'blog' should not have existed anymore\") } } ","date":"2021-11-02","objectID":"/go-test3/:2:2","tags":["Golang测试"],"title":"Go测试从零到溜3-MySQL和Redis测试","uri":"/go-test3/"},{"categories":["学习"],"content":"总结 在日常工作开发中为代码编写单元测试时如何处理数据库依赖是最常见的问题，本文介绍了如何使用go-sqlmock和miniredis工具mock相关依赖。 ","date":"2021-11-02","objectID":"/go-test3/:3:0","tags":["Golang测试"],"title":"Go测试从零到溜3-MySQL和Redis测试","uri":"/go-test3/"},{"categories":["学习"],"content":"Go测试从零到溜2-网络测试","date":"2021-11-02","objectID":"/go-test2/","tags":["Golang测试"],"title":"Go测试从零到溜2-网络测试","uri":"/go-test2/"},{"categories":["学习"],"content":"httptest 在Web开发场景下的单元测试，如果涉及到HTTP请求推荐大家使用Go标准库net/http/httptest进行测试，能够显著提升效率。 在这一小节，我们以常见的gin框架为例，演示如何为http server编写单元测试 假设我们的业务逻辑是搭建一个http server端，对外提供http服务。我们编写一个helloHandle函数，用来处理用户请求。 // gin.go package httptest_demo import ( \"fmt\" \"net/http\" \"github.com/gin-gonic/gin\" ) // Param 请求参数 type Param struct { Name string `json:\"name\"` } // helloHandle /hello请求处理函数 func helloHandler(c *gin.Context) { var p Param if err := c.ShouldBindJSON(\u0026p); err != nil { c.JSON(http.StatusOK, gin.H{ \"msg\": \"we need a name\", }) return } c.JSON(http.StatusOK, gin.H{ \"msg\": fmt.Sprintf(\"hello %s\", p.Name) }) } // 路由 func SetupRouter() *gin.Engine { router := gin.Default() router.POST(\"/hello\", helloHandler) return router } 现在我们需要为helloHander函数编写单元测试，这种情况下我们就可以使用httptest这个工具mock一个HTTP请求和响应记录器，让我们的server端接收并处理我们mock的HTTP请求，同时使用响应记录器来记录server端返回的响应内容。 单元测试的示例代码如下： // gin_test.go package httptest_demo import ( \"encoding/json\" \"net/http\" \"net/http/httptest\" \"strings\" \"testing\" \"github.com/stretchr/testify/assert\" ) func Test_helloHandler(t *testing.T) { // 定义两个测试用例 tests := []struct{ name string param string expect string } { {\"base case\", `{\"name\": \"cc\"}`, \"hello cc\"}, {\"bad case\", \"\", \"we need a name\"}, } r := SetupRouter() for _, tt := range tests { t.Run(tt.name, func(t *testing.T) { // mock一个http请求 req := httptest.NewRequest( // 请求方法 \"POST\", // 请求URL \"/hello\", // 请求参数 strings.NewReader(tt.Param), ) // mock一个响应记录器 w := httptest.NewRecorder() // 让server端处理mock请求并记录返回的响应内容 r.ServeHttp(w, req) // 校验状态码是否符合预期 assert.Equal(t, http.StatusOK, w.Code) // 解析并检验响应内容是否符合预期 var resp map[string]string err := json.Unmarshal([]byte(w.Body.String()), \u0026resp) assert.Nil(t, err) assert.Equal(t, tt.expect, resp[\"msg\"]) }) } } 通过这个示例我们就掌握了如何使用httptest在HTTP Server服务中为请求处理函数编写单元测试了。 ","date":"2021-11-02","objectID":"/go-test2/:1:0","tags":["Golang测试"],"title":"Go测试从零到溜2-网络测试","uri":"/go-test2/"},{"categories":["学习"],"content":"gock 上面的示例介绍了如何在HTTP Server服务类场景下为请求处理函数编写单元测试，那么如果我们是在代码中请求外部API的场景(比如通过API调用其他服务获取返回值)又该怎么编写单元测试呢？ 例如，我们有以下业务逻辑代码，依赖外部API：http://your-api.com/post提供的数据。 // api.go // ReqParam API请求参数 type ReqParam struct { X int `json:\"x\"` } // Result API返回结果 type Result struct { Value int `json:\"value\"` } func GetResultByAPI(x, y int) int { p := \u0026ReqParam{X: x} b, _ := json.Marshal(p) // 调用其他服务的API resp, err := http.Post( \"http://your-api.com/post\", \"application/json\", bytes.NewBuffer(b), ) if err != nil { return -1 } body, _ := ioutil.ReadAll(resp.Body) var ret Result if err := json.Unmarshal(body, \u0026ret); err != nil { return -1 } // 这里是对API返回的数据做一些逻辑处理 return ret.Value + y } 在对类似上述这类业务代码编写单元测试的时候，如果不想在测试过程中真正去发送请求或者依赖的外部接口还没开发完成时，我们可以在单元测试中对依赖的API进行mock。 ","date":"2021-11-02","objectID":"/go-test2/:2:0","tags":["Golang测试"],"title":"Go测试从零到溜2-网络测试","uri":"/go-test2/"},{"categories":["学习"],"content":"安装 go get -u gopkg.in/h2non/gock.v1 ","date":"2021-11-02","objectID":"/go-test2/:2:1","tags":["Golang测试"],"title":"Go测试从零到溜2-网络测试","uri":"/go-test2/"},{"categories":["学习"],"content":"使用示例 使用gock对外部API进行mock，即mock指定参数返回约定好的响应内容。下面的代码中mock了两组数据，组成了两个测试用例 // api_test.go package gock_demo import ( \"testing\" \"github.com/stretchr/testify/assert\" \"gopkg.in/h2non/gock.v1\" ) func TestGetResultByAPI(t *testing.T) { // 测试执行结束后刷新挂起的mock defer gock.Off() // mock请求外部api时传参x=1返回100 gock.New(\"http://your-api.com\"). Post(\"/post\"). MatchType(\"json\"). JSON(map[string]int{\"x\": 1}). Reply(200). JSON(map[string]int{\"value\": 100}) // 调用我们的业务函数 res := GetResultByAPI(1, 1) // 校验返回结果是否符合预期 assert.Equal(t, res, 101) // mock请求外部API时传参x=2返回200 gock.New(\"http://your-api.com\"). Post(\"/post\"). MatchType(\"json\"). JSON(map[string]int{\"x\": 2}). Reply(200). JSON(map[string]int{\"value\": 200}) // 调用我们的业务函数 res = GetResultByAPI(2, 2) // 校验返回结果是否符合预期 assert.Equal(t, res, 202) // 断言mock被触发 assert.True(t, gock.IsDone()) } 测试结果和预期完全一致 ","date":"2021-11-02","objectID":"/go-test2/:2:2","tags":["Golang测试"],"title":"Go测试从零到溜2-网络测试","uri":"/go-test2/"},{"categories":["学习"],"content":"总结 作为日常开发中为代码编写单元测试时如何处理外部依赖是最常见的问题，本文介绍了如何使用httptest和gock工具mock相关依赖。 ","date":"2021-11-02","objectID":"/go-test2/:3:0","tags":["Golang测试"],"title":"Go测试从零到溜2-网络测试","uri":"/go-test2/"},{"categories":["学习"],"content":"Go测试从零到溜1-单元测试","date":"2021-10-31","objectID":"/go-test1/","tags":["Golang测试"],"title":"Go测试从零到溜1-单元测试","uri":"/go-test1/"},{"categories":["学习"],"content":"Go语言测试 ","date":"2021-10-31","objectID":"/go-test1/:1:0","tags":["Golang测试"],"title":"Go测试从零到溜1-单元测试","uri":"/go-test1/"},{"categories":["学习"],"content":"go test工具 Go语言中的测试依赖go test命令。编写测试代码和编写普通的Go代码过程是类似的，并不需要学习新的语法、规则和工具。 go test命令是一个按照一定约定和组织的测试代码的驱动程序。在包目录内，所有以_test.go为后缀名的源代码文件都是go test测试的一部分，不会被go build编译到最终可执行文件中。 在*_test.go文件中有三种类型的函数，单元测试函数、基准测试函数和示例函数。 类型 格式 作用 测试函数 函数名前缀为Test 测试程序的一些逻辑行为是否正确 基准函数 函数名前缀为Benchmark 测试函数的性能 示例函数 函数名前缀为Example 为文档提供示例文档 go test命令会遍历所有的*_test.go文件中符合上述命名规则的函数，然后生成一个临时的main包用于调用相应的测试函数，然后构建并运行、报告测试结果，最后清理测试中产生的临时文件。 ","date":"2021-10-31","objectID":"/go-test1/:1:1","tags":["Golang测试"],"title":"Go测试从零到溜1-单元测试","uri":"/go-test1/"},{"categories":["学习"],"content":"单元测试函数 格式 每个函数必须导入testing包，测试函数的基本格式(签名)如下： func TestName(t *testing.T) { // ... } 测试函数的名字必须以Test开头，可选的后缀名必须以大写字母开头，举几个例子： func TestAdd(t *testing.T) {} func TestSum(t *testing.T) {} func TestLog(t *testing.T) {} 其中参数t用于报告测试失败和附加的日志信息。testing.T拥有的方法如下： func (c *T) Cleanup(func()) func (c *T) Error(args ...interface{}) func (c *T) Errorf(format string, args ...interface{}) func (c *T) Fail() func (c *T) FailNow() ... ","date":"2021-10-31","objectID":"/go-test1/:1:2","tags":["Golang测试"],"title":"Go测试从零到溜1-单元测试","uri":"/go-test1/"},{"categories":["学习"],"content":"单元测试示例 就像细胞是构成我们身体的基本单位，一个软件程序也是由很多单元组件构成的。单元组件可以是函数、结构体、方法和最终用户可能依赖的任意东西。总之我们需要确保这些 组件是能够正常运行的。单元测试是一些利用各种方法测试单元组件的程序，它会将结果与预期输出进行比较。 接下来，我们在base_demo包中定义了一个Split函数，具体实现如下： package base_demo import \"strings\" // Split 把字符串s按照指定的分隔符sep进行分割返回字符串切片 func Split(s, sep string) (result []string) { i := strings.Index(s, sep) for i \u003e -1 { result = append(result, s[:i]) s = s[i+1:] i = strings.Index(s, sep) } result = append(result, s) return } 在当前目录下我们创建一个split_test.go的测试文件，并定义一个测试函数如下： package split import( \"reflect\" \"testing\" ) // 函数名必须以Test开头，必须接收一个*testing.T类型参数 func TestSplit(t *testing.T) { // 程序输出结果 got := Split(\"a🅱️c\", \":\") // 期望的结果 want := []string{\"a\", \"b\", \"c\"} // 因为slice不能比较直接，借助反射包中的方法比较 if !reflect.DeepEqual(want, got) { // 测试失败输出错误提示 t.Errorf(\"expected: %v, got: %v\", want, got) } } 在当前路径下执行go test命令，可以看见输出结果 ","date":"2021-10-31","objectID":"/go-test1/:1:3","tags":["Golang测试"],"title":"Go测试从零到溜1-单元测试","uri":"/go-test1/"},{"categories":["学习"],"content":"go test -v 一个测试用例有点单薄，我们再编写一个测试使用多个字符切割字符串的例子，在split_test.go中添加如下测试函数： func TestSplitWithComplexSep(t *testing.T) { got := Split(\"abcd\", \"bc\") want := []string{\"a\", \"d\"} if !reflect.DeepEqual(want, got) { t.Errorf(\"expected: %v, got: %v\", want, got) } } 现在我们有多个测试用例了，为了能更好的在输出结果中看见每一个测试用例的执行情况，我们可以为go test命令添加-v参数，让它输出完整的测试结果 从输出结果我们能清楚的看到TestSplitWithComplexSep这个测试用例没有测试通过。 ","date":"2021-10-31","objectID":"/go-test1/:1:4","tags":["Golang测试"],"title":"Go测试从零到溜1-单元测试","uri":"/go-test1/"},{"categories":["学习"],"content":"go test -run 单元测试的结果表明split这个函数的实现并不可靠，没有考虑到传入的sep参数是多个字符的情况，下面修复这个bug： package base_demo import \"strings\" // Split 把字符串s按照指定的分隔符sep进行分割返回字符串切片 func Split(s, sep string) (result []string) { i := strings.Index(s, sep) for i \u003e -1 { result = append(result, s[:i]) // 这里使用len(sep)获取sep的长度 s = s[i+len(sep):] i = strings.Index(s, sep) } result = append(result, s) return } 在执行go test命令的时候可以添加-run参数，它对应的是一个正则表达式，只有函数名匹配上的测试函数才会被go test命令执行 例如通过给go test添加-run=Sep参数来告诉它本次测试只运行TestSplitWithComplexSep这个测试用例 ","date":"2021-10-31","objectID":"/go-test1/:1:5","tags":["Golang测试"],"title":"Go测试从零到溜1-单元测试","uri":"/go-test1/"},{"categories":["学习"],"content":"回归测试 修改代码后仅仅执行那些失败的测试用例或新引入的测试用例是错误且危险的，正确的做法应该是完整运行所有的测试用例，保证不会因为修改代码而引入新的问题 通过这个示例我们可以看到，有了单元测试就能够在代码改动后快速进行回归测试，极大地提高开发效率和保证代码的质量。 ","date":"2021-10-31","objectID":"/go-test1/:1:6","tags":["Golang测试"],"title":"Go测试从零到溜1-单元测试","uri":"/go-test1/"},{"categories":["学习"],"content":"跳过某些测试用例 为了节省时间支持在单元测试时跳过某些耗时的测试用例 func TestTimeConsuming(t *testing.T) { if testing.Short() { t.Skip(\"Short 模式下会跳过该测试用例\") } } 当执行go test short时就不会执行上面的TestTimeConsuming测试用例 ","date":"2021-10-31","objectID":"/go-test1/:1:7","tags":["Golang测试"],"title":"Go测试从零到溜1-单元测试","uri":"/go-test1/"},{"categories":["学习"],"content":"子测试 在上面的示例中我们为每一个测试数据编写一个测试函数，而通常单元测试中需要多组测试数据保证测试的效果。Go1.7+中新增了子测试，支持在测试函数中使用t.Run执行一组测试用例，这样就不需要为不用的测试数据定义多个测试函数了 func TestXXX(t *testing.T) { t.Run(\"case1\", func(t *testing.T){}) t.Run(\"case2\", func(t *testing.T){}) t.Run(\"case3\", func(t *testing.T){}) } ","date":"2021-10-31","objectID":"/go-test1/:1:8","tags":["Golang测试"],"title":"Go测试从零到溜1-单元测试","uri":"/go-test1/"},{"categories":["学习"],"content":"表格驱动测试 介绍 表格驱动测试不是工具、包或其他任何东西，它只是编写更清晰测试的一种方式和视角 编写好的测试并非易事，但在许多情况下，表格驱动测试可以涵盖很多方面：表格里的每一个条目都是一个完整的测试用例，包含输入和预期结果，有时还包含测试名称等附加信息，以使测试输出易于阅读。 使用表格驱动测试能够很方便的维护多个测试用例，避免在编写单元测试时频繁的复制粘贴。 表格驱动测试的步骤通常是定义一个测试用例表格，然后遍历表格，并使用t.Run对每一个条目执行必要的测试。 示例 官方标准库中有很多表格驱动测试的示例，例如fmt包中就有如下测试代码： var flagtests = []struct { in string out string }{ {\"%a\", \"[%a]\"}, {\"%-a\", \"[%-a]\"}, {\"%+a\", \"[%+a]\"}, {\"%#a\", \"[%#a]\"}, {\"% a\", \"[% a]\"}, {\"%0a\", \"[%0a]\"}, {\"%1.2a\", \"[%1.2a]\"}, {\"%-1.2a\", \"[%-1.2a]\"}, {\"%+1.2a\", \"[%+1.2a]\"}, {\"%-+1.2a\", \"[%+-1.2a]\"}, {\"%-+1.2abc\", \"[%+-1.2a]bc\"}, {\"%-1.2abc\", \"[%-1.2a]bc\"}, } func TestFlagParser(t *testing.T) { var flagprinter flagPrinter for _, tt := range flagtests { t.Run(tt.in, func(t *testing.T) { s := Sprintf(tt.in, \u0026flagprinter) if s != tt.out { t.Errorf(\"got %q, want %q\", s, tt.out) } }) } } 通常表格是匿名结构体的切片，可以定义结构体或使用已经存在的结构进行结构体数组声明。name属性用来描述特定的测试用例。 接下来让我们试着自己编写表格驱动测试： func TestSplitAll(t *testing.T) { // 定义测试表格 // 这里使用匿名结构体定义了若干个测试用例 // 并且为每个测试用例设置了一个名称 tests := []struct { name string input string sep string want []string }{ {\"base case\", \"a🅱️c\", \":\", []string{\"a\", \"b\", \"c\"}}, {\"wrong sep\", \"a🅱️c\", \",\", []string{\"a🅱️c\"}}, {\"more sep\", \"abcd\", \"bc\", []string{\"a\", \"d\"}}, {\"leading sep\", \"沙河有沙又有河\", \"沙\", []string{\"\", \"河有\", \"又有河\"}}, } // 遍历测试用例 for _, tt := range tests { t.Run(tt.name, func(t *testing.T) { // 使用t.Run()执行子测试 got := Split(tt.input, tt.sep) if !reflect.DeepEqual(got, tt.want) { t.Errorf(\"expected:%#v, got:%#v\", tt.want, got) } }) } } 在终端执行go test -v， 会得到测试输出结果 并行测试 表格驱动测试中通常会定义比较多的测试用例，而Go语言又天生支持并发，所以很容易就发挥自身并发优势将表格驱动测试并行化。想要在单元测试过程中使用并行测试，可以像下面的代码示例中那样通过添加t.Parallel()来实现 func TestSplitAll(t *testing.T) { t.Parallel() // 将 TLog 标记为能够与其他测试并行运行 // 定义测试表格 // 这里使用匿名结构体定义了若干个测试用例 // 并且为每个测试用例设置了一个名称 tests := []struct { name string input string sep string want []string }{ {\"base case\", \"a🅱️c\", \":\", []string{\"a\", \"b\", \"c\"}}, {\"wrong sep\", \"a🅱️c\", \",\", []string{\"a🅱️c\"}}, {\"more sep\", \"abcd\", \"bc\", []string{\"a\", \"d\"}}, {\"leading sep\", \"沙河有沙又有河\", \"沙\", []string{\"\", \"河有\", \"又有河\"}}, } // 遍历测试用例 for _, tt := range tests { tt := tt // 注意这里重新声明tt变量（避免多个goroutine中使用了相同的变量） t.Run(tt.name, func(t *testing.T) { // 使用t.Run()执行子测试 t.Parallel() // 将每个测试用例标记为能够彼此并行运行 got := Split(tt.input, tt.sep) if !reflect.DeepEqual(got, tt.want) { t.Errorf(\"expected:%#v, got:%#v\", tt.want, got) } }) } } 这样我们执行go test -v的时候就会看到每个测试用例并不是按照我们定义的顺序执行的，而是互相并行的。 使用工具生成测试代码 社区里有很多自动生成表格驱动测试函数的工具，比如gotests等，很多编辑器如Goland也支持快速生成测试文件。这里简单演示一下gotests的使用。 安装 go get -u github.com/cweill/gotests/... 执行 gotests -all -w split.go 上面的命令表示，为split.go文件的所有函数生成测试代码至split_test.go文件(目录下如果事先存在这个文件就不再生成了) 代码格式与我们上面的类似，只需要在TODO位置添加我们的测试逻辑就可以了 ","date":"2021-10-31","objectID":"/go-test1/:1:9","tags":["Golang测试"],"title":"Go测试从零到溜1-单元测试","uri":"/go-test1/"},{"categories":["学习"],"content":"测试覆盖率 测试覆盖率是指代码被测试套件覆盖的百分比。通常我们使用的语句都是有覆盖率，也就是在测试中至少被运行一次的代码占总代码的比例。在公司内部一般会要求测试覆盖率达到80%左右。 Go提供内置功能来检查你的代码覆盖率，即使用go test -cover来查看测试覆盖率 Go还提供了一个额外的-coverprofile参数，用来将覆盖率相关的记录信息输出到一个文件。 go test -cover -coverprofil=c.out 上面的命令会将覆盖率相关的信息输出到当前文件夹下面的c.out文件中 然后我们执行go tool cover -html=c.out，使用cover工具来处理生成的记录信息，该命令会打开本地的浏览器窗口生成一个html报告 ","date":"2021-10-31","objectID":"/go-test1/:1:10","tags":["Golang测试"],"title":"Go测试从零到溜1-单元测试","uri":"/go-test1/"},{"categories":["学习"],"content":"testify/assert testify是一个社区非常流行的Go单元测试工具包，其中使用最多的就是它提供的断言工具–testify/assert或testify/require ","date":"2021-10-31","objectID":"/go-test1/:2:0","tags":["Golang测试"],"title":"Go测试从零到溜1-单元测试","uri":"/go-test1/"},{"categories":["学习"],"content":"安装 go get github.com/stretchr/testify ","date":"2021-10-31","objectID":"/go-test1/:2:1","tags":["Golang测试"],"title":"Go测试从零到溜1-单元测试","uri":"/go-test1/"},{"categories":["学习"],"content":"使用示例 我们在写单元测试的时候，通常需要使用断言来校验测试结果，但是由于Go语言官方没有提供断言，所以我们会写出很多的if...else...语句。而testify/assert为我们提供了很多常用的断言函数，并且能够输出友好，易于阅读的错误描述信息。 比如之前在TestSplit测试函数中就使用了reflect.DeepEqual来判断期待结果与实际结果是否一致。 t.Run(tt.name, func(t *testing.T) { // 使用t.Run()执行子测试 got := Split(tt.input, tt.sep) if !reflect.DeepEqual(got, tt.want) { t.Errorf(\"expected:%#v, got:%#v\", tt.want, got) } }) 使用testify/assert之后就能将上述判断过程简化如下： t.Run(tt.name, func(t *testing.T) { // 使用t.Run()执行子测试 got := Split(tt.input, tt.sep) assert.Equal(t, got, tt.want) // 使用assert提供的断言函数 }) 当我们有多个断言语句时，还可以使用assert := assert.New(t)创建一个assert对象，它拥有前面所有的断言方法，只是不需要再传入Testing.T参数了。 ","date":"2021-10-31","objectID":"/go-test1/:2:2","tags":["Golang测试"],"title":"Go测试从零到溜1-单元测试","uri":"/go-test1/"},{"categories":["学习"],"content":"总结 本文介绍了Go语言单元测试的基本用法，通过为Split函数编写单元测试的真实案例，模拟了日常开发过程中的场景，一步一步详细介绍了表格驱动测试、回归测试和常用的测试工具testify/assert的使用。 ","date":"2021-10-31","objectID":"/go-test1/:3:0","tags":["Golang测试"],"title":"Go测试从零到溜1-单元测试","uri":"/go-test1/"},{"categories":["生活"],"content":"20211028感慨","date":"2021-10-28","objectID":"/20211028sighwithemotion/","tags":["生活感慨"],"title":"20211028感慨","uri":"/20211028sighwithemotion/"},{"categories":["生活"],"content":"刺激的周一下午 日常开发的周一下午（2021年10月25日），午睡完之后怀疑人生的一段悠闲时光过后，刚要把一个commit提交。忽然一声大喝：“所有人起立，双手抱头!”。哈哈哈，一脸懵逼，看着周围的人都起立双手抱头。我当然也是不例外啦。影视作品里发生的事情终于还是落在了我的头上，哈哈哈，笑死。随后便是一阵沉默，所有人都不懂发生了什么。我看着周围的人，基本上都不懂发生了什么，有的人脸上露出来焦虑的神色，可能是想到以后的工作履历不好操作吧（我猜的，我也有这样想）。然后那些算是警官吧，从人事那拿了好多白纸，让我们分别填上自己的信息，在公司的职务，入职时间等等。填完之后，那些警官磨蹭一会，带了一些高层去茶水间问话（鬼知道他们说什么）。那个时候我甚至处在一个看热闹的状态（哈哈哈，真是不怕死），随后我们一群小喽啰便被点名一个接一个的去到了会议室。在里面也很无聊，填写个人信息。之后便是在那里呆坐着。期间一群人要去上厕所（太紧张了？害怕？）。反正那一段时间基本去厕所排队的人是一直都有的。过了好长一段时间（期间我仿佛一个无关人士，以一个上帝视角看着周围的人。尤其是里面的最大职务公司的法人–耀哥，只见他一直摸头好像很紧张的样子。我那时候以为他应该是焦虑血本无归吧，但我现在不是这样想的）。 终于事情结束了，警察走了，我们也开始做自己的事了。过了一会，耀哥分别组织人员去会议室解释刚刚的情况，说是公司的上一个项目出事了（上一个项目卖给了泉州的一家公司，那家公司拿着这个软件去做了诈骗还是违法的一些事），反正我们公司里有接触上一个项目的高层都去了。解释完之后，我们就分别回去工作了，仿佛没有发生过什么。只留下了一个可以让人闲话的话题。 周一的下午结束了！ ","date":"2021-10-28","objectID":"/20211028sighwithemotion/:1:0","tags":["生活感慨"],"title":"20211028感慨","uri":"/20211028sighwithemotion/"},{"categories":["生活"],"content":"平静的周二 这个周二是个无聊的一天，和之前一样进行着日常的开发。除了几个没经历过周一的小伙伴在他人的滔滔不绝下了解了当时的情形，并发表了若有若无的看法。那又有什么鬼用呢。下午那些被走的几位回来了，各个油头，哈哈哈。稍微了解了一下他们的事情，我也差不多撤了，回家！反正这个平静的周二就这样有惊无险的过了。 ","date":"2021-10-28","objectID":"/20211028sighwithemotion/:2:0","tags":["生活感慨"],"title":"20211028感慨","uri":"/20211028sighwithemotion/"},{"categories":["生活"],"content":"最后的周三 过了一个平静的周二，本以为那件事情终于是过去了。一切生活回归正常了。哈哈哈，事情是过去了，我也又被辞职了。唉。周三的早上还是一个正常的平静的早上，我在那默默的摸鱼，一个早上就过去了。哈哈哈，轻松啊！中午和同事去吃个饭，和平常无二的午睡，午睡之后的怀疑人生。之后就真的怀疑人生了。首先是一些产品ui之类的去了会议室，之后客户端的小伙伴也去了。那时候我还以为就是要开启下一阶段了，在讨论需求了吧。紧随其后，我们也开会了，我TM甚至还带了笔记本去。哈哈哈，笑死，就我一个带了笔记本。结果进去并不是什么讨论需求，而是被辞职大会。首先，老板的小舅子又再一次说明了周一的情况，然后说为了保护我们不被牵连，希望我们可以自己辞职。老板被抓走了，一时半会回不来了，趁现在还有点钱，把我们工资结了。随后便是苦情策略了，直接开哭。笑死，一个大男人说哭就哭，牛皮。唉，最后举手表决愿不愿意了。哈哈哈，大家都举手了，我能干嘛，蛮举着吧。然后就差不多散会了。散会了之后就在工位上瞎聊呗，等人事通知呗，最后一份同安香骨鸡腿作为简单的散伙饭了，也是搞笑。本来那时候我也挺无所谓的，但是后面越想越不对（现在心生恼火，艹！！！）。散伙饭吃完，和现在的相亲好友一起吃了顿饭，应该啥也没有暴露吧。我那时候不想回家，不想让他们知道。晚上也还行玩的挺开心的。下班之后，几个同事的朋友圈也是挺有意思的！ 最恼火的是回家之后看了boss直聘上居然有公司的招聘岗位。呵呵，玩这招，够损啊。项目开发完毕，然后把第一波开发人员都炒了，改招几个其他的人来进行开发。真TM有意思。资本主义。 就希望他们说的是真的，公司boss直接给抓走。哈哈哈，我也是老狗一条了。 ","date":"2021-10-28","objectID":"/20211028sighwithemotion/:3:0","tags":["生活感慨"],"title":"20211028感慨","uri":"/20211028sighwithemotion/"},{"categories":["生活"],"content":"同事的有趣朋友圈 云深不知处（又彬）： 今天下班真早 好久没有这么早下班过了 真爽 后面几天也不用上班了 卧槽原来失业了 别人的天空 我的天空😱 加了几个月的班 都算上线了 结果搞这出 眼看果实就要成熟了 结果一口屎 狗头 狗头 狗头 别人的天空\u0026ldquo;别人的天空\u0026rdquo; \"\r别人的天空\r 我的天空\u0026ldquo;我的天空\u0026rdquo; \"\r我的天空\r ","date":"2021-10-28","objectID":"/20211028sighwithemotion/:4:0","tags":["生活感慨"],"title":"20211028感慨","uri":"/20211028sighwithemotion/"},{"categories":["生活"],"content":"c:哈哈哈，老阴阳怪气了！（挺有意思的） nicklos（小君）： 行路难，多歧路，今安在？长风破浪会有时，直挂云帆济沧海。 ","date":"2021-10-28","objectID":"/20211028sighwithemotion/:5:0","tags":["生活感慨"],"title":"20211028感慨","uri":"/20211028sighwithemotion/"},{"categories":["生活"],"content":"c:怎么说呢。共勉吧。总感觉这人和高层有点不明关系（总感觉这次事件他应该也有点东西）但愿是我误会 浮苏（城城）： 生活可能真的很难吧，每每看见一点盼头，啪，一巴掌又打回去了 但是，但是啊，生活不是一个人的，是一家人的，更要相信，现在遭受的困苦，都是将来回报的财富 永远不要失去眼里的光 不要失去眼里的光\u0026ldquo;不要失去眼里的光\u0026rdquo; \"\r不要失去眼里的光\r ","date":"2021-10-28","objectID":"/20211028sighwithemotion/:6:0","tags":["生活感慨"],"title":"20211028感慨","uri":"/20211028sighwithemotion/"},{"categories":["生活"],"content":"c:我永远不会失去眼里的光(哈哈哈) ","date":"2021-10-28","objectID":"/20211028sighwithemotion/:7:0","tags":["生活感慨"],"title":"20211028感慨","uri":"/20211028sighwithemotion/"},{"categories":["学习"],"content":"RabbitMQ Go语言6","date":"2021-09-29","objectID":"/rabbitmq6/","tags":["RabbitMQ"],"title":"RabbitMQ6","uri":"/rabbitmq6/"},{"categories":["学习"],"content":"远程过程调用(RPC) 在第二个教程中，我们学会了如何使用工作队列在多个worker之间分配耗时的任务。 但是，如果我们需要在远程计算机上运行函数并等待结果怎么办？好吧，那是一个不同的故事。这种模式通常称为\"远程调用\"或RPC。 在本教程中，我们将使用RabbitMQ构建一个RPC系统：客户端和可伸缩RPC服务器。由于我们没有值得分配的定时任务，因此我们将将构建一个虚拟的RPC服务，该服务返回斐波那契数。 有关RPC的说明 尽管RPC是计算中非常常见的模式，但它经常受到批评。 当程序员不知道函数调用是本地的还是缓慢的RPC时，就会出现问题。这样的混乱会导致系统变幻莫测，并给调试增加了不必要的复杂性。滥用RPC可能会导致无法维护的意大利面条式代码而不是简化软件。 牢记这一点，请考虑以下建议： 1.确定那个函数调用是本地的，那个是远程的 2.为你的系统编写文档。明确组件之间的依赖关系 3.处理错误情况。当RPC服务器长时间关闭时，客户端应如何处理 ","date":"2021-09-29","objectID":"/rabbitmq6/:1:0","tags":["RabbitMQ"],"title":"RabbitMQ6","uri":"/rabbitmq6/"},{"categories":["学习"],"content":"回调队列 通常，通过RabbitMQ进行RPC很容易。客户端发送请求消息，服务端发送相应消息。为了接受响应，我们需要发送带有\"回调\"队列地址的请求。我们可以使用默认队列。让我们尝试一下： q, err := ch.QueueDeclare( // 不指定队列名，默认使用随机生成的队列名 \"\", // durable false, // delete when unused false, // exclusive true, // noWait false, // arguments nil, ) err = ch.Publish( // exchange \"\", // routing key \"rpc_queue\", // mandatory false, // immediate false, amqp.Publishing{ ContentType: \"text/plain\", CorrelationId: corrId, // 在这里指定callback队列名，也是在这个队列等回复 ReplyTo: q.Name, Body: []byte(strconv.Itoa(n)), } ) 消息属性 AMQP 0-9-1协议预定义了消息附带的14个属性集。除以下属性外，大多数属性很少用： 1. persistent:将消息标记为持久性(值为true)或瞬态(false)。你可能还记得第二个教程中的此属性。 2. content_type:用于描述编码的mime类型。例如，对于经常使用的JSON编码，将此属性设置为application/json是一个好习惯 3. reply_to:常用于命名回调队列 4. correlation_id:有助于将RPC响应与请求相关联 ","date":"2021-09-29","objectID":"/rabbitmq6/:2:0","tags":["RabbitMQ"],"title":"RabbitMQ6","uri":"/rabbitmq6/"},{"categories":["学习"],"content":"关联ID (Correlation Id) 在上面介绍的方法中，我们建议每个RPC请求创建一个回调队列。这是相当低效的，但是幸运的是，有一个更好的方法–让我们为每个客户端创建一个回调队列。 这就引发了一个新问题，在该队列中收到响应后，尚不清楚属于哪个请求。这个时候就应该使用correlation_id这个属性了。针对每个请求我们将其设置一个唯一值。随后，当我们在回调队列中收到消息时，我们将查看该属性，并基于这个属性将响应与请求进行匹配。如果我们看到未知的correlation_id值，则可以放心地丢弃该消息–它不属于我们的请求。 你可能会问，为什么我们应该忽略回调队列中的未知消息，而不是报错而失败？这是由于服务器端可能出现竞争状况。尽管可能性不大，但RPC服务器可能会在向我们发送答案之后，在发送请求的确认消息之前死亡。如果发生这种情况，重新启动RPC服务器将再次处理该请求。这就是为什么在客户端上我们必须妥善处理重复的响应，并且理想情况下RPC应该是幂等的。 ","date":"2021-09-29","objectID":"/rabbitmq6/:3:0","tags":["RabbitMQ"],"title":"RabbitMQ6","uri":"/rabbitmq6/"},{"categories":["学习"],"content":"总结 我们的RPC工作流程如下： 客户端启动时，它将创建一个匿名排他回调队列 对于RPC请求，客户端发送一条消息，该消息具有两个属性：reply_to(设置为回调队列)和correlation_id(设置为每个请求的唯一值) 该请求被发送到rpc_queue队列 RPC工作程序(又名：服务器)正在等待该队列上的请求。当出现请求时，它会完成计算工作并把结果作为消息使用replay_to字段中的队列发回给客户端。 客户端等待回调队列上的数据。出现消息时，它将检查correlation_id属性。如果它与请求中的值匹配，则将响应返回给应用程序。 ","date":"2021-09-29","objectID":"/rabbitmq6/:4:0","tags":["RabbitMQ"],"title":"RabbitMQ6","uri":"/rabbitmq6/"},{"categories":["学习"],"content":"完整示例 斐波那契函数： func fib(n int) int { if n == 0 { return 0 } else if n == 1 { return 1 } else { return fib(n-1) + fib(n-2) } } 声明我们的斐波那契函数。它仅假设有效的正整数输入。(不要指望这种方法适用于大量用户，它可能是最慢的递归实现) 我们的RPC服务器rpc_server.go的代码如下所示： package main import ( \"log\" \"strconv\" \"github.com/streadway/amqp\" ) func failOnError(err error, msg string) { if err != nil { log.Fatalf(\"%s: %s\", msg, err) } } func fib(n int) int { if n == 0 { return 0 } else if n == 1 { return 1 } else { return fib(n-1) + fib(n-2) } } func main() { conn, err := amqp.Dial(\"amqp://guest:guest@localhost:5672/\") failOnError(err, \"Failed to connect to RabbitMQ\") defer conn.Close() ch, err := conn.Channel() failOnError(err, \"Failed to open a channel\") defer ch.Close() q, err := ch.QueueDeclare( // name \"rpc_queue\", // durable false, // delete when unused false, // exclusive false, // no-wait false, // arguments nil, ) failOnError(err, \"Failed to declare a queue\") q, err := ch.Qos( // prefetch count 1, // prefetch size 0, // global false, ) failOnError(err, \"Failed to set Qos\") msgs, err := ch.Consume( // queue q.Name, // consumer \"\", // auto-ack false, // exclusive false, // no-local false, // no-wait false, // args nil, ) failOnError(err, \"Failed to register a consumer\") forever := make(chan bool) go func() { for d := range msgs { n, err := strconv.Atoi(string(d.body)) failOnError(err, \"Failed to convert body to integer\") log.Printf(\" [.] fib(%d)\", n) response := fib(n) err = ch.Publish( \"\", d.ReplyTo, false, false, amqp.Publishing{ ContentType: \"text/plain\", CorrelationId: d.CorrelationId, Body: []byte(strconv.Itoa(response)), } ) failOnError(err, \"failed to publish a message\") d.Ask(false) } }() log.Printf(\" [*] Awaiting RPC requests\") \u003c-forever } 服务器代码非常简单： 和往常一样，我们首先建立连接，通道并声明队列 我们可能要运行多个服务器进程。为了将负载平均分配给多个服务器，我们需要在通道上设置prefetsh设置 我们使用Channel.Consume获取去队列，我们从队列中接收消息。然后我们进入goroutine进行工作，并将响应发送回去。 我们的RPC客户端rpc_client的代码 package main import ( \"log\" \"math/rand\" \"os\" \"strconv\" \"strings\" \"time\" \"github.com/streadway/amqp\" ) func failOnError(err error, msg string) { if err != nil { log.Fatalf(\"%s: %s\", msg, err) } } func randomString(l int) string { bytes := make([]byte, l) for int i := 0; i \u003c l; i++ { bytes[i] := byte(randInt(65, 90)) } return string(bytes) } func randInt(min int, max int) int { return min + rand.Intn(max-min) } func fibonacciRPC(n int) (res int, err error) { conn, err := amqp.Dial(\"amqp://guest:guest@localhost:5672/\") failOnError(err, \"Failed to connect to RabbitMQ\") defer conn.Close() ch, err := conn.Channel() failOnError(err, \"Failed to open a channel\") defer ch.Close() q, err := ch.QueueDeclare( // name \"\", // durable false, // delete when unused false, // exclusive true, // noWait false, // arguments nil, ) failOnError(err, \"Failed to declare a queue\") msg, err := ch.Consume( // queue q.Name, // consumer \"\", // auto-ack true, // exclusive false, // no-local false, // no-wait false, // args nil, ) failOnError(err, \"Failed to register a consumer\") corrId := randomString(32) err = ch.Publish( \"\", \"rpc_queue\", false, false, amqp.Publishing{ ContentType: \"text/plain\", CorrelationId: corrId, ReplyTo: q.Name, Body: []byte(strconv.Itoa(n)), } ) failOnError(err, \"Failed to publish a message\") for d := range msgs { if corrId == d.CorrelationId { res, err := strconv.Atoi(string(d.Body)) failOnError(err, \"Failed to convert body to integer\") break } } return } func main() { rand.Seed(time.Now().UTC().UnixNano()) n := bodyFrom(os.Args) log.Printf(\" [X] Requesting fib (%d)\", n) res, err := fibonacciRPC(n) failOnError(err, \"Failed to handle RPC request\") log.Printf(\" [.] Got %d\", res) } func bodyFrom(args []string) int { var s string if (len(args) \u003c 2) || args[1] == \"\" { s = \"30\" } else { s = strings.Join(args[1:], \" \") } n, err := strconv.Atoi(s) failOnError(err, \"Failed to convert arg to integer\") return n } 这里介绍的设计不是RPC服务唯一可能的实现，但是它具有一些重要的特点： 如果RPC服务器太慢，则可以通过运行另一台RPC服务器来进行扩展。尝试在新控制台中运行另一个rpc_server.go 在客户端，RPC只需要发送和接收一条消息。结果，RPC客户端只需要一个网络往返就可以处理单个RPC请求 我们的代码仍然非常简单，并且不会尝试解决更复杂（但很重要）的问","date":"2021-09-29","objectID":"/rabbitmq6/:5:0","tags":["RabbitMQ"],"title":"RabbitMQ6","uri":"/rabbitmq6/"},{"categories":["学习"],"content":"RabbitMQ Go语言5","date":"2021-09-25","objectID":"/rabbitmq5/","tags":["RabbitMQ"],"title":"RabbitMQ5","uri":"/rabbitmq5/"},{"categories":["学习"],"content":"topic交换器(主题交换器) 发送到topic交换器的消息不能具有随意的routing_key – 它必须是单词列表，以点分割。这些词可以是任何东西，但通常它们指定与消息相关的某些功能。一些有效的routing_key示例：“stock.usd.nyse”, “nyse.vmw”, “quick.orange.rabbit”。 “routing_key\"中可以包含任意多个单词，最多255个字节。 绑定键也必须采用相同的形式。topic交换器背后的逻辑类似direct交换器–用特定路由器发送消息将传递到所有匹配绑定键绑定的队列。但是，绑定键有两个重要的特殊情况： *可以代替一个单词 #可以代替零个或多个单词 通过下面这个示例可以很容易看明白这一点： 在这个例子中，我们将发送一些都是描述动物的信息。将使用包含三个词(两个点)的路由密钥发送消息。路由键中的第一个单词将描述速度，第二个是颜色，第三个是种类 “\u003cspeed\u003e.\u003ccolour\u003e.\u003cspecies\u003e\"。 我们创建三个绑定关系：Q1与绑定键*.orange.*绑定，Q2与绑定键*.*.rabbit和lazy.#绑定。 这些绑定可以总结为： Q1对所有橙色动物都感兴趣 Q2想接收有关兔子(rabbit)的一切消息，以及有关懒惰(lazy)动物的一切消息。 路由键设置为quick.orange.rabbit的消息将传递到两个队列。消息lazy.orange.elephant也将发送给他们两个。另一方面，quick.orange.fox将仅进入第一个队列，而lazy.pink.rabbit与两个绑定匹配绑定(匹配绑定Q2的两个绑定)，也只会传递到第二个队列一次。quick.brown.fox与任何绑定都不匹配，因此将被丢弃。 如果我们打破约定并发送一个或四个单词的消息，例如orange或quick.orange.male.rabbit，会发生什么？好吧，这些消息将不匹配任何绑定，并且将会丢失。 另外，lazy.orange.male.rabbit即使有四个单词，也将匹配最后一个绑定，并将其传送到第二个队列。 topic交换器 top交换器功能强大，可以像其他交换器一样运行。 当队列用#绑定键绑定时，它将接收所有消息，而与路由键无关，就像在fanout交换器中一样。 当绑定中不使用特殊字符*和#时，topic交换器的行为就像direct交换器一样。 ","date":"2021-09-25","objectID":"/rabbitmq5/:1:0","tags":["RabbitMQ"],"title":"RabbitMQ5","uri":"/rabbitmq5/"},{"categories":["学习"],"content":"完整示例 我们将在日志记录系统中使用topic交换器。我们将从一个可行的假设开始，即日志的路由键将包含两个词：\u003cfacility\u003e.\u003cserverity\u003e ","date":"2021-09-25","objectID":"/rabbitmq5/:2:0","tags":["RabbitMQ"],"title":"RabbitMQ5","uri":"/rabbitmq5/"},{"categories":["学习"],"content":"RabbitMQ Go语言4","date":"2021-08-15","objectID":"/rabbitmq4/","tags":["RabbitMQ"],"title":"RabbitMQ4","uri":"/rabbitmq4/"},{"categories":["学习"],"content":"路由 在上一教程中，我们构建了一个简单的日志记录系统。我们能够向许多接收者广播日志消息。 在本教程中，我们将它添加一个特性–我们将使它能够只订阅消息的一个子集。例如，我们将只能将错误消息定向到日志文件(以节省磁盘空间)，同时仍然能够在控制台上打印所有日志消息。 ","date":"2021-08-15","objectID":"/rabbitmq4/:1:0","tags":["RabbitMQ"],"title":"RabbitMQ4","uri":"/rabbitmq4/"},{"categories":["学习"],"content":"绑定 在前面的示例中，我们已经在创建绑定。你可能会想起以下代码： err = ch.QueueBind( // queue name q.Name, // routing key \"\", // exchange \"logs\", false, nil, ) 绑定是交换器和队列之间的关系。这可以简单地理解为：队列对来自此交换器的消息感兴趣。 绑定可以采用额外的routing_key参数。为了避免与Channel.Publish参数混淆，我们将其称为binding key。这是我们如何使用键创建绑定的方法： err = ch.QueueBind( // queue name q.Name, // routing key \"black\", // exchange \"logs\", false, nil, ) 绑定密钥的含义取决于交换器的类型。我们以前使用的fanout交换器只是忽略了这个值。 ","date":"2021-08-15","objectID":"/rabbitmq4/:1:1","tags":["RabbitMQ"],"title":"RabbitMQ4","uri":"/rabbitmq4/"},{"categories":["学习"],"content":"直连交换器 我们上一个教程中的日志系统将所有消息广播给所有消费者。我们希望扩展这一点，允许根据消息的严重性过滤消息。例如，我们可能希望将日志消息写入磁盘的脚本只接受严重错误，而不会在warning或info日志消息上浪费磁盘空间。 我们是有fanout交换器，这并没有给我们很大的灵活性–它只能无脑广播。 我们将使用direct交换器。direct交换器背后的路由算法很简单–消息进入其binding key与消息的routing key完全匹配的队列。 为了说明这一点，请考虑一下设置： 在此设置中，我们可以看见绑定了两个队列的direct交换器x。第一个队列绑定键为orange，第二个队列绑定为两个，一个绑定键为black，另一个为green。 在这种设置用，使用orange路由键发布到交换器的消息将被路由到队列Q1。路由键为black或green的消息将转到Q2。所有其他消息将被丢弃。 ","date":"2021-08-15","objectID":"/rabbitmq4/:1:2","tags":["RabbitMQ"],"title":"RabbitMQ4","uri":"/rabbitmq4/"},{"categories":["学习"],"content":"多重绑定 用相同的绑定键绑定多个队列是完全合法的。在我们的示例中，我们可以使用绑定键black在x和Q1之间添加绑定。在这种情况下，direct交换器将类似fanout，并将消息广播到所有匹配的队列。带有black路由键的消息同时传递给Q1和Q2， ","date":"2021-08-15","objectID":"/rabbitmq4/:1:3","tags":["RabbitMQ"],"title":"RabbitMQ4","uri":"/rabbitmq4/"},{"categories":["学习"],"content":"发送日志 我们将日志系统中使用这个模型。我们将发送消息到direct交换器，而不是fanout。我们将提供严重性（通常我们将日志级别划分为日志信息的严重性）作为路由键。这样，接收脚本将能够选择其想接收的日志级别。让我们首先关注发送日志。 和往常一样，我们需要首先创建一个交换器 err = ch.ExchangeDeclare*=( // name \"logs_direct\", // type \"direct\", // durable true, // auto_deleted false, // internal false, // no_wait false, // arguments nil, ) 我们已经准备好发送一条消息 err = ch.ExchangeDeclare*=( // name \"logs_direct\", // type \"direct\", // durable true, // auto_deleted false, // internal false, // no_wait false, // arguments nil, ) failOnError(err, \"Failed to declare an exchange\") body := bodyFrom(os.Args) err = ch.Publish( \"logs_direct\", severityFrom(os.Args), false, false, amqp.Publish{ ContentType: \"text/plain\", Body: []byte(body) } ) 为了简化问题，我们假设“严重性”可以是\"info\", “warning”, “error\"之一。 ","date":"2021-08-15","objectID":"/rabbitmq4/:1:4","tags":["RabbitMQ"],"title":"RabbitMQ4","uri":"/rabbitmq4/"},{"categories":["学习"],"content":"订阅 接收消息的工作方式与上一教程一样，但有一个例外–我们将为感兴趣的每种严重性（日志级别）创建一个新的绑定。 q, err := ch.QueueDeclare( // name \"\", // durable false, // delect when unused false, // exclusive true, // no_wait false, // arguments nil, ) failOnError(err, \"Failed to declare a queue\") if len(os.Args) \u003c 2 { log.Printf(\"Usage: %s [info] [warning] [error]\", os.Args[0]) os.Exit(0) } // 建立多个绑定关系 for _, s := range os.Args[1:] { log.Printf(\"Binding queue %s to exchange %s with routing key %s\", q.Name, \"log_direct\", s) err = ch.QueueBind( // queue name q.Name, // routing key s, // exchange \"logs_direct\", false, nil, ) failOnError(err, \"Failed to bind a queue\") } ","date":"2021-08-15","objectID":"/rabbitmq4/:1:5","tags":["RabbitMQ"],"title":"RabbitMQ4","uri":"/rabbitmq4/"},{"categories":["学习"],"content":"Go Study 18-validator库参数校验若干实用技巧","date":"2021-07-25","objectID":"/go-study18/","tags":["golang"],"title":"Go Study18","uri":"/go-study18/"},{"categories":["学习"],"content":"在web开发中一个不可避免的环节就是对请求参数进行校验，通常我们对在代码中定义和请求参数相对应的模型(结构体)，借助模型绑定快捷地解析请求中的参数，例如gin框架中的Bind和ShouldBind系列的方法。本文就以gin框架的请求参数校验为例，介绍一些validator库的实用技巧。 gin框架使用的是github.com/go-playground/validator进行参数校验，目前已经支持github.com/go-playground/validator/v10了，我们需要在定义结构体时使用binding tag标识相关校验规则。 ","date":"2021-07-25","objectID":"/go-study18/:0:0","tags":["golang"],"title":"Go Study18","uri":"/go-study18/"},{"categories":["学习"],"content":"基本示例 首先来看gin框架内置使用validator做参数校验的基本示例。 package main import ( \"net/http\" \"github.com/gin-gonic/gin\" ) type SignUpParam struct { Age uint8 `json:\"age\" binding:\"gte=1, lte=130\"` Name string `json:\"name\" binding:\"required\"` Email string `json:\"email\" binding:\"required, email\"` Password string `json:\"password\" binding:\"required\"` RePassword string `josn:\"re_password\" binding:\"required, eqfield=Password\"` } func main() { r := gin.Default() r.POST(\"/signup\", func(c *gin.Context) { var u SignUpParam if err := c.ShouldBind(\u0026u), err != nil { c.JSON(http/StatusOK, gin.H{ \"msg\": err.Error(), }) return } // 保存入库等业务逻辑代码... c.JSON(http.StatusOK, \"success\") }) _ := r.Run(\":8999\") } 我们使用curl发送一个POST请求测试下 curl -H \"Content-type: application/json\" -X POST -d '{\"name\": \"q1mi\", \"age\": 18, \"email\": \"123.com\"}' http://127.0.0.1:8999/signup 输出结果 {\"msg\":\"Key: 'SignUpParam.Email' Error:Field validation for 'Email' failed on the 'email' tag\\nKey: 'SignUpParam.Password' Error:Field validation for 'Password' failed on the 'required' tag\\nKey: 'SignUpParam.RePassword' Error:Field validation for 'RePassword' failed on the 'required' tag\"} 从最终的输出结果可以看到validator的检验生效了，但是错误提示的字段不是特别友好，我们可能需要将它翻译成中文 ","date":"2021-07-25","objectID":"/go-study18/:1:0","tags":["golang"],"title":"Go Study18","uri":"/go-study18/"},{"categories":["学习"],"content":"翻译校验错误提示信息 validator库本身是支持国际化的，借助相应的语言包可以实现校验错误提示信息的自动翻译。下面的示例代码演示了如何将错误提示信息翻译成中文，翻译成其他语言的方法类似。 package main import ( \"fmt\" \"net/http\" \"github.com/gin-gonic/gin\" \"github.com/gin-gonic/gin/binding\" \"github.com/go-playground/locales/en\" \"github.com/go-playground/locales/zh\" ut \"github.com/go-playground/universal-translator\" \"github.com/go-playground/validator/v10\" enTranslations \"github.com/go-playground/validator/v10/translations/en\" zhTranslations \"github.com/go-playground/validator/v10/translations/zh\" ) // 定义一个全局翻译器T var trans ut.Translator // InitTrans 初始化翻译器 func InitTrans(locale string) (err error) { if v, ok := binding.Validator.Engine().(*validator.Validate); ok { // 中文翻译器 zhT := zh.New() // 英文翻译器 enT := en.New() // 第一个参数是备用(fallback)的语言环境 // 后面的参数是应该支持的语言环境(支持多个) // uni := ut.New(zhT, zhT)也是可以的 uni := ut.New(enT, zhT, enT) // locale通常取决于http请求头的'Accept-Language' var ok bool // 也可以使用uni.FindTranslator(...)传入多个locale进行查找 trans, ok = uni.GetTranslator(locale) if !ok { return fmt.Errorf(\"uni.GetTranslator(%s) failed\", locale) } // 注册翻译器 switch locale { case \"en\": err = enTranslations.RegisterDefaultTranslations(v, trans) case \"zh\": err = zhTranslations.RegisterDefaultTranslations(v, trans) default: err = enTranslations.RegisterDefaultTranslations(v, trans) } return } return } type SignUpParam struct { Age uint8 `json:\"age\" binding:\"gte=1,lte=130\"` Name string `json:\"name\" binding:\"required\"` Email string `json:\"email\" binding:\"required,email\"` Password string `json:\"password\" binding:\"required\"` RePassword string `json:\"re_password\" binding:\"required,eqfield=Password\"` } func main() { if err := InitTrans(\"zh\"); err != nil { fmt.Printf(\"init trans failed, err:%v\\n\", err) return } r := gin.Default() r.POST(\"/signup\", func(c *gin.Context) { var u SignUpParam if err := c.ShouldBind(\u0026u); err != nil { // 获取validator.ValidationErrors类型的errors errs, ok := err.(validator.ValidationErrors) if !ok { // 非validator.ValidationErrors类型错误直接返回 c.JSON(http.StatusOK, gin.H{ \"msg\": err.Error(), }) return } // validator.ValidationErrors类型错误则进行翻译 c.JSON(http.Status, gin.H{ \"msg\": errs.Translate(trans), }) return } // 保存入库等具体业务逻辑代码... c.JSON(http.StatusOK, \"success\") }) _ = r.Run(\":8999\") } 我们使用curl发送一个POST请求测试下： curl -H \"Content-type: application/json\" -X POST -d '{\"name\":\"q1mi\", \"age\":18, \"email\":\"123.com\"}' http://127.0.0.1:8999/signup 输出结果： {\"msg\": \"Key: 'SignUpParam.Email' Error:Field validation for 'Email' failed on the 'email' tag\\nKey: 'SignUpParam.Password' Error:Field validation for 'Password' failed on the 'required' tag\\nKey: 'SignUpParam.RePassword' Error:Field validation for 'RePassword' failed on the 'required' tag\"} 从最终的输出结果可以看到validator的检验生效了，但是错误提示的字段不是很友好，我们可能需要将它翻译成中文 ","date":"2021-07-25","objectID":"/go-study18/:2:0","tags":["golang"],"title":"Go Study18","uri":"/go-study18/"},{"categories":["学习"],"content":"翻译校验错误提示信息 validator库本身是支持国际化的，借助相应的语言包可以实现校验错误提示信息的自动翻译，下面的示例代码演示了如何将错误提示信息翻译成中文，翻译成其他语言的方法类似 package main import ( \"fmt\" \"net/http\" \"github.com/gin-gonic/gin\" \"github.com/gin-gonic/gin/binding\" \"github.com/go-playground/locales/en\" \"github.com/go-playground/locales/zh\" ut \"github.com/go-playground/universal-translator\" \"github.com/go-playground/validator/v10\" enTranslations \"github.com/go-playground/validator/v10/translations/en\" zhTranslations \"github.com/go-playground/validator/v10/translations/zh\" ) // 定义一个全局翻译器T var trans ut.Translator // 初始化翻译器 func InitTrans(locale string) (err error) { // 修改gin框架中的Validator引擎属性，实现自定制 if v, ok := binding.Validator.Engine().(*validator.Validate); ok { zhT := zh.New() // 中文翻译器 enT := en.New() // 英文翻译器 // 第一个参数是备用（fallback）的语言环境 // 后面的参数是应该支持的语言环境（支持多个） // uni := ut.New(zhT, zhT) 也是可以的 uni := ut.New(enT, zhT, enT) // locale 通常取决于 http 请求头的 'Accept-Language' var ok bool // 也可以使用 uni.FindTranslator(...) 传入多个locale进行查找 trans, ok = uni.GetTranslator(locale) if !ok { return fmt.Errorf(\"uni.GetTranslator(%s) failed\", locale) } // 注册翻译器 switch locale { case \"en\": err = enTranslations.RegisterDefaultTranslations(v, trans) case \"zh\": err = zhTranslations.RegisterDefaultTranslations(v, trans) default: err = enTranslations.RegisterDefaultTranslations(v, trans) } return } return } type SignUpParam struct { Age uint8 `json:\"age\" binding:\"gte=1,lte=130\"` Name string `json:\"name\" binding:\"required\"` Email string `json:\"email\" binding:\"required,email\"` Password string `json:\"password\" binding:\"required\"` RePassword string `json:\"re_password\" binding:\"required,eqfield=Password\"` } func main() { if err := InitTrans(\"zh\"); err != nil { fmt.Printf(\"init trans failed, err:%v\\n\", err) return } r := gin.Default() r.POST(\"/signup\", func(c *gin.Context) { var u SignUpParam if err := c.ShouldBind(\u0026u); err != nil { // 获取validator.ValidationErrors类型的errors errs, ok := err.(validator.ValidationErrors) if !ok { // 非validator.ValidationErrors类型错误直接返回 c.JSON(http.StatusOK, gin.H{ \"msg\": err.Error(), }) return } // validator.ValidationErrors类型错误则进行翻译 c.JSON(http.StatusOK, gin.H{ \"msg\":errs.Translate(trans), }) return } // 保存入库等具体业务逻辑代码... c.JSON(http.StatusOK, \"success\") }) _ = r.Run(\":8999\") } 同样的请求再来一次 curl -H \"Content-type: application/json\" -X POST -d '{\"name\":\"q1mi\",\"age\":18,\"email\":\"123.com\"}' http://127.0.0.1:8999/signup 这次的输出结果如下 {\"msg\":{\"SignUpParam.Email\":\"Email必须是一个有效的邮箱\",\"SignUpParam.Password\":\"Password为必填字段\",\"SignUpParam.RePassword\":\"RePassword为必填字段\"}} ","date":"2021-07-25","objectID":"/go-study18/:3:0","tags":["golang"],"title":"Go Study18","uri":"/go-study18/"},{"categories":["学习"],"content":"自定义错误提示信息的字段名 上面的错误提示看起来可以了，但是还是差点意思，首先是错误提示中的字段并不是请求中使用的字段，例如：RePassword使我们后端定义的结构体中的字段名，而请求中使用的是re_password字段。如何使错误提示中的字段使用自定义的名称，例如json tag指定的值？ 只需要在初始化翻译器的时候像下面一样添加一个获取json tag的自定义方法即可。 // InitTrans 初始化翻译器 func InitTrans(locale string) (err error) { // 修改gin框架中的Validator引擎属性，实现自定制 if v, ok := binding.Validator.Engine().(*validator.Validate); ok { // 注册一个获取json tag的自定义方法 v.RegisterTagNameFunc(func(fld reflect.StructField) string { name := strings.SplitN(fld.Tag.Get(\"json\"), \",\", 2)[0] if name == \"-\" { return \"\" } return name }) zhT := zh.New() // 中文翻译器 enT := en.New() // 英文翻译器 // 第一个参数是备用（fallback）的语言环境 // 后面的参数是应该支持的语言环境（支持多个） // uni := ut.New(zhT, zhT) 也是可以的 uni := ut.New(enT, zhT, enT) // ... liwenzhou.com ... } 再尝试发请求，看一下效果： {\"msg\":{\"SignUpParam.email\":\"email必须是一个有效的邮箱\",\"SignUpParam.password\":\"password为必填字段\",\"SignUpParam.re_password\":\"re_password为必填字段\"}} 可以看到现在错误提示信息中使用的就是我们结构体中json tag设置的名称了 但是还是有点瑕疵，那就是最终的错误提示信息中心还是有我们后端定义的结构体名称–SignUpParam，这个名称其实是不需要随错误提示返回给前端的，前端并不需要这个值。我们需要想办法把它去掉。 这里参考https://github.com/go-playground/validator/issues/633#issuecomment-654382345提供的方法，定义一个去掉结构体名称前缀的自定义方法： func removeTopStruct(fields map[string]string) map[string]string { res := map[string]string{} for field, err := range fields { res[field[strings.Index(field, \".\")+1:]] = err } return res } 我们在代码中使用上述函数将翻译后的errors做一下处理即可： if err := c.ShouldBind(\u0026u); err != nil { // 获取validator.ValidationErrors类型的errors errs, ok := err.(validator.ValidationErrors) if !ok { // 非validator.ValidationErrors类型错误直接返回 c.JSON(http.StatusOK, gin.H{ \"msg\": err.Error(), }) return } // validator.ValidationErrors类型错误则进行翻译 // 并使用removeTopStruct函数去除字段名中的结构体名称标识 c.JSON(http.StatusOK, gin.H{ \"msg\": removeTopStruct(errs.Translate(trans)), }) return } 看一下最终的效果 {\"msg\":{\"email\":\"email必须是一个有效的邮箱\",\"password\":\"password为必填字段\",\"re_password\":\"re_password为必填字段\"}} 这一次看起来就比较符合我们预期的标准了。 ","date":"2021-07-25","objectID":"/go-study18/:4:0","tags":["golang"],"title":"Go Study18","uri":"/go-study18/"},{"categories":["学习"],"content":"自定义结构体校验方法 上面的校验还是有点小问题，就是当涉及到一些复杂的校验规则，比如re_password字段需要与password字段的值相等这样的校验规则，我们的自定义错误提示字段名称方法就不能很好解决错误提示信息中的其他字段名称了。 curl -H \"Content-type: application/json\" -X POST -d '{\"name\":\"q1mi\",\"age\":18,\"email\":\"123.com\",\"password\":\"123\",\"re_password\":\"321\"}' http://127.0.0.1:8999/signup 最后输出的错误提示信息如下 {\"msg\":{\"email\":\"email必须是一个有效的邮箱\",\"re_password\":\"re_password必须等于Password\"}} 可以看到re_password字段的提示信息中还是出现了Password这个结构体字段名称。这有点小小的遗憾，毕竟自定义字段名称的方法不能影响被当成param传入的值。 此时如果想要追求更好的提示效果，将上面的Password字段也改为和json tag一致的名称，就需要我们自定义结构体校验的方法。 例如，我们为SignUpParam自定义一个校验方法如下： // SignUpParamStructLevelValidation 自定义SignUpParam结构体校验函数 func SignUpParamStructLevelValidation(sl validator.StructLevel) { su := sl.Current().Interface().(SignUpParam) if su.Password != su.RePassword { // 输出错误提示信息，最后一个参数就是传递的param sl.ReportError(su.RePassword, \"re_password\", \"RePassword\", \"eqfield\", \"password\") } } 然后在初始化校验器的函数中注册该自定义校验方法即可： func InitTrans(locale string) (err error) { // 修改gin框架中的Validator引擎属性，实现自定制 if v, ok := binding.Validator.Engine().(*validator.Validate); ok { // ... liwenzhou.com ... // 为SignUpParam注册自定义校验方法 v.RegisterStructValidation(SignUpParamStructLevelValidation, SignUpParam{}) zhT := zh.New() // 中文翻译器 enT := en.New() // 英文翻译器 // ... liwenzhou.com ... } 最终再请求一次，看一下效果： {\"msg\":{\"email\":\"email必须是一个有效的邮箱\",\"re_password\":\"re_password必须等于password\"}} 这一次re_password字段的错误提示信息就符合我们预期了。 ","date":"2021-07-25","objectID":"/go-study18/:5:0","tags":["golang"],"title":"Go Study18","uri":"/go-study18/"},{"categories":["学习"],"content":"自定义字段校验方法 除了上面介绍到的自定义结构体校验方法，validator还支持为某个字段自定义校验方法，并使用RegisterValidation()注册到校验器实例中。 接下来我们来为SignUpParam添加一个需要使用自定义校验方法checkDate做参数校验的字段Date。 type SignUpParam struct { Age uint8 `json:\"age\" binding:\"gte=1,lte=130\"` Name string `json:\"name\" binding:\"required\"` Email string `json:\"email\" binding:\"required,email\"` Password string `json:\"password\" binding:\"required\"` RePassword string `json:\"re_password\" binding:\"required,eqfield=Password\"` // 需要使用自定义校验方法checkDate做参数校验的字段Date Date string `json:\"date\" binding:\"required,datetime=2006-01-02,checkDate\"` } 其中datetime=2006-01-02是内置的用于校验日期类参数是否满足指定格式要求的tag。 如果传入的date参数不满足2006-01-02这种格式就会提示如下错误： {\"msg\":{\"date\":\"date的格式必须是2006-01-02\"}} 针对date字段除了内置的datetime=2006-01-02提供的格式要求外，假设我们还要求该字段的时间必须是一个未来的时间（晚于当前时间），像这样针对某个字段的特殊校验需求就需要我们使用自定义字段校验方法了。 首先我们要在需要执行自定义校验的字段后面添加自定义tag，这里使用的是checkDate，注意使用英文分号分隔开。 // customFunc 自定义字段级别校验方法 func customFunc(fl validator.FieldLevel) bool { date, err := time.Parse(\"2006-01-02\", fl.Field().String()) if err != nil { return false } if date.Before(time.Now()) { return false } return true } 定义好了字段及其自定义校验方法后，就需要将它们联系起来并注册到我们的校验器实例中。 // 在校验器注册自定义的校验方法 if err := v.RegisterValidation(\"checkDate\", customFunc); err != nil { return err } 这样，我们就可以对请求参数中date字段执行自定义的checkDate进行校验了。 我们发送如下请求测试一下： curl -H \"Content-type: application/json\" -X POST -d '{\"name\":\"q1mi\",\"age\":18,\"email\":\"123@qq.com\",\"password\":\"123\", \"re_password\": \"123\", \"date\":\"2020-01-02\"}' http://127.0.0.1:8999/signup 此时得到的响应结果是： {\"msg\":{\"date\":\"Key: 'SignUpParam.date' Error:Field validation for 'date' failed on the 'checkDate' tag\"}} 这…自定义字段级别的校验方法的错误提示信息很“简单粗暴”，和我们上面的中文提示风格有出入，必须想办法搞定它呀！ ","date":"2021-07-25","objectID":"/go-study18/:6:0","tags":["golang"],"title":"Go Study18","uri":"/go-study18/"},{"categories":["学习"],"content":"自定义翻译方法 我们现在需要为自定义字段校验方法提供一个自定义的翻译方法，从而实现该字段错误提示信息的自定义显示。 // registerTranslator 为自定义字段添加翻译功能 func registerTranslator(tag string, msg string) validator.RegisterTranslationsFunc { return func(trans ut.Translator) error { if err := trans.Add(tag, msg, false); err != nil { return err } return nil } } // translate 自定义字段的翻译方法 func translate(trans ut.Translator, fe validator.FieldError) string { msg, err := trans.T(fe.Tag(), fe.Field()) if err != nil { panic(fe.(error).Error()) } return msg } 定义好了相关翻译方法之后，我们在InitTrans函数中通过调用RegisterTranslation()方法来注册我们自定义的翻译方法。 // InitTrans 初始化翻译器 func InitTrans(locale string) (err error) { // ...liwenzhou.com... // 注册翻译器 switch locale { case \"en\": err = enTranslations.RegisterDefaultTranslations(v, trans) case \"zh\": err = zhTranslations.RegisterDefaultTranslations(v, trans) default: err = enTranslations.RegisterDefaultTranslations(v, trans) } if err != nil { return err } // 注意！因为这里会使用到trans实例 // 所以这一步注册要放到trans初始化的后面 if err := v.RegisterTranslation( \"checkDate\", trans, registerTranslator(\"checkDate\", \"{0}必须要晚于当前日期\"), translate, ); err != nil { return err } return } return } 这样再次尝试发送请求，就能得到想要的错误提示信息了。 {\"msg\":{\"date\":\"date必须要晚于当前日期\"}} ","date":"2021-07-25","objectID":"/go-study18/:7:0","tags":["golang"],"title":"Go Study18","uri":"/go-study18/"},{"categories":["学习"],"content":"总结 本文总结的gin框架中validator的使用技巧同样也适用于直接使用validator库，区别仅仅在于我们配置的是gin框架中的校验器还是由validator.New()创建的校验器。同时使用validator库确实能够在一定程度上减少我们的编码量，但是它不太可能完美解决我们所有需求，所以你需要找到两者之间的平衡点。 ","date":"2021-07-25","objectID":"/go-study18/:8:0","tags":["golang"],"title":"Go Study18","uri":"/go-study18/"},{"categories":["学习"],"content":"Go Study 17-select语句中实现优先级","date":"2021-07-22","objectID":"/go-study17/","tags":["golang"],"title":"Go Study17","uri":"/go-study17/"},{"categories":["学习"],"content":"select语句介绍 Go语言中的select语句用于监控并选择一组case语句执行相应的代码。它看起来类似于switch语句，但是select语句中所有case中的表达式必须是channel的发送或者接受操作。一个典型的select的使用示例如下： select { case \u003c- ch1: fmt.Println(\"liwenzhou.com\") case ch2 \u003c- 1: fmt.Println(\"qimi\") } Go语言中select关键字也能够让当前goroutine同时等待ch1的可读和ch2的可写，在ch1和ch2状态改变之前，select会一直堵塞下去，直到其中的一个channel转为就绪状态时执行对应的case分支的代码。如果多个channel同时就绪的话则随机选择一个case执行。 处理上面展示的典型实例外，接下来我们逐一介绍一些select的特殊示例 ","date":"2021-07-22","objectID":"/go-study17/:1:0","tags":["golang"],"title":"Go Study17","uri":"/go-study17/"},{"categories":["学习"],"content":"空select 空select指的是内部不包含任何case，例如： select { } 空的select语句会直接堵塞当前的goroutine，使得该goroutine进入无法唤醒的永久休眠状态 ","date":"2021-07-22","objectID":"/go-study17/:2:0","tags":["golang"],"title":"Go Study17","uri":"/go-study17/"},{"categories":["学习"],"content":"只有一个case 如果select中只包含一个case，那么该select就变成了一个堵塞的channel读/写操作。 select { case \u003c- ch1: fmt.Println(\"liwenzhou.com\") } 上面的代码，当ch1可读时会执行打印操作，否则就会堵塞 ","date":"2021-07-22","objectID":"/go-study17/:3:0","tags":["golang"],"title":"Go Study17","uri":"/go-study17/"},{"categories":["学习"],"content":"有default语句 如果select中还可以包含default语句，用于当其他case都不满足时执行一些默认操作。 select { case \u003c- ch1: fmt.Println(\"liwenzhou.com\") default: time.Sleep(time.Second) } 上面的代码，当ch1可读时会执行打印操作，否则就执行default语句中的代码，这里就相当于做了一个非堵塞的channel读取操作。 ","date":"2021-07-22","objectID":"/go-study17/:4:0","tags":["golang"],"title":"Go Study17","uri":"/go-study17/"},{"categories":["学习"],"content":"总结 select不存在任何的case：永久堵塞当前goroutine select只存在一个case：堵塞的发送/接收 select存在多个case：随机选择一个满足条件的case执行 select存在default，其他case都不满足时，执行default语句中的代码 ","date":"2021-07-22","objectID":"/go-study17/:5:0","tags":["golang"],"title":"Go Study17","uri":"/go-study17/"},{"categories":["学习"],"content":"如何在select中实现优先级 已知，当select存在多个case时会随机选择一个满足条件的case执行 现在我们有一个需求：我们有一个函数会持续不间断地从ch1和ch2中分别接收任务1和任务2，如何确保当ch1和ch2同时达到就绪状态时，优先执行任务1，在没有任务1的时候再去执行任务2 func worker (ch1, ch2 \u003c-chan int, stopCh chan struct{}) { for { select { case \u003c-stopCh: return case job1 := \u003c-ch1: fmt.Println(job1) default: select { case job2 := \u003c-ch2: fmt.Println(job2) default: } } } } 上面的代码通过嵌套两个select实现了\"优先级\"，看起来是满足题目要求的。但是这代码有点问题，如果ch1和ch2都没有达到就绪状态的话，整个程序不会堵塞而是进入死循环。 func worker2(ch1, ch2 \u003c-chan int, stopCh chan struct{}) { for { select { case \u003c-stopCh: return case job1 := ch1: fmt.Printl(job1) case job2 := ch2: priority: for { select { case job1 := \u003c-ch1: fmt.Println(job1) default: break priority } } fmt.Println(job2) } } } 这一次不仅使用了嵌套的select，还组合使用了for循环和LABEL来实现题目的要求。上面的代码在外层select选中执行job := \u003c-ch2时，进入到内层select循环尝试执行job1 := \u003c-ch1，当ch1就绪时就会一直执行，否则跳出内层select ","date":"2021-07-22","objectID":"/go-study17/:6:0","tags":["golang"],"title":"Go Study17","uri":"/go-study17/"},{"categories":["学习"],"content":"实际应用场景 K8s的controller中就有关于上面这个技巧的实际使用示例，这里在关于select中实现优先级相关代码的关键处都已添加了注释。 // kubernetes/pkg/controller/nodelifecycle/scheduler/taint_manager.go func (tc *NoExecuteTaintManager) worker(worker int, done func(), stopCh \u003c-chan struct{}) { defer done() // 当处理具体事件的时候，我们会希望 Node 的更新操作优先于 Pod 的更新 // 因为 NodeUpdates 与 NoExecuteTaintManager无关应该尽快处理 // -- 我们不希望用户(或系统)等到PodUpdate队列被耗尽后，才开始从受污染的Node中清除pod。 for { select { case \u003c-stopCh: return case nodeUpdate := \u003c-tc.nodeUpdateChannels[worker]: tc.handleNodeUpdate(nodeUpdate) tc.nodeUpdateQueue.Done(nodeUpdate) case podUpdate := \u003c-tc.podUpdateChannels[worker]: // 如果我们发现了一个 Pod 需要更新，我么你需要先清空 Node 队列. priority: for { select { case nodeUpdate := \u003c-tc.nodeUpdateChannels[worker]: tc.handleNodeUpdate(nodeUpdate) tc.nodeUpdateQueue.Done(nodeUpdate) default: break priority } } // 在 Node 队列清空后我们再处理 podUpdate. tc.handlePodUpdate(podUpdate) tc.podUpdateQueue.Done(podUpdate) } } } ","date":"2021-07-22","objectID":"/go-study17/:7:0","tags":["golang"],"title":"Go Study17","uri":"/go-study17/"},{"categories":["学习"],"content":"Go Study 16-切片操作常用技巧","date":"2021-07-18","objectID":"/go-study-16/","tags":["golang"],"title":"Go Study 16","uri":"/go-study-16/"},{"categories":["学习"],"content":"复制 将切片a中的元素复制到切片b中。 最简单的、最常用的方法就是使用内置的copy方法 // 一次将内存申请到位 b = make([]T, len(a)) copy(b, a) 除了使用内置的copy函数外，还有下面两种使用append函数复制切片的方法 b = append([]T(nil), a...) b = append(a[:0:0], a...) 这两种方法通常比使用copy函数复制的方法要慢一点，但是如果在复制之后有更多的元素要添加到b中，那么它们的效率会更高。 ","date":"2021-07-18","objectID":"/go-study-16/:1:0","tags":["golang"],"title":"Go Study 16","uri":"/go-study-16/"},{"categories":["学习"],"content":"剪切 将切片a中索引i~j位置的元素剪切掉 可以按照下面的方式，使用append函数完成 a = append(a[:i], a[j:]...) ","date":"2021-07-18","objectID":"/go-study-16/:2:0","tags":["golang"],"title":"Go Study 16","uri":"/go-study-16/"},{"categories":["学习"],"content":"删除 将切片a中索引位置为i的元素删除。 同样可以使用上面剪切的方式使用append函数完成删除操作 a = append(a[:i], a[i+1:]...) 或者搭配copy函数使用切片表达式完成删除操作 a = a[:i + copy(a[i:], a[i+1])] 此外，如果只需要删除索引为i的元素，无需保留切片元素原有的顺序，那么还可以使用下面这种简单的方式删除 // 将最后一个元素移到索引i处 a[i] = a[len(a) - 1] // 截掉最后一个元素 a = a[:len(a) - 1] ","date":"2021-07-18","objectID":"/go-study-16/:3:0","tags":["golang"],"title":"Go Study 16","uri":"/go-study-16/"},{"categories":["学习"],"content":"剪切或删除操作可能引起的内存泄露 需要特别注意的是，如果切片a中的元素是一个指针类型或者包含指针字段的结构体类型(需要被垃圾回收)，上面的剪切和删除的示例代码会存在一个潜在的内存泄露问题：一些具有值的元素仍被切片a引用，因此无法被垃圾回收机制回收掉。下面代码可以解决这个问题。 ","date":"2021-07-18","objectID":"/go-study-16/:4:0","tags":["golang"],"title":"Go Study 16","uri":"/go-study-16/"},{"categories":["学习"],"content":"剪切 copy(a[i:], a[j:]) for k, n := len(a)-j+i, len(a); k \u003c n; k++ { // 或类型T的零值 a[k] = nil } a = a[:len(a)-j+i] ","date":"2021-07-18","objectID":"/go-study-16/:4:1","tags":["golang"],"title":"Go Study 16","uri":"/go-study-16/"},{"categories":["学习"],"content":"删除 copy(a[i:], a[i+1:]) // 或类型T的零值 a[len(a)-1] = nil a = a[:len(a)-1] ","date":"2021-07-18","objectID":"/go-study-16/:4:2","tags":["golang"],"title":"Go Study 16","uri":"/go-study-16/"},{"categories":["学习"],"content":"删除但不保留元素原有顺序 a[i] = a[len(a)-1] a[len(a)-1] = nil a = a[:len(a)-1] ","date":"2021-07-18","objectID":"/go-study-16/:4:3","tags":["golang"],"title":"Go Study 16","uri":"/go-study-16/"},{"categories":["学习"],"content":"内部扩张 在切片a的索引i之后扩张j个元素 使用两个append函数完成，即先将索引i之后的元素追加到一个长度为j的切片后，再将这个切片中的所有元素追加到切片a的索引i之后 a = append(a[:i], append(make([]T, j), a[i:]...)...) 扩张的这一部分元素为T类型的零值 ","date":"2021-07-18","objectID":"/go-study-16/:5:0","tags":["golang"],"title":"Go Study 16","uri":"/go-study-16/"},{"categories":["学习"],"content":"尾部扩张 将切片a的尾部扩张j个元素的空间。 a = append(a, make([]T, j)...) 扩张的这一部分元素同样为T类型的零值 ","date":"2021-07-18","objectID":"/go-study-16/:6:0","tags":["golang"],"title":"Go Study 16","uri":"/go-study-16/"},{"categories":["学习"],"content":"过滤 按照一定的规则将切片a中的元素进行就地过滤 这里假设过滤的条件已经封装为keep函数，使用for range遍历切片a的所有元素逐一调用keep函数进行过滤 n := 0 for _, x := range a { if keep(x) { // 保留该元素 a[n] = x n++ } } // 截取切片中需保留的元素 a = a[:n] ","date":"2021-07-18","objectID":"/go-study-16/:7:0","tags":["golang"],"title":"Go Study 16","uri":"/go-study-16/"},{"categories":["学习"],"content":"插入 将元素x插入切片a的索引i处 还是使用两个append函数完成插入x的操作 a = append(a[:i], append([]T{x}, a[i:...])...) 第二个append函数创建了一个具有自己底层数组的新切片，并将a[i:] 中的元素复制到该切片，然后由第一个append函数将这些元素复制回切片。 我们可以通过使用另一个方法来避免新切片的创建(以及由此产生的内存垃圾)和第二个副本： // 这里应使用元素的零值 a = append(a, 0) copy(a[i+1:], a[i:]) a[i] = x ","date":"2021-07-18","objectID":"/go-study-16/:8:0","tags":["golang"],"title":"Go Study 16","uri":"/go-study-16/"},{"categories":["学习"],"content":"追加 将元素x追加到切片a的最后 这里使用append函数即可 a = append(a, x) ","date":"2021-07-18","objectID":"/go-study-16/:9:0","tags":["golang"],"title":"Go Study 16","uri":"/go-study-16/"},{"categories":["学习"],"content":"弹出 将切片a的最后一个元素弹出 这里使用切片表达式完成弹出操作 x, a = a[len(a)-1], a[:len(a)-1] 弹出切片a的第一个元素 x, a = a[0], a[i:] ","date":"2021-07-18","objectID":"/go-study-16/:10:0","tags":["golang"],"title":"Go Study 16","uri":"/go-study-16/"},{"categories":["学习"],"content":"前插 将元素x前插到切片a的最开始 a = append([]T{x}, a...) ","date":"2021-07-18","objectID":"/go-study-16/:11:0","tags":["golang"],"title":"Go Study 16","uri":"/go-study-16/"},{"categories":["学习"],"content":"其他技巧 ","date":"2021-07-18","objectID":"/go-study-16/:12:0","tags":["golang"],"title":"Go Study 16","uri":"/go-study-16/"},{"categories":["学习"],"content":"过滤而不分配内存 此技巧使用了一个事实，即切片b与原始切片a共享相同的底层数组和容量，因此原存储空间已重新用于过滤后的切片。当然原始切片的内容被修改了。 b := a[:0] for _, x := range a { if f(x) { b = append(b, x) } } 对于必须被垃圾回收的元素，在完成上述操作后可以添加一下代码 for i := len(b); i \u003c len(a); i++ { a[i] = nil } ","date":"2021-07-18","objectID":"/go-study-16/:12:1","tags":["golang"],"title":"Go Study 16","uri":"/go-study-16/"},{"categories":["学习"],"content":"翻转 将切片a的元素顺序翻转 通过迭代两两互换元素完成 for i := len(a)/2-1; i \u003e= 0; i-- { opp := len(a)-1-i a[i], a[opp] = a[opp], a[i] } 同样的操作： for left, right := 0, len(a)-1; left \u003c right; left, right = left+1, right-1 { a[left], a[right] = a[right], a[left] } ","date":"2021-07-18","objectID":"/go-study-16/:12:2","tags":["golang"],"title":"Go Study 16","uri":"/go-study-16/"},{"categories":["学习"],"content":"洗牌 打乱切片a中元素的顺序 Fisher-Yates算法： for i := len(a)-1; i \u003e 0; i-- { j := rand.Intn(i+1) a[i], a[j] = a[j], a[i] } 从go1.10开始，可以使用math/rand.Shuffle rand.Shuffle(len(a), func(i, j int) { a[i], a[j] = a[j], a[i] }) ","date":"2021-07-18","objectID":"/go-study-16/:12:3","tags":["golang"],"title":"Go Study 16","uri":"/go-study-16/"},{"categories":["学习"],"content":"使用最小分配进行批处理 如果你想对一个大型切片a的元素分批进行处理，这会很有用。 actions := []int{0, 1, 2, 3, 4, 5, 6, 7, 8, 9} batchSize := 3 batches := make([][]int, 0, (len(actions)+batchSize-1)/batchSize) for batchSize \u003c len(actions) { actions, batches = actions[batchSize:], append(batches, actions[0:batchSize:batchSize]) } batches = append(batches, actions) 得到的效果如下： [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9]] ","date":"2021-07-18","objectID":"/go-study-16/:12:4","tags":["golang"],"title":"Go Study 16","uri":"/go-study-16/"},{"categories":["学习"],"content":"原地删除重复元素(元素可比较) import \"sort\" // 切片元素可以是任何可排序的类型 in := []int{3, 2, 1, 4, 3, 2, 1, 4, 1} sort.Ints(in) j := 0 for i := 1; i \u003c len(in); i++ { if in[j] == in[i] { continue } j++ // 需要保存原始数据时 // in[i], in[j] = in[j], in[i] // 只需要保存需要的数据时 in[j] = in[i] } result := in[:j+1] // [1, 2, 3, 4] fmt.Println(result) ","date":"2021-07-18","objectID":"/go-study-16/:12:5","tags":["golang"],"title":"Go Study 16","uri":"/go-study-16/"},{"categories":["学习"],"content":"存在就移到前面，不存在就插到前面 如果给定的元素在切片中存在则把该元素移到切片的头部，如果不存在则将该元素插入到切片的头部。 func moveToFront(needle string, haystack []string) []string { if len(haystack) != 0 \u0026\u0026 haystack[0] == needle { return haystack } prev := needle for i, elem := range haystack { switch { case i == 0: haystack[0] = needle prev = elem case elem == needle: haystack[i] = prev return haystack default: haystack[i] = prev prev = elem } } return append(haystack, prev) } // [a, b, c, d, e] haystack := []string{\"a\", \"b\", \"c\", \"d\", \"e\"} haystack = moveToFront(\"c\", haystack) haystack = moveToFront(\"f\", haystack) ","date":"2021-07-18","objectID":"/go-study-16/:12:6","tags":["golang"],"title":"Go Study 16","uri":"/go-study-16/"},{"categories":["学习"],"content":"滑动窗口 将切片input生成size大小的滑动窗口 func slidingWindow(size int, input []int) [][]int { // 返回入参的切片作为第一个元素 if len(input) \u003c= size { return [][]int{input} } // 以所需的精确大小分配切片 r := make([][]int, 0, len(input)-size+1) for i, j := 0, size; j \u003c= len(input); i, j = i+1, j+1 { r = append(r, input[i:j]) } return r } 示例： a := []int{1, 2, 3, 4, 5} res L= slidingWindow(2, a) fmt.Println(res) 输出： [[1, 2] [2, 3] [3, 4] [4, 5]] ","date":"2021-07-18","objectID":"/go-study-16/:12:7","tags":["golang"],"title":"Go Study 16","uri":"/go-study-16/"},{"categories":["学习"],"content":"RabbitMQ Go语言3","date":"2021-07-14","objectID":"/rabbitmq3/","tags":["RabbitMQ"],"title":"RabbitMQ3","uri":"/rabbitmq3/"},{"categories":["学习"],"content":"发布订阅 在上一个教程中，我们创建了一个工作队列。工作队列背后的假设是每个任务只传递给一个工人。在这一部分中，我们将做一些完全不同的事情–我们将向多个消费者传递一个消息。这就是所谓的\"订阅/发布模式\"。 为了说明这种模式，我们将构建一个简单的日志系统。它由两个程序组成–第一个程序将发出日志消息，第二个程序将接收并打印他们。 在我们的日志系统中，每一个运行的接收器程序副本都会受到消息。这样我们就可以运行一个接收器并将日志定向到磁盘；同时，我们还可以运行另一个接收器并在屏幕上查看日志。 本质上，已发布的日志消息将被广播到所有接收者。 ","date":"2021-07-14","objectID":"/rabbitmq3/:1:0","tags":["RabbitMQ"],"title":"RabbitMQ3","uri":"/rabbitmq3/"},{"categories":["学习"],"content":"Exchanges(交换器) 在本教程的前面部分中，我们向队列发送消息和从队列接收消息。现在是时候在Rabbit中引入完整的消息传递模型了。 快速回顾先前教程的内容： “生产者\"是发送消息的用户应用程序 “队列\"是存储消息的缓冲区 “消费者\"是接收消息的用户应用程序 RabbitMQ的消息传递模型中的核心思想是生产者从不将任何消息发送到队列。实际上，生产者甚至根本不知道是否将消息传递到任何队列。 相反，生产者只能将消息发送到交换器。交换器是非常简单的东西。一方面，它接收来自生产者的消息，另一方面，将它们推入队列。交换器必须确切知道如何处理接收到的消息。它应该被附加到特定的队列？还是应该将其附加到许多队列中？或者它应该被丢弃。这些规则由交换器的类型定义。 有几种交换器类型可用：direct， topic， headers和fanout。我们将集中讨论最后一个–fanout。 fanout(扇出)交换器非常简单。正如名称一样，它只是将接收到的所有消息广播到它知道的所有队列中。而这正是我们记录器所需要的。 ","date":"2021-07-14","objectID":"/rabbitmq3/:1:1","tags":["RabbitMQ"],"title":"RabbitMQ3","uri":"/rabbitmq3/"},{"categories":["学习"],"content":"临时队列 先前我们使用的是具有特定名称的队列，能够命名队列对我们来说至关重要–我们需要将工作人员指向同一个队列。当你想在生产者和消费者之间共享队列时，给队列一个名称是非常重要的。 但对于记录器来说，情况并非如此。我们希望收到所有的日志消息，而不仅仅是它们的一部分。我们也只对当前正在发送的消息感兴趣，而对旧消息不感兴趣。为了解决这个问题，我们需要两件事。 首先，当我们连接RabbitMQ时，我们需要一个新的空的队列。为此，我们可以创建一个随机名称的队列，或者更好的方法是让服务器为我们选择一个随机队列名称。 其次，一旦我们断开消费者的连接，队列就会自动删除。 在amqp客户端中，当我们传递一个空字符串作为队列名称时，我们将使用随机生成的名称创建一个非持久队列： q, err := ch.QueueDeclare( // 空字符串作为队列的名称 \"\", // 非持久队列 false, // delete when unused false, // 独占队列(当前声明队列的连接关闭后即被删除) true, // no-wait false, // arguments nil, ) 上述方法返回时，生成的队列实例包含RabbitMQ生成的随机队列名称。例如，它可能看起来像amq.gen-JzTY20RgKO-HjmUJj0wLg。 当声明它的连接关闭时，该队列将被删除，因为它被声明为独占。 ","date":"2021-07-14","objectID":"/rabbitmq3/:1:2","tags":["RabbitMQ"],"title":"RabbitMQ3","uri":"/rabbitmq3/"},{"categories":["学习"],"content":"绑定 我们已经创建了一个扇出交换器和一个队列。现在我们需要告诉服务器将消息发送到我们的队列。交换器和队列之间的关系成为绑定 ch.QueueBind( // queue name q.Name, // routing key \"\", // exchange \"logs\", false, nil, ) 从现在开始，logs交换器将会把消息添加到我们的队列中。 ","date":"2021-07-14","objectID":"/rabbitmq3/:2:0","tags":["RabbitMQ"],"title":"RabbitMQ3","uri":"/rabbitmq3/"},{"categories":["学习"],"content":"列出绑定关系 rabbitmqctl list_binding 如果要将日志保存到文件，只需打开控制台并输入： go run receive_logs.go \u003e logs_from_rabbit.log 如果希望在屏幕上查看日志，请切换到一个新的终端并运行 go run receive_logs.go 当然要发日志，请输入： go run emit_log.go ","date":"2021-07-14","objectID":"/rabbitmq3/:2:1","tags":["RabbitMQ"],"title":"RabbitMQ3","uri":"/rabbitmq3/"},{"categories":["学习"],"content":"RabbitMQ Go语言2","date":"2021-06-28","objectID":"/rabbitmq2/","tags":["RabbitMQ"],"title":"RabbitMQ2","uri":"/rabbitmq2/"},{"categories":["学习"],"content":"任务队列/工作队列 在第一个教程中，我们编写程序从命名的队列发送和接收消息。在这一节中，我们将创建一个工作队列，该队列将用于多个工人之间分配耗时的任务。 工作队列(又称任务队列)的主要思想是避免立即执行某些资源密集型任务并且不得不等待这些任务完成。相反，我们安排任务异步地同时或当前任务之后完成。我们将任务封装成消息并将其发送到队列，在后台运行的工作进程将取出消息并最终执行任务。当你运行多个工作进程时，任务将在它们之间共享。 这个概念在Web应用中特别有用，因为在Web应用中不可能在较短的HTTP请求窗口内处理复杂的任务，(译注：例如注册时发送邮件或短信验证码等场景)。 ","date":"2021-06-28","objectID":"/rabbitmq2/:1:0","tags":["RabbitMQ"],"title":"RabbitMQ2","uri":"/rabbitmq2/"},{"categories":["学习"],"content":"准备工作 在本教程的上一部分，我们发送了一条包含“Hello World！”的消息。现在，我们将发送代表复杂任务的字符串。我们没有实际的任务，例如调整图像大小或渲染pdf文件，所以我们通过借助time.Sleep函数模拟一些比较耗时的任务。我们会将一些包含.的字符串封装为消息发送到队列中，其中每有一个.就表示需要耗费1秒钟的工作，例如，hello…表示一个将花费三秒钟的假任务。 我们将稍微修改上一个示例中的send.go代码，以允许从命令行发送任意消息。该程序会将任务安排到我们的工作队列中，因此我们将其命名为new_task.go ","date":"2021-06-28","objectID":"/rabbitmq2/:1:1","tags":["RabbitMQ"],"title":"RabbitMQ2","uri":"/rabbitmq2/"},{"categories":["学习"],"content":"循环调度 使用任务队列的优点之一是能够轻松并行化工作。如果我们的工作正在积压，我们可以增加更多的工人，这样就可以轻松扩展。 首先，让我们尝试同时运行两个worker.go脚本。它们都将从队列中获取消息。这时候需要打开三个控制台。其中两个运行worker.go脚本。这些控制台将成为我们的两个消费者–C1和C2。 在第三个控制台中，我们将发布新任务。启动消费者之后，可以发布一些消息 之后我们就可以在C1和C2两个窗口看到如下的输出结果： 默认情况下，RabbitMQ将按顺序将每个消息发送给下一个消费者。平均而言，每个消费者都会收到相同数量的消息。这种分发消息的方式成为轮询。可以使用三个或者多个worker试一下。 ","date":"2021-06-28","objectID":"/rabbitmq2/:1:2","tags":["RabbitMQ"],"title":"RabbitMQ2","uri":"/rabbitmq2/"},{"categories":["学习"],"content":"消息确认 work完成任务可能需要耗费几秒钟，如果一个worker在任务执行过程中宕机了该怎么办？在当前代码中RabbitMQ一旦向消费者传递了一条消息，便立即将其标记为删除。在这种情况下，如果你终止一个worker那么你就可能会丢失这个任务，我们还将丢失所有已经交付给这个worker的尚未处理的消息。 我们不想丢失任何任务，如果一个worker意外宕机了，那么我们希望将任务交付给其他worker来处理 为了确保消息永不丢失，RabbitMQ支持消息确认。消费者返回一个确认(acknowledgement)，以告知RabbitMQ已经接收，处理了特定的消息，并且RabbitMQ可以自由删除它。 如果使用者在不发送确认的情况下死亡(其通道已关闭，连接已关闭或TCP连接丢失)，RabbitMQ将了解消息未完全处理，并将对其重新排队。如果同时有其他消费者在线，它将很快将其重新分发给另一个消费者。这样，您可以确保即使工人偶尔死亡也不会丢失任何消息。 没有任何消息超时，RabbitMQ将在消费者死亡时重新传递消息。即使处理一条消息要很长时间也没关系。 在本教程中，我们将使用手动消息确认，方法是为“auto-ack”参数传递一个false，然后在完成任务后，使用d.Ack(false)从worker发送一个正确的确认(这将确认一次传递) 使用消息确认模式，可以确保即使你在处理消息时使用CTRL+C杀死一个worker，也不会丢失任何内容。在worker死后不久，所有未确认的消息都将被重新发送。 消息确认必须在接收消息的同一通道(Channel)上发送。尝试使用不同的通道(Channel)进行消息确认将导致通道级协议异常。 ","date":"2021-06-28","objectID":"/rabbitmq2/:1:3","tags":["RabbitMQ"],"title":"RabbitMQ2","uri":"/rabbitmq2/"},{"categories":["学习"],"content":"忘记确认 忘记确认是一个常见的错误。这是一个简单的错误，但是后果很严重。当你的客户机退出时，消息将被重新传递(这看起来想随机重新传递)，但是RabbitMQ将消耗越来越多的内存，因为它无法释放任何未确认的消息。 为了调试这种错误，可以使用rabbitmqctl打印message_unacknowledged字段 rabbitmqctl.bat list_queues name message_ready message_unacknowed ","date":"2021-06-28","objectID":"/rabbitmq2/:1:4","tags":["RabbitMQ"],"title":"RabbitMQ2","uri":"/rabbitmq2/"},{"categories":["学习"],"content":"消息持久化 我们已经学会如何确保即使消费者死亡，任务也不会消失。但如果RabbitMQ服务器停止运行，我们任务仍然会丢失。当RabbitMQ退出或崩溃时，它将忘记队列和消息，除非你告诉它不要这样做。要确保数据不丢失，需要做两件事，需要将消息和队列都标记为持久的。 q, err := ch.QueueDeclare( // name \"hello\", // 声明为持久化 true, // delete when unused false, // exclusive false, // no-wait false, // arguments nil, ) 虽然这个命令本身是正确的，但它在我们当前的设置中不起作用。这是因为我们已经定义了一个名为hello的队列，它不是持久的。RabbitMQ不允许使用不同的参数重新定义现有队列，并将向任何尝试重新定义的程序返回错误。但有一个快速解决方法–声明一个具有不同名称的队列。 这种持久的选项更改需要同时应用于生产者代码和消费者代码。 在这一点上我们确信即使RabbitMQ重新启动，任务队列也不会消失。 ","date":"2021-06-28","objectID":"/rabbitmq2/:1:5","tags":["RabbitMQ"],"title":"RabbitMQ2","uri":"/rabbitmq2/"},{"categories":["学习"],"content":"有关消息持久性的说明 将消息标记为持久性并不能完全保证消息不会丢失。尽管它告诉RabbitMQ将消息保存到磁盘上，但是RabbitMQ接受了一条消息并且还没有保存它时，仍然有一个很短的时间窗口。而且，RabbitMQ并不是对每个消息都执行fsync(2)–它可能只是保存到缓存中，而不是真正写入磁盘中。持久性保证不是很强，但是对于我们的简单任务队列来说已经足够了。如果需要更强有力的担保，那么可以使用publisher confirms。 ","date":"2021-06-28","objectID":"/rabbitmq2/:1:6","tags":["RabbitMQ"],"title":"RabbitMQ2","uri":"/rabbitmq2/"},{"categories":["学习"],"content":"公平分发 你可能已经注意到调度仍然不能完全按照我们的要求工作。例如，在一个有两个worker的情况下，当所有的奇数消息都是重消息而偶数消息都是轻消息时，一个worker将持续忙碌，而另一个worker几乎不用做任何工作。RabbitMQ对此一无所知，仍然会均匀的发送消息。 这是因为RabbitMQ只是在消息进入队列时发送消息。它不考虑消费者在未确认消息的数量。只是盲目的向消费者发送消息。 为了避免这种情况，我们可以将预计数设置为1。这告诉RabbitMQ不要一次向一个worker发出多个消息。或者换句话说，在处理并确认前一条消息前，不要向worker发送任何消息。相反，它将把它发送给下一个不忙的worker。 err = ch.Qos( // prefetch count 1, // prefetch size 0, // global false, ) ","date":"2021-06-28","objectID":"/rabbitmq2/:1:7","tags":["RabbitMQ"],"title":"RabbitMQ2","uri":"/rabbitmq2/"},{"categories":["学习"],"content":"关于队列的大小说明 如果所有的worker都很忙，你的queue随时可能会满。你会想继续关注这一点，也许需要增加更多的worker，或者有一些其他的策略。 ","date":"2021-06-28","objectID":"/rabbitmq2/:1:8","tags":["RabbitMQ"],"title":"RabbitMQ2","uri":"/rabbitmq2/"},{"categories":["学习"],"content":"RabbitMQ Go语言1","date":"2021-06-23","objectID":"/rabbitmq1/","tags":["RabbitMQ"],"title":"RabbitMQ1","uri":"/rabbitmq1/"},{"categories":["学习"],"content":"先决条件 本教程假设RabbitMQ已安装并运行在本机上的标准端口(5672)。如果你使用不同的主机、端口或凭据，则需要调整连接设置 ","date":"2021-06-23","objectID":"/rabbitmq1/:1:0","tags":["RabbitMQ"],"title":"RabbitMQ1","uri":"/rabbitmq1/"},{"categories":["学习"],"content":"RabbitMQ Go语言客户端教程(一) ","date":"2021-06-23","objectID":"/rabbitmq1/:2:0","tags":["RabbitMQ"],"title":"RabbitMQ1","uri":"/rabbitmq1/"},{"categories":["学习"],"content":"介绍 RabbitMQ是一个消息代理：它接受并转发消息。可以把它想象成一个邮局：当你把你想要邮寄的邮件放进一个邮箱时，你可以确定邮差先生或女士最终会把邮件送到你的收件人那里。在这个比喻中，RabbitMQ是一个邮箱、一个邮局和一个邮递员。 RabbitMQ和邮局的主要区别在于它不处理纸张，而是接受、存储和转发二进制数据块–消息 RabbitMQ和一般的消息传递都使用一些术语 生产者意味着发送。发送消息的程序是生产者 队列是位于RabbitMQ内部的邮箱的名称。尽管消息通过RabbitMQ和你的应用程序流动，但它们只能存储在队列中。队列只受主机内存和磁盘限制的限制，实际上它是一个大的消息缓冲区。许多生产者可以向一个队列发送消息，而许多消费者可以尝试从一个队列接收数据 消费和接收具有相似的含义。消费者是一个主要等待接收消息的程序 请注意生产者，消费者和代理(broker)不必位于同一主机上。实际上，在大多数应用程序上它们不是。一个应用程序既可以是生产者，也可以是消费者。 ","date":"2021-06-23","objectID":"/rabbitmq1/:2:1","tags":["RabbitMQ"],"title":"RabbitMQ1","uri":"/rabbitmq1/"},{"categories":["学习"],"content":"“Hello World” 在本教程的这一部分中，我们将在Go中编写两个小程序：发送单个消息的生产者和接收消息并将其打印出来的消费者。我们将忽略Go-RabbitMQ API中的一些细节，只关注非常简单的事情，以便开始教程。这是一个消息传送版的“Hello World”。 ","date":"2021-06-23","objectID":"/rabbitmq1/:3:0","tags":["RabbitMQ"],"title":"RabbitMQ1","uri":"/rabbitmq1/"},{"categories":["学习"],"content":"发送 我们将消息发布者（发送者）成为send.go，将消息消费者（接收者）称为receive.go。发布者将连接到RabbitMQ，发送一条消息，然后退出 在send.go中，我们需要首先导入库： package main import ( \"log\" \"github.com/streadway/amqp\" ) 我们还需要一个辅助函数来检查每个amqp调用的返回值 func failOnError(err error, msg string) { if err != nil { log.Fatalf(\"%s: %s\", msg, err) } } 然后连接到RabbitMQ服务器 // 1. 尝试连接RabbitMQ，建立连接 // 该连接抽象了套接字连接，并为我们处理协议版本协商和认证等 conn, err := amqp.Dial(\"amqp://guest:guest@localhost:5672/\") failOnError(err, \"Failed to connect to RabbitMQ\") defer conn.Close() 连接抽象了socket连接，并为我们处理协议版本协商和认证等。接下来，我们创建一个通道，这是大多数用于完成任务的API所在的位置： // 2. 接下来，我们创建一个通道，大多数API都是用过该通道操作的 ch, err := conn.Channel() failOnError(err, \"Failed to open a channel\") defer ch.Close() 要发送，我们必须声明要发送到的队列。然后我们可以将消息发布到队列： // 3. 声明消息要发布到的队列 q, err := ch.QueueDeclare( // name \"hello\", // durable false, // delete when unused false, // exclusive false, // no-wait false, // arguments nil ) failOnError(err, \"Failed to declare a queue\") body := \"hello world\" // 将消息发布到声明的队列 err = ch.Publish( // exchange \"\", // routing key q.Name, // mandatory false, // immediate false amqp.Publishing { ContentType: \"text/plain\", Body: []byte(body), } ) failOnError(err, \"Failed to publish a message\") 声明队列是幂等的–仅当队列不存在时才创建。消息内容是一个字节数组，因此你可以在此处编码任何内容。 ","date":"2021-06-23","objectID":"/rabbitmq1/:3:1","tags":["RabbitMQ"],"title":"RabbitMQ1","uri":"/rabbitmq1/"},{"categories":["学习"],"content":"接收 上面是我们的发布者。我们的消费者监听来自RabbitMQ的消息，因此与发布单个消息的发布者不同，我们将使消费者保持运行状态以监听消息并打印出来。 该代码(在receive.go中)具有与send相同的导入和帮助功能： package main import ( \"github.com/streadway/amqp\" \"log\" ) func failOnErrorReceive(err error, msg string) { if err != nil { log.Fatalf(\"%s: %s\", err, msg) } } 设置与发布者相同；我们打开一个连接和一个通道，并声明要消耗的队列。请注意，这与send发布到的队列匹配 //建立连接 conn, err := amqp.Dial(\"amqp://guest:guest@localhost:5672/\") failOnErrorReceive(err, \"Failed to connect to RabbitMQ\") defer conn.Close() //获取channel ch, err := conn.Channel() failOnErrorReceive(err, \"Failed to open a channel\") defer ch.Close() //声明队列 q, err := ch.QueueDeclare( \"hello\", false, false, false, false, nil, ) failOnErrorReceive(err, \"Failed to declare a queue\") 请注意，我们也在这里声明队列。因为我们可能再在发布者之前启动使用者，所以我们希望在尝试使用队列中的消息之前确保队列存在。 我们将告诉服务器将队列中的消息传递给我们。由于它将异步地向我们发送消息，因此我们将在goroutine中从通道(由amqp::Consume返回)中读取消息。 //获取接收消息的Delivery通道 msgs, err := ch.Consume( q.Name, \"\", true, false, false, false, nil, ) failOnErrorReceive(err, \"Failed to register a consumer\") forever := make(chan bool) go func() { for d := range msgs { log.Printf(\"Received a message: %s\", d.Body) } }() log.Printf(\" [*] Waiting for message. To exit press CTRL+C\") \u003c-forever ","date":"2021-06-23","objectID":"/rabbitmq1/:3:2","tags":["RabbitMQ"],"title":"RabbitMQ1","uri":"/rabbitmq1/"},{"categories":["学习"],"content":"完整示例 现在我们可以运行两个脚本。在一个终端窗口，运行发布者： go run send.go 然后运行使用者 go run receive.go 消费者将打印通过RabbitMQ从发布者那里得到的消息。使用者将持续运行，等待消息(使用Ctrl+C停止它)，因此请尝试从另一个终端运行发布者。 如果要检查队列，请尝试使用rabbitmqctl list_queues命令 ","date":"2021-06-23","objectID":"/rabbitmq1/:3:3","tags":["RabbitMQ"],"title":"RabbitMQ1","uri":"/rabbitmq1/"},{"categories":["学习"],"content":"Go性能调优","date":"2021-06-13","objectID":"/go%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/","tags":["Go性能调优"],"title":"Go性能调优","uri":"/go%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/"},{"categories":["学习"],"content":"Go性能优化 Go语言项目中的性能优化主要有以下几个方面 CPU profile：报告程序的CPU使用情况，按照一定频率去采集应用程序在CPU和寄存器上面的数据 Memory Profile (Heap Profile)：报告程序的内存使用情况 Block Profiling：报告goroutine不在运行时状态的情况，可以用来分析和查找死锁等性能瓶颈 Goroutine Profiling：报告goroutines的使用情况，有哪些goroutine，它们的调用关系是怎样的 ","date":"2021-06-13","objectID":"/go%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/:1:0","tags":["Go性能调优"],"title":"Go性能调优","uri":"/go%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/"},{"categories":["学习"],"content":"采集性能数据 Go语言内置了获取程序运行数据的工具，包括以下两个标准库： runtime/pprof：采集工具型应用运行数据进行分析 net/http/pprof：采集服务型应用运行数据进行分析 pprof开启后，每个一段时间(10ms)就会收集下当前的堆栈信息，获取各个函数占用的CPU以及内存资源；最后通过对这些采样数据进行分析，形成一个性能分析报告。 注意，我们只应该在性能测试的时候才在代码中引入pprof ","date":"2021-06-13","objectID":"/go%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/:2:0","tags":["Go性能调优"],"title":"Go性能调优","uri":"/go%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/"},{"categories":["学习"],"content":"工具型应用 如果你的应用程序是运行一段时间就退出类型。那么最好的方法是在应用退出的时候把profiling的报告保存到文件中，进行分析。对于这种情况，可以使用runtime/pprof库。首先在代码中导入runtime/pprof工具： import \"runtime/pprof\" ","date":"2021-06-13","objectID":"/go%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/:3:0","tags":["Go性能调优"],"title":"Go性能调优","uri":"/go%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/"},{"categories":["学习"],"content":"CPU性能分析 开启CPU性能分析 pprof.StartCPUProfile(w io.Writer) 停止CPU性能分析 pprof.StopCPUProfile() 应用执行结束后，就会生成一个文件，保存了我们的CPU profiling数据。得到采样数据之后，使用go tool pprof工具进行CPU性能分析 ","date":"2021-06-13","objectID":"/go%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/:3:1","tags":["Go性能调优"],"title":"Go性能调优","uri":"/go%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/"},{"categories":["学习"],"content":"内存性能优化 记录程序的堆栈信息 pprof.WriteHeapProfile(w io.Writer) 得到采样数据之后，使用go tool pprof工具进行内存性能分析。 go tool pprof默认是使用-inuse_space进行统计，还可以使用-inuse-objects查看分配对象的数量。 ","date":"2021-06-13","objectID":"/go%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/:4:0","tags":["Go性能调优"],"title":"Go性能调优","uri":"/go%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/"},{"categories":["学习"],"content":"服务型应用 如果你的程序是一直运行的，比如web应用，可以使用net/http/pprof库，它能够在提供HTTP服务进行分析。如果使用了默认的http.DefaultServeMux(通常是代码直接用http.ListenAndServe(“0.0.0.0:8000”, nil))，只需要在你的web server端代码中按如下方式导入net/http/pprof import _ \"net/http/pprof\" 如果使用自定义的Mux，则需要手动注册一些路由规则 r.HandleFunc(\"/debug/pprof/\", pprof.Index) r.HandleFunc(\"/debug/pprof/cmdline\", pprof.Cmdline) r.HandleFunc(\"/debug/pprof/profile\", pprof.Profile) r.HandleFunc(\"/debug/pprof/symbol\", pprof.Symbol) r.HandleFunc(\"/debug/pprof/trace\", pprof.Trace) 如果使用的是gin框架，那么推荐使用github.com/gin-contrib/pprof，在代码中通过以下命令注册pprof相关路由 pprof.Register(router) 不管哪种方式，你的HTTP服务都会多出/debug/pprof endpoint,可以通过(0.0.0.0:8080/debug/pprof)进行访问 这个路径下还有几个子页面： /debug/pprof/profile：访问这个链接会自动进行CPU profiling，持续30s，并生成一个文件供下载 /debug/pprof/heap：Memory Profiling的路径，访问这个链接会得到一个内存Profiling结果的文件 /debug/pprof/block：block Profiling的路径 /debug/pprof/goroutines：运行的goroutines列表，以及调用关系 ","date":"2021-06-13","objectID":"/go%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/:5:0","tags":["Go性能调优"],"title":"Go性能调优","uri":"/go%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/"},{"categories":["学习"],"content":"go tool pprof命令 不管是工具型还是服务型应用，我们使用相应的pprof库获取数据之后，下一步的都要对这些数据进行分析，我们可以使用go tool pprof命令行工具。 go tool pprof最简单的使用方式为： go tool pprof [binary] [source] 其中： binary是应用的二进制文件，可以解析各种符号 source表示profile数据的来源，可以是本地的文件，也可以是http地址 注意事项：获取的Profiling数据是动态的，要想获得有效的数据，请保证应用处于较大的负载(比如正在生成中运行的服务，或者通过其他工具模拟访问压力)。否则如果应用处于空闲状态，得到的结果可能没有任何意义。 ","date":"2021-06-13","objectID":"/go%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/:6:0","tags":["Go性能调优"],"title":"Go性能调优","uri":"/go%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/"},{"categories":["学习"],"content":"具体示例 ","date":"2021-06-13","objectID":"/go%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/:7:0","tags":["Go性能调优"],"title":"Go性能调优","uri":"/go%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/"},{"categories":["学习"],"content":"go-torch和火焰图 火焰图(Flame Graph)是Bredan Gregg创建的一种性能分析表图，因为它的样子近似火焰而得名。上面的profiling结果也转换成火焰图，如果对火焰图比较了解可以手动来操作，不过这里我们要介绍一个工具：go-torch。这是Uber开源的一个工具，可以直接读取golang profiling数据，并生成一个火焰图的svg文件 ","date":"2021-06-13","objectID":"/go%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/:8:0","tags":["Go性能调优"],"title":"Go性能调优","uri":"/go%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/"},{"categories":["学习"],"content":"安装go-torch go get -v githug.com/uber/go-torch 火焰图svg文件可以通过浏览器打开，它对调用图的最大优点是它是动态的：可以通过点击每个方块来zoom in分析它上面的内容。 火焰图的调用顺序从下到上，每个方块代表一个函数，它上面一层表示这个函数会调用哪些函数，方块的大小代表了占用CPU使用的长短。火焰图的配色并没有特殊的意义，默认的红、黄配色是为了更像火焰而已。 go-torch工具的使用非常简单，没有任何参数的话，它会尝试从http://localhost:8080/debug/pprof/profile获取profiling数据。它有三个常用的参数可以调整： -u -url：要访问的URL，这里只是主机和端口部分 -s -suffix：pprof profile的路径，默认为/debug/pprof/profile -seconds：要执行profiling的时间长度，默认为30s ","date":"2021-06-13","objectID":"/go%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/:8:1","tags":["Go性能调优"],"title":"Go性能调优","uri":"/go%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/"},{"categories":["学习"],"content":"安装FlameGraph 要生成火焰图，需要事先安装FlameGraph工具，这个工具安装很简单(需要perl环境支持)，只要把对应的可执行文件加入到环境变量中即可。 下载安装perl：https://www.perl.org/get.html 下载FlameGraph：git clone https://github.com/brendangregg/FlameGraph.git 将FrameGraph目录加入到操作系统的环境变量中 window只需要把go-torch/render/flamegraph.go文件中的GenerateFlameGraph按如下方式修改，然后在go-torch目录下执行go install即可 // GenerateFlameGraph runs the flamegraph script to generate a flame graph SVG. func GenerateFlameGraph(graphInput []byte, args ...string) ([]byte, error) { flameGraph := findInPath(flameGraphScripts) if flameGraph == \"\" { return nil, errNoPerlScript } if runtime.GOOS == \"windows\" { return runScript(\"perl\", append([]string{flameGraph}, args...), graphInput) } return runScript(flameGraph, args, graphInput) } ","date":"2021-06-13","objectID":"/go%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/:8:2","tags":["Go性能调优"],"title":"Go性能调优","uri":"/go%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/"},{"categories":["学习"],"content":"压测工具 推荐使用https://github.com/wg/wrk 或 https://github.com/adjust/go-wrk ","date":"2021-06-13","objectID":"/go%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/:8:3","tags":["Go性能调优"],"title":"Go性能调优","uri":"/go%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/"},{"categories":["学习"],"content":"使用go-torch 使用wrk进行压测 go-work -n 50000 http://127.0.0.1:8080/book/list 在上面进行压测的同时，打开另一个终端执行 go-torch -u http://127.0.0.1:8080 -t 30 30秒之后终端就会出现如下提示 Writing svg to torch.svg 然后我们使用浏览器打开torch.svg就能看到火焰图了 火焰图的y轴表示cpu调用方法的先后，x轴表示在每个采样调用时间内，方法所占的时间百分比，越宽代表占据CPU时间越多。通过火焰图我们就可以更清楚的找出耗时长的函数调用，然后不断的修正代码，重新采样不断优化。 此外还可以借助火焰图分析内存性能数据： go-torch -inuse_space http://127.0.0.1:8080/debug/pprof/heap go-torch -inuse_objects http://127.0.0.1:8080/debug/pprof/heap go-torch -alloc_space http://127.0.0.1:8080/debug/pprof/heap go-torch -alloc_objects http://127.0.0.1:8080/debug/pprof/heap ","date":"2021-06-13","objectID":"/go%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/:8:4","tags":["Go性能调优"],"title":"Go性能调优","uri":"/go%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/"},{"categories":["学习"],"content":"Go context study","date":"2021-06-03","objectID":"/gocontextstudy/","tags":["golang"],"title":"GoContextStudy","uri":"/gocontextstudy/"},{"categories":["学习"],"content":"Go标准库Context 在Go http包的server中，每一个请求在都有一个对应的goroutine去处理。请求处理函数通常会启动额外的goroutine用来访问后端服务，比如数据库和RPC服务。用来处理一个请求的goroutine通常需要访问一些与请求特定的数据，比如终端用户的身份认证信息，验证相关的token，请求的截止时间。当一个请求被取消或超时时，所有用来处理该请求的goroutine都应该迅速退出，然后系统才能释放这些goroutine占用的资源。 ","date":"2021-06-03","objectID":"/gocontextstudy/:1:0","tags":["golang"],"title":"GoContextStudy","uri":"/gocontextstudy/"},{"categories":["学习"],"content":"为什么需要Context ","date":"2021-06-03","objectID":"/gocontextstudy/:2:0","tags":["golang"],"title":"GoContextStudy","uri":"/gocontextstudy/"},{"categories":["学习"],"content":"基本示例 package main import ( \"fmt\" \"sync\" \"time\" ) var wg sync.WaitGroup // 初始的例子 func work() { for { fmt.Println(\"worker\") time.Sleep(time.Second) } // 如何接收外部命令实现退出 wg.Done() } func main() { wg.Add(1) go work() // 如何优雅的实现结束子goroutine wg.Wait() fmt.Println(\"over\") } ","date":"2021-06-03","objectID":"/gocontextstudy/:2:1","tags":["golang"],"title":"GoContextStudy","uri":"/gocontextstudy/"},{"categories":["学习"],"content":"全局变量方式 package main import ( \"fmt\" \"sync\" \"time\" ) //全局变量方式存在的问题： //1.使用全局变量在跨包调用时不容易统一 //2.如果在worker中再启动goroutine，就不太好控制了 var wg2 sync.WaitGroup var exit bool func work2() { for { fmt.Println(\"work\") time.Sleep(time.Second) if exit { break } } wg2.Done() } func main() { wg2.Add(1) go work2() //sleep3秒避免程序过早退出 time.Sleep(time.Second * 3) //修改全局变量实现子goroutine的退出 exit = true wg2.Wait() fmt.Println(\"over\") } ","date":"2021-06-03","objectID":"/gocontextstudy/:2:2","tags":["golang"],"title":"GoContextStudy","uri":"/gocontextstudy/"},{"categories":["学习"],"content":"通道方式 package main import ( \"fmt\" \"sync\" \"time\" ) var wg sync.WaitGroup //管道方式存在的问题 //1.使用全局变量在跨包调用时不容易实现规范和统一，需要维护一个共同的channel func work3(exitChan chan struct{}) { LOOP: for { fmt.Println(\"work\") time.Sleep(time.Second) select { //等待接收上级通知 case \u003c- exitChan: break LOOP default: } } wg.Done() } func main() { wg.Add(1) exitChan := make(chan struct{}) go work3(exitChan) //sleep3秒避免程序过早退出 time.Sleep(time.Second * 3) //给子goroutine发送退出信号 exitChan \u003c- struct {}{} close(exitChan) wg.Wait() fmt.Println(\"over\") } ","date":"2021-06-03","objectID":"/gocontextstudy/:2:3","tags":["golang"],"title":"GoContextStudy","uri":"/gocontextstudy/"},{"categories":["学习"],"content":"官方版的方案 gopackage main import ( \"context\" \"fmt\" \"sync\" \"time\" ) var wg4 sync.WaitGroup func work4(ctx context.Context) { LOOP: for { fmt.Println(\"work4\") time.Sleep(time.Second) select { case \u003c- ctx.Done(): break LOOP default: } } wg4.Done() } func main() { wg4.Add(1) ctx, cancel := context.WithCancel(context.Background()) go work4(ctx) time.Sleep(time.Second*3) cancel() wg4.Wait() fmt.Println(\"over\") } ","date":"2021-06-03","objectID":"/gocontextstudy/:2:4","tags":["golang"],"title":"GoContextStudy","uri":"/gocontextstudy/"},{"categories":["学习"],"content":"当子goroutine又开启另一个goroutine时，只需将ctx传入即可 package main import ( \"context\" \"fmt\" \"sync\" \"time\" ) var wg5 sync.WaitGroup func work5(ctx context.Context) { go work5_2(ctx) LOOP: for { fmt.Println(\"work5\") time.Sleep(time.Second) select { //等待上级通知 case \u003c-ctx.Done(): break LOOP default: } } wg5.Done() } func work5_2(ctx context.Context) { LOOP: for { fmt.Println(\"work5_2\") time.Sleep(time.Second) select { //等待上级通知 case \u003c-ctx.Done(): break LOOP default: } } } func main() { wg5.Add(1) ctx, cancel := context.WithCancel(context.Background()) go work5(ctx) time.Sleep(time.Second * 3) //通知子goroutine结束 cancel() wg5.Wait() fmt.Println(\"over\") } ","date":"2021-06-03","objectID":"/gocontextstudy/:2:5","tags":["golang"],"title":"GoContextStudy","uri":"/gocontextstudy/"},{"categories":["学习"],"content":"Context初识 Go1.7加入了一个新的标准库context，它定义了Context类型，专门用来简化对于处理单个请求的多个goroutine之间与请求域的数据，取消信号、截止时间等相关操作，这些操作可能涉及多个API调用。 对服务器传入的请求应该创建上下文，而对服务器的传出调用应该接受上下文，它们之间的函数调用链必须传递上下文，或者可以使用WithCancel、WithDeadline、WithTimeout或WithValue创建派生的上下文。当一个上下文被取消时，它派生的所有上下文也被取消。 ","date":"2021-06-03","objectID":"/gocontextstudy/:3:0","tags":["golang"],"title":"GoContextStudy","uri":"/gocontextstudy/"},{"categories":["学习"],"content":"Context接口 context.Context是一个接口，该接口定义了四个需要实现的方法。具体接口如下： type Context interface { Deadline() (deadline time.Time, ok bool) Done() \u003c-chan struct{} Err() error Value(key interface{}) interface{} } 其中： Deadline方法返回需要返回当前Context被取消的时间，也就是完成工作的时间 Done方法返回需要一个Channel，这个Channel会在当前工作完成或者上下文被取消后关闭，多次调用Done方法会返回同一Channel Err方法会返回当前Context结束的原因，它只会在Done返回的Channel被关闭时才会返回非空的值 如果当前的Context被取消就会返回Canceled错误 如果当前的Context超时就会返回DeadlineExceeded错误 Value方法会从Context中返回键对应的值，对于同一个上下文来说，多次调用Value并传入相同的Key会返回相同的结果，该方法仅用于传递跨API和进程间跟请求域的数据 ","date":"2021-06-03","objectID":"/gocontextstudy/:4:0","tags":["golang"],"title":"GoContextStudy","uri":"/gocontextstudy/"},{"categories":["学习"],"content":"Background()和TODO() Go内置两个函数：Background()和TODO()，这两个函数分别返回一个实现了Context接口的background和todo。我们代码中最开始都是以这两个内置的上下文对象作为最顶层的parent context，衍生出更多的子上下文对象。 Background()主要作用于main函数，初始化以及测试代码中，作为Context这个树结构最顶层的Context，也就是根Context。 TODO()，它目前还不知道具体的使用场景，如果我们不知道该使用什么Context的使用可以使用这个。 backgroud和todo本质上都是emptyCtx结构类型，是一个不可取消，没有设置截止时间，没有携带任何值的Context。 ","date":"2021-06-03","objectID":"/gocontextstudy/:4:1","tags":["golang"],"title":"GoContextStudy","uri":"/gocontextstudy/"},{"categories":["学习"],"content":"With系列函数 此外，context包中还定义了四个With系列函数。 ","date":"2021-06-03","objectID":"/gocontextstudy/:5:0","tags":["golang"],"title":"GoContextStudy","uri":"/gocontextstudy/"},{"categories":["学习"],"content":"WithCancel WithCancel的函数如下： func WithCancel(parent Context) (ctx Context, cancel CancelFunc) WithCancel返回带有新Done通道的父节点的副本。当调用返回的cancel函数或当关闭父上下文的Done通道时，将关闭返回上下文的Done通道，无论发生什么情况。 取消此上下文将释放与其关联的资源，因此代码应该在此上下文中运行的操作完成后立即调用cancel。 package main import ( \"context\" \"fmt\" ) func gen(ctx context.Context) \u003c- chan int { dst := make(chan int) n := 1 go func() { for { select { case \u003c-ctx.Done(): //return结束该goroutine，防止泄露 return case dst \u003c- n: n++ } } }() return dst } func main() { ctx, cancel := context.WithCancel(context.Background()) //当取完需要的整数后调用cancel defer cancel() for r := range gen(ctx) { fmt.Println(r) if r == 5 { break } } } 上面的示例代码中，gen函数在单独的goroutine中生成整数并将它们发送到返回的通道。gen的调用者在使用生成的整数之后需要取消上下文，以免gen启动的内部goroutine发生泄漏。 ","date":"2021-06-03","objectID":"/gocontextstudy/:5:1","tags":["golang"],"title":"GoContextStudy","uri":"/gocontextstudy/"},{"categories":["学习"],"content":"WithDeadline WithDeadline的函数接口如下 func WithDeadline(parent Context, d time.Time) (Context, CancelFunc) 返回父上下文的副本，并将d调整不迟于deadline。如果父上下文的d已经早于deadline，则WithDeadline(parent, d)在语义上等同于父上下文。当截止日过期时，当调用返回的cancel函数时，或者当父上下文的Done通道关闭时，返回上下文的Done通道将被关闭，以最先发生的情况为准。 取消上下文将释放与其关联的资源，因此代码应该在此上下文中运行的操作完成后立即调用cancel。 package main import ( \"context\" \"fmt\" \"time\" ) func main() { d := time.Now().Add(time.Millisecond * 500) ctx, cancel := context.WithDeadline(context.Background(), d) defer cancel() select { case \u003c-time.After(time.Second): fmt.Println(\"overslept\") case \u003c-ctx.Done(): fmt.Println(ctx.Err()) } } 上面的代码中分，定义了一个500毫秒之后过期的deadline，然后我们调用context.WithDeadline(context.Backgroud(), d)得到一个上下文(ctx)和一个取消函数(cancel)，然后使用一个select让主程序陷入等待：等待1秒后打印overslept退出或者等待ctx过期后退出。因为ctx500毫秒后就过期了，所以ctx.Done()会先接收到值，上面代码会打印ctx.Err()取消原因。 ","date":"2021-06-03","objectID":"/gocontextstudy/:5:2","tags":["golang"],"title":"GoContextStudy","uri":"/gocontextstudy/"},{"categories":["学习"],"content":"WithTimeout WithTimeout的函数接口如下 func WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc) WithTimeout返回WithDeadline(parent, time.Now().Add(timeout)) 取消此上下文将释放与其相关的资源，因此代码应该在上下文中运行的操作完成后立即调用cancel，通常用于数据库或者网络连接的超时控制。具体示例如下： package main import ( \"context\" \"fmt\" \"sync\" \"time\" ) var wg8 sync.WaitGroup func work8(ctx context.Context) { LOOP: for { fmt.Println(\"db connect...\") //假设正常连接数据库需要10毫秒 time.Sleep(time.Millisecond * 10) select { //50毫秒后自动调用 case \u003c-ctx.Done(): break LOOP default: } } fmt.Println(\"work done\") wg8.Done() } func main() { //设置一个50毫秒的超时 ctx, cancel := context.WithTimeout(context.Background(), time.Millisecond*50) wg8.Add(1) go work8(ctx) time.Sleep(time.Second * 5) //通知子goroutine结束 cancel() wg8.Wait() fmt.Println(\"over\") } ","date":"2021-06-03","objectID":"/gocontextstudy/:5:3","tags":["golang"],"title":"GoContextStudy","uri":"/gocontextstudy/"},{"categories":["学习"],"content":"WithValue WithValue 函数能够将请求作用域的数据与Context对象建立联系。函数接口如下： func WithValue(parent Context, key, val interface{}) Context WithValue返回父节点的副本，其中与key关联的值是val。 仅对API和进程传递请求域的数据使用上下文值，而不是使用它来传递可选参数给函数。 所提供的键必须是可比较的，并且不应该是string类型或任何其他内置类型，以避免使用上下文在包之间发生冲突。WithValue的用户应该为键定义自己的类型。为了避免在分配给interface{}时进行分配，上下文通常具有具体类型struct{}。或者，导出的上下文关键变量的静态类型应该是指针或接口。 package main import ( \"context\" \"fmt\" \"sync\" \"time\" ) var wg9 sync.WaitGroup type TraceCode string func work9(ctx context.Context) { key := TraceCode(\"Trace_Code\") //在子goroutine中获取TraceCode traceCode, ok := ctx.Value(key).(string) if !ok { fmt.Println(\"invalid trace code\") } LOOP: for { fmt.Printf(\"worker, trace code: %s\\n\", traceCode) //假设正常连接数据库需要10毫秒 time.Sleep(time.Millisecond * 10) select { //50毫秒后自动调用 case \u003c-ctx.Done(): break LOOP default: } } fmt.Println(\"work done\") wg9.Done() } func main() { //设置一个50毫秒的超时 ctx, cancel := context.WithTimeout(context.Background(), time.Millisecond*50) //在系统入口设置trace code传递给后续启动的子goroutine实现日志数据聚合 ctx = context.WithValue(ctx, TraceCode(\"Trace_Code\"), \"12345\") wg9.Add(1) go work9(ctx) time.Sleep(time.Second * 5) //通知子goroutine结束 cancel() wg9.Wait() fmt.Println(\"over\") } ","date":"2021-06-03","objectID":"/gocontextstudy/:5:4","tags":["golang"],"title":"GoContextStudy","uri":"/gocontextstudy/"},{"categories":["学习"],"content":"使用Context的注意事项 推荐以参数的方式显示传递Context。 以Context作为参数的函数方法，应该把Context作为第一参数。 给一个函数方法传递Context的时候，不要传递nil，如果不知道传递什么，就使用context.TODO() Context的Value相关方法应该传递请求域的必要数据，不应该用于传递可选参数。 Context是线程安全的，可以放心的在多个goroutine中传递。 ","date":"2021-06-03","objectID":"/gocontextstudy/:6:0","tags":["golang"],"title":"GoContextStudy","uri":"/gocontextstudy/"},{"categories":["学习"],"content":"Git Study 01","date":"2021-04-25","objectID":"/git-study02/","tags":["Git学习"],"title":"Git Study02","uri":"/git-study02/"},{"categories":["学习"],"content":"生成公钥 ssh -keygen ","date":"2021-04-25","objectID":"/git-study02/:1:0","tags":["Git学习"],"title":"Git Study02","uri":"/git-study02/"},{"categories":["学习"],"content":"Git Study 01","date":"2021-04-11","objectID":"/git-study01/","tags":["Git学习"],"title":"Git Study01","uri":"/git-study01/"},{"categories":["学习"],"content":"Git配置 ","date":"2021-04-11","objectID":"/git-study01/:1:0","tags":["Git学习"],"title":"Git Study01","uri":"/git-study01/"},{"categories":["学习"],"content":"查看配置 git config -l : git的配置清单 git config –system –list : git的系统配置 git config –global –list : git的用户配置 ","date":"2021-04-11","objectID":"/git-study01/:1:1","tags":["Git学习"],"title":"Git Study01","uri":"/git-study01/"},{"categories":["学习"],"content":"文件配置 系统配置 : E:\\git\\Git\\mingw64\\etc\\gitconfig 用户配置 : C:\\Users\\Administrator.gitconfig ","date":"2021-04-11","objectID":"/git-study01/:1:2","tags":["Git学习"],"title":"Git Study01","uri":"/git-study01/"},{"categories":["学习"],"content":"设置用户名和邮箱 git config –global user.name “xyf1111” : 设置名称 git config –global user.email 2219316464@qq.com : 设置邮箱 ","date":"2021-04-11","objectID":"/git-study01/:1:3","tags":["Git学习"],"title":"Git Study01","uri":"/git-study01/"},{"categories":["学习"],"content":"Git基本理论 ","date":"2021-04-11","objectID":"/git-study01/:2:0","tags":["Git学习"],"title":"Git Study01","uri":"/git-study01/"},{"categories":["学习"],"content":"工作区域 Git本地有三个工作区域：工作目录(Working Directory)、暂存区(Stage/Index)、资源库(Repository或Git Directory)。如果在加上远程的Git仓库(Remote Directory)就可以分为四个工作区域。文件在这四个区域之间的转换关系如下： Workspace : 工作区，就是你平时存放项目代码的地方 Index/Stage : 暂存区，用于临时存放你的改动，事实上她只是一个文件，保存即将提交到文件列表的信息 Repository : 仓库区(或本地仓库)，就是安全存放数据的位置，这里面有你提交到所有版本的数据。其中Head指向最新放入仓库的版本 Rempte : 远程仓库，托管代码的服务器，可以简单的认为是你项目组中的一台电脑用于远程数据交换 ","date":"2021-04-11","objectID":"/git-study01/:2:1","tags":["Git学习"],"title":"Git Study01","uri":"/git-study01/"},{"categories":["学习"],"content":"工作流程 在工作目录中添加、修改文件 将需要进行版本管理的文件放入暂存区 将暂存区的文件提交到git仓库 因此，git管理的文件有三种状态：已修改，已暂存，已提交 ","date":"2021-04-11","objectID":"/git-study01/:2:2","tags":["Git学习"],"title":"Git Study01","uri":"/git-study01/"},{"categories":["学习"],"content":"Git项目搭建 ","date":"2021-04-11","objectID":"/git-study01/:3:0","tags":["Git学习"],"title":"Git Study01","uri":"/git-study01/"},{"categories":["学习"],"content":"创建工作目录与常用指令 工作目录(WorkSpace)一般就是你希望Git帮你管理的文件夹，可以是项目的目录，也可以是一个空目录，建议不要有中文。 日常使用只要记住以下6个命令 Git日常命令\u0026ldquo;Git日常命令\u0026rdquo; \"\rGit日常命令\r ","date":"2021-04-11","objectID":"/git-study01/:3:1","tags":["Git学习"],"title":"Git Study01","uri":"/git-study01/"},{"categories":["学习"],"content":"本地仓库搭建 创建全新的仓库，需要用GIT管理的项目的根目录执行： # 在当前目录新建一个Git代码库 $ git init 执行后可以看见，在项目中多出了一个git目录，关于版本等的所有信息都在这个目录里面 ","date":"2021-04-11","objectID":"/git-study01/:3:2","tags":["Git学习"],"title":"Git Study01","uri":"/git-study01/"},{"categories":["学习"],"content":"克隆远程仓库 将远程服务器上的仓库完全镜像一份至本地 # 克隆一个项目和她的整个代码历史(版本信息) $ git clone [url] ","date":"2021-04-11","objectID":"/git-study01/:3:3","tags":["Git学习"],"title":"Git Study01","uri":"/git-study01/"},{"categories":["学习"],"content":"Git文件操作 ","date":"2021-04-11","objectID":"/git-study01/:4:0","tags":["Git学习"],"title":"Git Study01","uri":"/git-study01/"},{"categories":["学习"],"content":"文件4种状态 版本控制就是对文件的版本控制，要对文件进行修改、提交等操作，首先要知道文件当前在什么状态，不然可能会提交了现在不想提交的文件，或者要提交的文件没提交上 Untracked : 未跟踪，此文件在文件夹中，但是并没有加入到git库，不参与版本控制，通过 git add 状态变为 Staged Unmodify : 文件已经入库，未修改，即版本库中的文件快照内容与文件中完全一致，这种类型的文件有两种去处，如果她被修改，而变为 Modified 。如果使用 git rm 移出版本库，则称为 Untracked 文件 Modified : 文件已修改，仅仅是修改，并没有进行其他操作，这个文件也有两个去处，通过 git add 可进入暂存 Staged 状态，使用 git checkout 则丢弃修改过的，返回 Unmodify 状态，这个 git checkout 即从库中取出文件，覆盖当前修改 Staged : 暂存状态，执行 git commit 则将修改同步到库中，这时库中的文件和本地的文件又变为一致，文件为 UNmodify 状态，执行 git reset HEAD filename 取消暂存，文件状态为 Modified ","date":"2021-04-11","objectID":"/git-study01/:4:1","tags":["Git学习"],"title":"Git Study01","uri":"/git-study01/"},{"categories":["学习"],"content":"查看文件状态 # 查看指定文件状态 git status [filename] # 查看所有文件状态 git status ","date":"2021-04-11","objectID":"/git-study01/:4:2","tags":["Git学习"],"title":"Git Study01","uri":"/git-study01/"},{"categories":["学习"],"content":"忽略文件 有些时候不想把某些文件纳入版本控制中，比如数据库文件，临时文件，设计文件等 在主目录下建立\".gitingnore\"文件，此文件有如下规则 忽略文件中的空行或者以井号(#)开始的行都会被忽略 可以使用Linux通配符。例如：星号(*)代表任意多个字符，问号(?)代表一个字符，方括号([abc])代表可选字符范围，大括号({string1,string2…})代表可选的字符串等 如果名称的最前面有一个感叹号(!)，表示例外规则，将不被忽略 如果名称的最前面是一个路径分隔符(/)，表示要忽略的文件在此目录下，而子目录中的文件不被忽略 如果名称的最后名是一个路径分隔符(/)，表示要忽略的是此目录下该名称的子目录，而非文件(默认文件或目录都被忽略) # 为注释 # 忽略所有 .txt 结尾的文件 *.txt # lib.txt 除外 !lib.txt # 忽略项目根目录下的temp文件，不包含其他目录 /temp # 忽略build/目录下的所有文件 build/ # 忽略doc/file.txt但是不包括 doc/xx/aa.txt doc/*.txt ","date":"2021-04-11","objectID":"/git-study01/:4:3","tags":["Git学习"],"title":"Git Study01","uri":"/git-study01/"},{"categories":["学习"],"content":"Linux Study 01","date":"2021-04-11","objectID":"/linux-study01/","tags":["Linux学习"],"title":"Linux Study01","uri":"/linux-study01/"},{"categories":["学习"],"content":"基本的Linux命令 cd : 改变目录 cd.. : 回退到上一个目录，直接cd进入默认目录 pwd : 显示当前所在的目录路径 ls(ll) : 都是列出当前目录中的所有文件，只不过ll列出的内容更为详细 touch : 新建一个文件，如 touch index.js 就会在当前目录下新建一个index.js文件 rm : 删除一个文件，rm index.js 就会把index.js文件删除 mkdir : 新建一个目录，就是新建一个文件夹 rm -r : 删除一个文件夹， rm -r src 删除src目录 mv 移动文件， mv index.html src index index.html是我们要移动的文件，src是目标文件夹，当然这样写，必须保证文件和目标文件夹在同一目录下 reset : 重新初始化终端/清屏 clear : 清屏 history : 查看命令历史 help : 帮助 exit : 退出 # : 表示注释 ","date":"2021-04-11","objectID":"/linux-study01/:1:0","tags":["Linux学习"],"title":"Linux Study01","uri":"/linux-study01/"},{"categories":["面试"],"content":"20210406启禾网络","date":"2021-04-06","objectID":"/interview-2021-04-06/","tags":["面试"],"title":"Interview 2021 04 06","uri":"/interview-2021-04-06/"},{"categories":["面试"],"content":"自我介绍 ","date":"2021-04-06","objectID":"/interview-2021-04-06/:1:0","tags":["面试"],"title":"Interview 2021 04 06","uri":"/interview-2021-04-06/"},{"categories":["面试"],"content":"说一下MVC架构 ","date":"2021-04-06","objectID":"/interview-2021-04-06/:2:0","tags":["面试"],"title":"Interview 2021 04 06","uri":"/interview-2021-04-06/"},{"categories":["面试"],"content":"slice切片的概念 在Go中slice不仅是一个切片动作，还是一种数据结构。 slice结构都由三部分组成：容量，长度和指向底层数组某元素的指针。 虽然nil slice和空slice的长度和容量虽然都为0，输出结果也都为[]，且都不存储任何数据，但是它们是不同的。nil slice不会指向底层数组，而空slice会指向底层数组，只不过这个底层数组暂时是空数组 ","date":"2021-04-06","objectID":"/interview-2021-04-06/:3:0","tags":["面试"],"title":"Interview 2021 04 06","uri":"/interview-2021-04-06/"},{"categories":["面试"],"content":"一个生产者多个消费者怎么使用channel ","date":"2021-04-06","objectID":"/interview-2021-04-06/:4:0","tags":["面试"],"title":"Interview 2021 04 06","uri":"/interview-2021-04-06/"},{"categories":["面试"],"content":"双重for循环怎么跳出 方法1：内层for循环赋值一个bool，break跳出，外层for判断bool，break跳出 方法2：使用goto+标签跳出多层循环（label标签） 方法3：使用break+标签跳出循环 ","date":"2021-04-06","objectID":"/interview-2021-04-06/:5:0","tags":["面试"],"title":"Interview 2021 04 06","uri":"/interview-2021-04-06/"},{"categories":["面试"],"content":"redis五种数据结构 string list set zset hash ","date":"2021-04-06","objectID":"/interview-2021-04-06/:6:0","tags":["面试"],"title":"Interview 2021 04 06","uri":"/interview-2021-04-06/"},{"categories":["面试"],"content":"经常使用redis的哪种数据结构 ","date":"2021-04-06","objectID":"/interview-2021-04-06/:7:0","tags":["面试"],"title":"Interview 2021 04 06","uri":"/interview-2021-04-06/"},{"categories":["面试"],"content":"Gin框架的了解 ","date":"2021-04-06","objectID":"/interview-2021-04-06/:8:0","tags":["面试"],"title":"Interview 2021 04 06","uri":"/interview-2021-04-06/"},{"categories":["面试"],"content":"map和slice分别怎么删除元素 map直接使用delete slice取需要删除的元素其他切片元素 ","date":"2021-04-06","objectID":"/interview-2021-04-06/:9:0","tags":["面试"],"title":"Interview 2021 04 06","uri":"/interview-2021-04-06/"},{"categories":["面试"],"content":"go中interface的概念 接口是一种抽象类型，是多个方法声明的集合。在Go中只要目标类型实现了接口要求的所有方法，就说它实现了这个接口 使用type关键词定义接口 type Duck interface { Eat() } 接口赋值分为两种情况 将对象实例赋值给接口 var c Duck = \u0026Cat{} c.Eat() 将对象实例赋值给接口时，一定要传结构体指针，如果直接传结构体会报错 2. 将一个接口赋值给另一个接口 已经初始化的接口变量c1直接赋值给另一个接口变量c2，要求c2的方法集是c 1方法集的子集 具有0个方法的接口称为空接口，它的表示为interface{}。由于空接口有0个方法，所以所有类型都实现了空接口 类型断言 x.(T) 其中x是接口类型的表达式，T是断言类型。作用是判断操作数的动态类型是否满足指定的断言类型。如果断言只返回一个值，类型错误报panic，如果返回两个值，类型错误另一个值为false。 ","date":"2021-04-06","objectID":"/interview-2021-04-06/:10:0","tags":["面试"],"title":"Interview 2021 04 06","uri":"/interview-2021-04-06/"},{"categories":["面试"],"content":"orm使用的什么 ","date":"2021-04-06","objectID":"/interview-2021-04-06/:11:0","tags":["面试"],"title":"Interview 2021 04 06","uri":"/interview-2021-04-06/"},{"categories":["面试"],"content":"mysql的存储引擎 ","date":"2021-04-06","objectID":"/interview-2021-04-06/:12:0","tags":["面试"],"title":"Interview 2021 04 06","uri":"/interview-2021-04-06/"},{"categories":["面试"],"content":"go读写锁的使用 读写锁sync.RWMutex，写锁Lock和Unlock，读锁RLock和RUnlock 读写锁可以让多个读同时进行，同时读取，但对于写操作是完全互斥的。也就是说，当一个goroutine进行写操作时，其他的goroutine既不能进行读操作，也不能进行写操作。 ","date":"2021-04-06","objectID":"/interview-2021-04-06/:13:0","tags":["面试"],"title":"Interview 2021 04 06","uri":"/interview-2021-04-06/"},{"categories":["面试"],"content":"redis分布式锁 设置锁setnx key value，设置锁的过期时间setex key second value。 当redis为集群，获取到多数节点的获取锁。 ","date":"2021-04-06","objectID":"/interview-2021-04-06/:14:0","tags":["面试"],"title":"Interview 2021 04 06","uri":"/interview-2021-04-06/"},{"categories":["面试"],"content":"Go Interview 08-Go map","date":"2021-03-25","objectID":"/go-interview-08/","tags":["golang"],"title":"Go Interview 08","uri":"/go-interview-08/"},{"categories":["面试"],"content":"什么是map map是一个可以存储key/value对的一种数据结构，map像slice一样是引用类型，map内部实现是一个hash table，因此在map中存入数据是无序的。而每次从map中读取数据也是无序的，因为在golang设计之初，map迭代器的顺序就是随机的，有别于C/C++，虽然存入map的数据是无序的，但是每次从map中取出的数据一样的。 ","date":"2021-03-25","objectID":"/go-interview-08/:1:0","tags":["golang"],"title":"Go Interview 08","uri":"/go-interview-08/"},{"categories":["面试"],"content":"声明和初始化 // 声明一个map，因为map是引用类型，所以m是nil var m map[keytype]valuetype // 初始化方式1，空map，空并不是nil m := map[keytype]valuetype{} // 初始化方式2，两种初始化方式相同 m := make(make[keytype]valuetype) ","date":"2021-03-25","objectID":"/go-interview-08/:2:0","tags":["golang"],"title":"Go Interview 08","uri":"/go-interview-08/"},{"categories":["面试"],"content":"基本操作 package main import \"fmt\" func main() { m := map[string]int{} //增加一个map m[\"tony\"] = 10 //删除一个key = tony的map delete(m, \"tony\") //修改key=tony的值 m[\"tony\"] = 20 //判断某个key是否存在 if _, ok := m[\"tony\"]; ok { fmt.Println(\"tony is exists\") } //遍历map for key, value := range m { fmt.Println(key, value) } //使用多个值对map进行初始化 m1 := map[string]int{ \"Tina\": 10, \"Dviad\": 20, \"Tom\": 5, } fmt.Println(m1) } ","date":"2021-03-25","objectID":"/go-interview-08/:3:0","tags":["golang"],"title":"Go Interview 08","uri":"/go-interview-08/"},{"categories":["面试"],"content":"key和value可以使用什么类型 key：只要是可比较(可以使用==进行比较，两边的操作数可以互相赋值)的类型就可以，像整型，字符串类型，浮点型，数组(必须类型相同)；而map，slice和function不能作为key的类型 value：任何类型都可以 ","date":"2021-03-25","objectID":"/go-interview-08/:4:0","tags":["golang"],"title":"Go Interview 08","uri":"/go-interview-08/"},{"categories":["面试"],"content":"对map进行并发访问时需要增加同步机制 map在并发访问中使用不安全，因为不清楚当时对map进行读写的时候会发生什么，如果像通过goroutine进行并发访问，则需要一种同步机制来保证访问数据的安全性。一种方法是使用sync.RWMutex //通过匿名函数结构体声明一个counter，变量中包含map和sync.RWMutex var counter = struct { sync.RWMutex m map[string]int }{m: make(map[string]int)} //读取数据的时候使用读锁 counter.RLock() n := counter.m[\"Tony\"] counter.RUnlock() fmt.Println(n) //写数据的时候使用写锁 counter.Lock() counter.m[\"Tony\"]++ counter.Unlock() fmt.Println(counter.m[\"Tony\"]) ","date":"2021-03-25","objectID":"/go-interview-08/:5:0","tags":["golang"],"title":"Go Interview 08","uri":"/go-interview-08/"},{"categories":["面试"],"content":"Go Interview 07-Go互斥锁的两种实现","date":"2021-03-25","objectID":"/go-interview-07/","tags":["golang"],"title":"Go Interview 07","uri":"/go-interview-07/"},{"categories":["面试"],"content":"Go互斥锁的两种实现 1.用Mutex实现 package main import ( \"fmt\" \"sync\" ) var num int var mtx sync.Mutex var wg sync.WaitGroup func add() { //mutex锁住 mtx.Lock() //mutex解锁 defer mtx.Unlock() //wg计数器减一 defer wg.Done() num += 1 } func main() { for i := 0; i \u003c 100; i++ { wg.Add(1) go add() } //wg.wait代替了之前的time.sleep。wg里面相当于有个计数器，只有计数器没了才继续进行，否则就阻塞。 wg.Wait() fmt.Println(num) } 使用chan实现 package main import ( \"fmt\" \"sync\" ) var num int func add(h chan int, wg *sync.WaitGroup) { defer wg.Done() h \u003c- 1 num += 1 \u003c-h } func main() { var wg = \u0026sync.WaitGroup{} h := make(chan int, 1) for i := 0; i \u003c 100; i++ { wg.Add(1) go add(h, wg) } wg.Wait() fmt.Println(num) } ","date":"2021-03-25","objectID":"/go-interview-07/:1:0","tags":["golang"],"title":"Go Interview 07","uri":"/go-interview-07/"},{"categories":["学习"],"content":"Http,TCP/IP学习","date":"2021-03-25","objectID":"/httptcpip-study-01/","tags":["Http,TCP/IP"],"title":"Httptcpip Study 01","uri":"/httptcpip-study-01/"},{"categories":["学习"],"content":"osi七层参考模型 osi七层模型\u0026ldquo;osi七层模型\u0026rdquo; \"\rosi七层模型\r ","date":"2021-03-25","objectID":"/httptcpip-study-01/:1:0","tags":["Http,TCP/IP"],"title":"Httptcpip Study 01","uri":"/httptcpip-study-01/"},{"categories":["学习"],"content":"TCP/IP五层模型 TCP/IP五层模型\u0026ldquo;TCP/IP五层模型\u0026rdquo; \"\rTCP/IP五层模型\r 应用层的主要协议有：http、smtp、ssh协议 传输控制层的主要协议有：tcp、udp协议 tcp协议面向连接，能正确处理丢包，传输顺序错乱的问题，但是为了建立和断开连接，需要至少7次收发包，资源浪费 udp协议面向无连接，不管对方有没有收到，如果要得到通知，需要通过应用层 网络层的主要协议有：ip协议 ","date":"2021-03-25","objectID":"/httptcpip-study-01/:2:0","tags":["Http,TCP/IP"],"title":"Httptcpip Study 01","uri":"/httptcpip-study-01/"},{"categories":["学习"],"content":"TCP三次握手 客户端发送带有SYN标志的数据包到服务端。一次握手 服务端发送带有SYN/ACK标志的数据包到客户端。二次握手 客户端发送带有ACK标志的数据包到服务端。三次握手 ","date":"2021-03-25","objectID":"/httptcpip-study-01/:3:0","tags":["Http,TCP/IP"],"title":"Httptcpip Study 01","uri":"/httptcpip-study-01/"},{"categories":["学习"],"content":"TCP四次挥手 客户端发送一个FIN，用来关闭客户端到服务端的数据传输 服务端收到FIN，发回ACK确认 服务端关闭与客户端的连接，发送FIN到客户端 客户端发回ACK确认 ","date":"2021-03-25","objectID":"/httptcpip-study-01/:4:0","tags":["Http,TCP/IP"],"title":"Httptcpip Study 01","uri":"/httptcpip-study-01/"},{"categories":["学习"],"content":"HTTP HTTP协议是建立在TCP协议基础上的，当浏览器需要从服务器获取网页数据的时候，会发出一次HTTP请求。HTTP会通过TCP建立一个到服务器的连接通道，当本次请求需要的数据完毕后，HTTP会立即与TCP断开连接，这个过程是很短的。所以HTTP连接是一种短连接，是一种无状态连接。 这个所谓的无状态，是指浏览器每次向服务器发起请求时，不是通过一个连接，而是每次都建立一个新的连接。如果是一个连接的话，服务进程中就能保持住这个连接并且在内存中记住一些信息状态。而每次请求结束后，连接就关闭了，相关内容就释放了，所以记不住任何状态，成为无状态连接。 ","date":"2021-03-25","objectID":"/httptcpip-study-01/:5:0","tags":["Http,TCP/IP"],"title":"Httptcpip Study 01","uri":"/httptcpip-study-01/"},{"categories":["学习"],"content":"HTTP英文全称 超文本传输协议 ","date":"2021-03-25","objectID":"/httptcpip-study-01/:6:0","tags":["Http,TCP/IP"],"title":"Httptcpip Study 01","uri":"/httptcpip-study-01/"},{"categories":["学习"],"content":"状态码 2xx 成功 200 ok，表示从客户端发来的请求在服务端被正确处理 204 No Content，表示请求成功，但响应报文不含实体的主体部分 206 Partial Content，进行范围请求 3xx 重定向 301 moved permanently，永久性重定向，表示资源已被分配了新的URL 302 found，临时性重定向，表示资源临时被分配了新的URL 303 see other，表示资源存在另一个URL，应使用GET方法定向获取资源 304 not modified，表示服务器允许访问资源，但因发生请求未满足条件的情况 307 temporary redirect，临时重定向，和302含义相同 4xx 客户端错误 400 bad request，请求报文存在语法错误 401 unauthorized，表示发送的请求需要有通过HTTP认证的认证信息 403 forbidden，表示对请求资源的访问被服务器拒绝 404 not found，表示服务器上没有找到对应资源 5xx 服务器错误 500 internal server error，表示服务器端执行请求时发生错误 503 service unavailable，表示服务器暂时处于超负载或正在停机维护，无法处理请求 ","date":"2021-03-25","objectID":"/httptcpip-study-01/:7:0","tags":["Http,TCP/IP"],"title":"Httptcpip Study 01","uri":"/httptcpip-study-01/"},{"categories":["学习"],"content":"HTTP的报文结构 HTTP请求报文 请求行 请求头 空行 请求数据 HTTP响应报文 状态行 消息报头 响应正文 ","date":"2021-03-25","objectID":"/httptcpip-study-01/:8:0","tags":["Http,TCP/IP"],"title":"Httptcpip Study 01","uri":"/httptcpip-study-01/"},{"categories":["学习"],"content":"TCP和UDP的区别 TCP：面向连接，可靠，速度慢，效率低 UDP：无连接，不可靠，速度快，效率高 当进程需要传输可靠的数据时应使用TCP，当进程需要高效传输数据，可以忽略可靠性时应使用UDP TCP如何保证可靠性： 数据包校验 超时重传机制 应答机制 对失序数据包重排序 TCP还能提供流量控制 ","date":"2021-03-25","objectID":"/httptcpip-study-01/:9:0","tags":["Http,TCP/IP"],"title":"Httptcpip Study 01","uri":"/httptcpip-study-01/"},{"categories":["学习"],"content":"HTTP和HTTPS有什么区别 HTTP协议传输的数据都是未加密的，也就是明文的，因此使用HTTP协议传输隐私信息非常不安全。为了保证这些隐私信息能加密传输，于是网景公司设计了SSL(Secure Socket Layer)协议用于对HTTP协议传输的数据加密，从而也就诞生了HTTPS。 简单来说，HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，要比HTTP安全 HTTPS和HTTP的区别主要如下： HTTPS协议需要到CA申请证书，一般免费证书比较少，因而需要一定费用 HTTP是超文本传输协议，信息是明文传输，HTTPS则是具有安全性的SSL加密传输协议 HTTP和HTTPS使用的是完全不同的连接方式，用的端口也不一样，HTTP是80，HTTPS是443 HTTP的连接很简单，是无状态的，HTTPS协议是由SSL+HTTP协议构建的可进行加密传输，身份认证的网络协议，比HTTP协议安全 ","date":"2021-03-25","objectID":"/httptcpip-study-01/:10:0","tags":["Http,TCP/IP"],"title":"Httptcpip Study 01","uri":"/httptcpip-study-01/"},{"categories":["学习"],"content":"HTTP1.0和HTTP1.1的区别 HTTP1.0中浏览器与服务器只保持短暂连接，浏览器的每次请求都与服务器建立一个TCP连接，服务器完成请求后立即断开TCP连接，服务器不跟踪每个客户也不记录过去请求 HTTP1.1提供永久性连接(即1.0非持久连接，HTTP1.0没有host字段) HTTP1.1中添加了HOST请求头字段后，实现了一台WEB服务器上可以在同一个IP地址和端口上使用不同的主机名来创建多个虚拟WEB站点 HTTP1.1提供身份认证 ","date":"2021-03-25","objectID":"/httptcpip-study-01/:11:0","tags":["Http,TCP/IP"],"title":"Httptcpip Study 01","uri":"/httptcpip-study-01/"},{"categories":["面试"],"content":"Go Interview 06-go两个协程交替打印1-100的奇数偶数","date":"2021-03-25","objectID":"/go-interview-06/","tags":["golang"],"title":"Go Interview 06","uri":"/go-interview-06/"},{"categories":["面试"],"content":"go两个协程交替打印1-100的奇数偶数 package main import ( \"fmt\" \"time\" ) const Pool = 100 func goroutine1(msg chan int) { for i:=1; i\u003c=Pool; i++ { msg \u003c- i if i%2 == 1 { fmt.Println(\"goroutine1:\", i) } } } func goroutine2(msg chan int) { for i := 1; i \u003c= Pool; i++ { \u003c- msg if i%2 == 0 { fmt.Println(\"goroutine2:\", i) } } } func main() { msg := make(chan int) go goroutine1(msg) go goroutine2(msg) time.Sleep(time.Second) } ","date":"2021-03-25","objectID":"/go-interview-06/:1:0","tags":["golang"],"title":"Go Interview 06","uri":"/go-interview-06/"},{"categories":["面试"],"content":"Go Interview 05-select机制|进程、线程、协程区别","date":"2021-03-24","objectID":"/go-interview-05/","tags":["golang"],"title":"Go Interview 05","uri":"/go-interview-05/"},{"categories":["面试"],"content":"Go的select机制 select机制用来处理异步IO问题 select机制最大的一条限制就是每个case语句里必须是一个IO操作 golang在语言级别支持select关键字 ","date":"2021-03-24","objectID":"/go-interview-05/:1:0","tags":["golang"],"title":"Go Interview 05","uri":"/go-interview-05/"},{"categories":["面试"],"content":"进程、线程、协程之间的区别 进程是资源的分配和调度的一个独立单元，而线程是CPU调度的基本单位 同一个进程中可以包含多个线程 进程结束后，她拥有的所有线程都将销毁，而线程的结束不会影响同个进程中其他线程的结束。 线程共享整个进程的资源(寄存器、堆栈、上下文)，一个进程至少包含一个线程 进程的创建使用fork或vfork，而线程的创建使用pthread_create 线程中执行时，一般要进行同步和互斥，因为他们共享同一进程的所有资源 进程是资源分配的单位 线程是操作系统调度的单位 进程切换需要的资源最大，效率很低。线程切换需要的资源一般，效率一般。协程切换需要的资源很小，效率高。多进程，多线程根据cpu核数不一样可能是并行也可能是并发的。协程的本质就是使用当前进程在不同的函数代码中切换执行，可以理解为并行。协程是一个用户层面的概念，不同协程的模型实现可能是单线程的，也可能是多线程的 进程拥有独立的堆和栈，既不共享堆，也不共享栈。进程由操作系统调度。(全局变量保存在堆中，局部变量及函数保存在栈中) 线程拥有独立的栈和共享的堆。共享堆，不共享栈，线程由操作系统调度。(标准线程) 协程和线程一个共享堆，不共享栈，协程由程序员在协程里显式调度 一个应用程序一般对应一个进程，一个进程一般有一个主线程，还有若干个辅助线程，线程之间是平行运行的，在线程里面可以开协程，让程序在特定时间运行 协程和线程的区别：协程避免了无意义的调度，由此可以提高性能，但也因此，程序员必须自己承担调度的责任，同时协程也失去了标准线程使用多CPU的能力 ","date":"2021-03-24","objectID":"/go-interview-05/:2:0","tags":["golang"],"title":"Go Interview 05","uri":"/go-interview-05/"},{"categories":["面试"],"content":"Go Interview 04-beego|goconvey|GoStub","date":"2021-03-24","objectID":"/go-interview-04/","tags":["golang"],"title":"Go Interview 04","uri":"/go-interview-04/"},{"categories":["面试"],"content":"Go中的beego框架 beego是一个golang实现的轻量级HTTP框架 beego可以通过注释路由、正则路由等多种方式完成url路由注入 可以使用bee new工具生成空工程，然后使用bee run命令自动热编译 ","date":"2021-03-24","objectID":"/go-interview-04/:1:0","tags":["golang"],"title":"Go Interview 04","uri":"/go-interview-04/"},{"categories":["面试"],"content":"Go中的goconvey框架 goconvey是一个支持golang的单元测试框架 goconvey能够自动监控文件并启动测试，并可以将测试结果实时输出到web界面 goconvey提供了非常丰富的断言简化测试用例的编写 ","date":"2021-03-24","objectID":"/go-interview-04/:2:0","tags":["golang"],"title":"Go Interview 04","uri":"/go-interview-04/"},{"categories":["面试"],"content":"Go中，GoStub的作用是什么 GoStub可以对全局变量打桩 GoStub可以对函数打桩 GoStub不可以对类的成员方法打桩 GoStub可以打动态桩，例如对一个函数打桩后，多次调用该函数会有不同的行为 ","date":"2021-03-24","objectID":"/go-interview-04/:3:0","tags":["golang"],"title":"Go Interview 04","uri":"/go-interview-04/"},{"categories":["面试"],"content":"Go Interview 03-for循环|switch|没有隐藏的this指针|引用类型|指针运算|main函数|同步锁|channel特性|触发异常场景","date":"2021-03-24","objectID":"/go-interview-03/","tags":["golang"],"title":"Go Interview 03","uri":"/go-interview-03/"},{"categories":["面试"],"content":"Go中的for循环 for循环支持continue和break来控制循环，但是她提供了一个更高级break，可以选择中断那个循环，for循环不支持以逗号为间隔的多个赋值语句，必须使用平行赋值的方式来初始化多个变量 ","date":"2021-03-24","objectID":"/go-interview-03/:1:0","tags":["golang"],"title":"Go Interview 03","uri":"/go-interview-03/"},{"categories":["面试"],"content":"Go中的switch 当个case中可以出现多个结果 只有在case中明确添加fallthrough关键字，才会继续执行紧跟的下一个case ","date":"2021-03-24","objectID":"/go-interview-03/:2:0","tags":["golang"],"title":"Go Interview 03","uri":"/go-interview-03/"},{"categories":["面试"],"content":"Go中没有隐藏的this指针，这句话是什么意思 方法施加的对象显示传递，没有被隐藏起来 golang的面向对象表达更直观，对于面向过程只是换了一种语法形式来表达 方法施加的对象不需要非得是指针，也不用非得叫this ","date":"2021-03-24","objectID":"/go-interview-03/:3:0","tags":["golang"],"title":"Go Interview 03","uri":"/go-interview-03/"},{"categories":["面试"],"content":"Go中引用类型包含什么 数组切片，字典(map)，通道(channel)，接口(interface) ","date":"2021-03-24","objectID":"/go-interview-03/:4:0","tags":["golang"],"title":"Go Interview 03","uri":"/go-interview-03/"},{"categories":["面试"],"content":"Go中指针运算有哪些 可以通过\u0026取指针的地址 可以通过*取指针指向的数据 ","date":"2021-03-24","objectID":"/go-interview-03/:5:0","tags":["golang"],"title":"Go Interview 03","uri":"/go-interview-03/"},{"categories":["面试"],"content":"说说Go的main函数 main函数不能带参数 main函数不能定义返回值 main函数所在的包必须是main包 main函数中可以使用flag包来获取和解析命令行参数 ","date":"2021-03-24","objectID":"/go-interview-03/:6:0","tags":["golang"],"title":"Go Interview 03","uri":"/go-interview-03/"},{"categories":["面试"],"content":"Go同步锁 当一个goroutine获得了Mutex后，其他的goroutine就只能乖乖的等待了，除非该goroutine释放这个Mutex RWMutex在读锁占用的情况下，会阻止写，但不会阻止写 RWMutex在写锁占用的情况下，会阻止任何goroutine(无论是读还是写)，整个锁相当于由该goroutine独占 ","date":"2021-03-24","objectID":"/go-interview-03/:7:0","tags":["golang"],"title":"Go Interview 03","uri":"/go-interview-03/"},{"categories":["面试"],"content":"channel特性 给一个nil channel发送数据，造成永久阻塞 从一个nil channel接收数据，造成永久阻塞 给一个已经关闭的channel发送数据，引起panic 从一个已经关闭的channel接收数据，如果缓冲区为空，则返回一个零值 无缓冲的channel是同步的，有缓冲的channel是非同步的 ","date":"2021-03-24","objectID":"/go-interview-03/:8:0","tags":["golang"],"title":"Go Interview 03","uri":"/go-interview-03/"},{"categories":["面试"],"content":"Go触发异常的场景有哪些 空指针解析 下标越界 除数为0 调用panic函数 ","date":"2021-03-24","objectID":"/go-interview-03/:9:0","tags":["golang"],"title":"Go Interview 03","uri":"/go-interview-03/"},{"categories":["面试"],"content":"Go Interview 02-Printf()、Sprintf()和Fprintf()函数的区别用法是什么|数组和切片的区别|解释go常用命令的作用|说说go中的协程","date":"2021-03-24","objectID":"/go-interview-02/","tags":["golang"],"title":"Go Interview 02","uri":"/go-interview-02/"},{"categories":["面试"],"content":"在Go中，Printf()、Sprintf()和Fprintf()函数的区别用法是什么 都是把格式好的字符串输出，只是输出的目标不同 Printf()，是把格式字符串输出到标准输出(一般是屏幕，可以重定向) Printf()是和标准输出文件(stdout)关联的，Fprintf()没有这个限制 Sprintf()，是把格式字符串输出到指定字符串中，所以参数比Printf()多一个char*。那就是目标字符串地址。 Fprintf()，是把格式字符串输出到指定文件设备中，所以参数比Printf()多一个File*。主要用于文件操作 Fprintf()是格式化输出到一个stream，通常是到文件 ","date":"2021-03-24","objectID":"/go-interview-02/:1:0","tags":["golang"],"title":"Go Interview 02","uri":"/go-interview-02/"},{"categories":["面试"],"content":"数组和切片的区别 数组是具有固定长度且拥有零个或者多个相同数据类型元素的序列。数组的长度是数组类型的一部分，所以[3]int和[4]int是两种不同的数组类型。 数组需要制定大小，不指定也会根据初始化自动推算出大小，不可改变。 数组是值传递 数组是内置(build-in)类型，是一组同类型数据的集合，他是值类型，通过从零开始的下标索引访问元素值。在初始化后长度是固定的，无法修改其长度。当作为方法的参数传入时将复制一份数组而不是引用同一指针。数组的长度也是其类型的一部分，通过内置函数len(array)获取其长度 数组定义 var array [10]int var array = [5]int{1,2,3,4,5} 2.切片表示拥有一个相同数据类型元素的可变长度的序列。切片是一种轻量级的数据结构，他有三个属性：指针、长度和容量。 切片不需要指定大小 切片是地址传递 切片可以通过数组初始化，也可以通过内置函数make()初始化，初始化时len=cap，在追加元素时如果容量cap不足时将按len的2倍扩容 切片定义 var slice []type = make([]type, len) ","date":"2021-03-24","objectID":"/go-interview-02/:2:0","tags":["golang"],"title":"Go Interview 02","uri":"/go-interview-02/"},{"categories":["面试"],"content":"解释以下命令的作用 go env： 用于查看go的环境变量 go run： 用于编译并运行go源码文件 go build： 用于编译源码文件、代码包、依赖包 go get： 用于动态获取远程包 go install： 用于编译go文件，并将编译结构安装到bin、pkg目录 go clean： 用于清理工作目录，删除编译和安装遗留的目标文件 go version： 用于查看go的版本信息 ","date":"2021-03-24","objectID":"/go-interview-02/:3:0","tags":["golang"],"title":"Go Interview 02","uri":"/go-interview-02/"},{"categories":["面试"],"content":"说说Go中的协程 协程和线程都可以实现程序的并发运行 通过channel来进行协程间的通信 只需要在函数调用前添加go关键字即可实现go协程，创建并发任务。 关键字go并非执行并发任务，而是创建一个并发任务单元 ","date":"2021-03-24","objectID":"/go-interview-02/:4:0","tags":["golang"],"title":"Go Interview 02","uri":"/go-interview-02/"},{"categories":["实例"],"content":"Go Instance 23-信号、退出","date":"2021-03-24","objectID":"/go-instance-23/","tags":["golang"],"title":"Go Instance 23","uri":"/go-instance-23/"},{"categories":["实例"],"content":"信号 有时候我们希望Go能智能的处理Unix信号。例如，希望当服务器接收到一个SIGTERM信号时能自动关机，或者一个命令号工具在接收到一个SIGINT信号时停止处理输入信息。 package main import ( \"fmt\" \"os\" \"os/signal\" \"syscall\" ) func main() { sigs := make(chan os.Signal, 1) done := make(chan bool, 1) //signal.Notify注册这个给定的通道用于接收特定的信号 signal.Notify(sigs, syscall.SIGINT, syscall.SIGTERM) //开启一个Go协程执行阻塞信号接收的操作 //当sign接收到一个值,将其打印,然后通知程序可以退出了 go func() { sig := \u003c-sigs fmt.Println() fmt.Println(sig) done \u003c- true }() //程序在这等待,直到得到了期待的信号,然后退出 fmt.Println(\"awaiting signal\") \u003c- done fmt.Println(\"exiting\") } ","date":"2021-03-24","objectID":"/go-instance-23/:1:0","tags":["golang"],"title":"Go Instance 23","uri":"/go-instance-23/"},{"categories":["实例"],"content":"退出 使用os.Exit来立即进行带给定状态的退出 package main import ( \"fmt\" \"os\" ) func main() { //当使用os.Exit时defer将不会执行 defer fmt.Println(\"!\") //退出并且退出状态为3 os.Exit(3) } ","date":"2021-03-24","objectID":"/go-instance-23/:2:0","tags":["golang"],"title":"Go Instance 23","uri":"/go-instance-23/"},{"categories":["实例"],"content":"Go Instance 22-行过滤器、命令号标志","date":"2021-03-23","objectID":"/go-instance-22/","tags":["golang"],"title":"Go Instance 22","uri":"/go-instance-22/"},{"categories":["实例"],"content":"行过滤器 一个行过滤器在读取标准输入流的输入，处理该输入，然后将得到一些的结果输出到标准输出的程序中是常见的一个功能。grep和sed是常见的行过滤器。 package main import ( \"bufio\" \"fmt\" \"os\" \"strings\" ) //将所有的输入文字转化为大写的 func main() { //对os.Stdin使用一个带缓冲的Scanner //可以直接使用方便的Scan方法来直接读取一行 //每次调用该方法可以让scanner读取下一行 scanner := bufio.NewScanner(os.Stdin) //Text返回当前的token，现在是输入下一行 if scanner.Scan() { str := strings.ToUpper(scanner.Text()) //输出大写的行 fmt.Println(str) } //检查Scan的错误，文件结束符是可以接收的，并且不会被Scan当做一个错误 if err := scanner.Err(); err != nil { fmt.Fprintf(os.Stderr, \"error:\", err) os.Exit(1) } } ","date":"2021-03-23","objectID":"/go-instance-22/:1:0","tags":["golang"],"title":"Go Instance 22","uri":"/go-instance-22/"},{"categories":["实例"],"content":"命令行标志 命令行标志是命令行程序指定选项的常用方式 package main import ( \"flag\" \"fmt\" ) func main() { //基本的标记只支持字符串，整数和布尔值 //声明一个默认值为foo的字符串标志word并带有一个简短的描述 //这个flag.string返回的是一个指针 wordPtr := flag.String(\"word\", \"foo\", \"a string\") //使用和word标志相同的方式声明numb和fork标志 numbPtr := flag.Int(\"numb\", 42, \"an int\") boolPtr := flag.Bool(\"fork\", false, \"a bool\") //用程序中已有的标志来声明一个标志也是可以的。注意在声明中使用参数的指针 var svar string flag.StringVar(\u0026svar, \"svar\", \"bar\", \"a string var\") //所有标志都声明完成后，调用flag.Parse()来执行命令解析 flag.Parse() //输出解析的选项以及后面的位置参数 fmt.Println(\"word:\", *wordPtr) fmt.Println(\"numB:\", *numbPtr) fmt.Println(\"fork:\", *boolPtr) fmt.Println(\"svar:\", svar) fmt.Println(\"tail:\", flag.Args()) } ","date":"2021-03-23","objectID":"/go-instance-22/:2:0","tags":["golang"],"title":"Go Instance 22","uri":"/go-instance-22/"},{"categories":["实例"],"content":"Go Instance 21-读文件、写文件","date":"2021-03-23","objectID":"/go-instance-21/","tags":["golang"],"title":"Go Instance 21","uri":"/go-instance-21/"},{"categories":["实例"],"content":"读文件 package main import ( \"bufio\" \"fmt\" \"io\" \"io/ioutil\" \"os\" ) func check(e error) { if e != nil { panic(e) } } func main() { //大部分文件读取都是将内容读取到内存中 dat, err := ioutil.ReadFile(\"f:/test/test.txt\") check(err) fmt.Println(string(dat)) //读取文件可以从os.Open打开文件获取一个os.File开始 f, e := os.Open(\"f:/test/test1.txt\") defer f.Close() check(e) //从文件开始位置读取字节。这里最多读取5个字节。 b1 := make([]byte, 5) n1, err1 := f.Read(b1) check(err1) fmt.Println(n1, string(b1)) fmt.Printf(\"%d bytes: %s\\n\", n1, string(b1)) //也可以Seek到一个文件已知的位置并从这个位置开始读取 o2, err := f.Seek(6, 0) check(err) b2 := make([]byte, 2) n2, err := f.Read(b2) check(err) fmt.Printf(\"%d bytes @ %d: %s\\n\", n2, o2, string(b2)) //io包提供了可以帮助文件读取的函数 //可以使用ReadAtLeast得到一个更健壮的实现 o3, err := f.Seek(6, 0) check(err) b3 := make([]byte, 2) n3, err := io.ReadAtLeast(f, b3, 2) check(err) fmt.Printf(\"%d bytes @ %d: %s\\n\", n3, o3, string(b3)) //没有内置的回转支持，但是可以使用Seek(0,0)实现 _, err = f.Seek(0, 0) check(err) //bufio包实现了带缓冲的读取 //这不仅对有很多的小读取操作的性能有所提升，还提供了很多附加的读取函数 r4 := bufio.NewReader(f) b4, err := r4.Peek(5) check(err) fmt.Printf(\"5 bytes: %s\\n\", string(b4)) } ","date":"2021-03-23","objectID":"/go-instance-21/:1:0","tags":["golang"],"title":"Go Instance 21","uri":"/go-instance-21/"},{"categories":["实例"],"content":"写文件 package main import ( \"bufio\" \"fmt\" \"io/ioutil\" \"os\" ) //和read处于同一个包，不能有相同的方法名 //func check(err error) { // if err != nil { // panic(err) // } //} func main() { //如何写入一个字符串到一个文件里 d1 := \"hello\\ngo\\n\" err := ioutil.WriteFile(\"f:/test/test2.txt\", []byte(d1), 0644) check(err) //更细粒度的写入，先打开一个文件 f1, err := os.Create(\"f:/test/test3.txt\") check(err) defer f1.Close() //写入要写的字节切片 d2 := []byte{115, 111, 109, 101, 10} n, err := f1.Write(d2) check(err) fmt.Println(n) //WriteString也是可用的 n3, err := f1.WriteString(\"writes\\n\") check(err) fmt.Println(n3) //调用sync将缓冲区的信息写入磁盘 f1.Sync() //bufio提供带缓冲的写入器 w := bufio.NewWriter(f1) n4, err := w.WriteString(\"buffered\\n\") check(err) fmt.Println(n4) //使用Flush确保所有缓存操作以写入磁盘 w.Flush() } ","date":"2021-03-23","objectID":"/go-instance-21/:2:0","tags":["golang"],"title":"Go Instance 21","uri":"/go-instance-21/"},{"categories":["实例"],"content":"Go Instance 20-SHA1散列、Base64编码","date":"2021-03-23","objectID":"/go-instance-20/","tags":["golang"],"title":"Go Instance 20","uri":"/go-instance-20/"},{"categories":["实例"],"content":"SHA1散列 SHA1散列经常用生成二进制文件或者文本块的短标识。例如：Git版本控制系统大量使用SHA1来标识受版本控制的文件和目录。 package main import ( \"crypto/sha1\" \"fmt\" ) func main() { s := \"sha1 this string\" //产生一个散列值的方式是sha1.New(),sha1.Write(bytes),sha1.sum(bytes) h := sha1.New() //写入要处理的字节。如果是字符串，需使用[]byte()强制转换成字节数组 h.Write([]byte(s)) //这个用来得到最终的散列值的字符切片 //Sum的参数为现有的字符切片追加额外的字节切片：一般不需要 sum := h.Sum(nil) //sha1值经常以16进制输出 fmt.Println(h) fmt.Println(sum) fmt.Printf(\"%x\\n\", sum) } ","date":"2021-03-23","objectID":"/go-instance-20/:1:0","tags":["golang"],"title":"Go Instance 20","uri":"/go-instance-20/"},{"categories":["实例"],"content":"Base64编码 Go提供内建的base64编码 package main import ( \"encoding/base64\" \"fmt\" ) func main() { //将要编解码的字符串 data := \"abc123!?$*\u0026()'-=@~\" //Go同时支持标准的和URL兼容的base64格式 //编码需要使用[]byte类型参数，故要将字符串转成字节型 s := base64.StdEncoding.EncodeToString([]byte(data)) fmt.Println(s) //解码可能会发生错误，如果不确定，需要进行错误检查 bys, _ := base64.StdEncoding.DecodeString(s) fmt.Println(string(bys)) fmt.Println() //使用URL兼容的base64格式进行编码解码 s1 := base64.URLEncoding.EncodeToString([]byte(data)) fmt.Println(s1) bys2, _ := base64.URLEncoding.DecodeString(s1) fmt.Println(string(bys2)) } ","date":"2021-03-23","objectID":"/go-instance-20/:2:0","tags":["golang"],"title":"Go Instance 20","uri":"/go-instance-20/"},{"categories":["实例"],"content":"Go Instance 19-数字解析，URL解析","date":"2021-03-23","objectID":"/go-instance-19/","tags":["golang"],"title":"Go Instance 19","uri":"/go-instance-19/"},{"categories":["实例"],"content":"数字解析 从字符串中解析数字 package main import ( \"fmt\" \"strconv\" ) func main() { //使用Parse.Float解析浮点数，64表示解析的数的位数 f, _ := strconv.ParseFloat(\"1.234\", 64) fmt.Println(f) //在使用ParseInt解析整数时，base参数0表示自动推断字符串所表示的数字进制 //64表示返回的整型数是以64存储的 i, _ := strconv.ParseInt(\"123\", 0, 64) fmt.Println(i) //ParseInt会自动识别出十六进制数 d, _ := strconv.ParseInt(\"0x1c8\", 0, 64) fmt.Println(d) //ParseUint也是可用的 u, _ := strconv.ParseUint(\"789\", 0, 64) fmt.Println(u) //Atoi是一个基础的十进制整型数转换函数 a, _ := strconv.Atoi(\"135\") fmt.Println(a) //在输入错误时，会报错 _, e := strconv.Atoi(\"wat\") fmt.Println(e) } ","date":"2021-03-23","objectID":"/go-instance-19/:1:0","tags":["golang"],"title":"Go Instance 19","uri":"/go-instance-19/"},{"categories":["实例"],"content":"URL解析 URL提供了一个同一资源定位方式 package main import ( \"fmt\" \"net/url\" \"strings\" ) func main() { //这个URL实例，包含一个Scheme，认证信息，主机名，端口，路径，查询参数和片段 s := \"postgres://user:pass@host.com:5432/path?k=v#f\" //解析URL，确保解析没错 u, e := url.Parse(s) if e != nil { panic(e) } //直接访问Scheme fmt.Println(u.Scheme) //User包含了所有的认证信息，调用Username和Password来获取独立值 fmt.Println(u.User) fmt.Println(u.User.Username()) p, _ := u.User.Password() fmt.Println(p) //Host同时包含主机名和端口信息，如果端口号存在的话，使用strings.Split从Host中手动提取 fmt.Println(u.Host) h := strings.Split(u.Host, \":\") fmt.Println(h[0]) fmt.Println(h[1]) //提取路径和查询片段信息 fmt.Println(u.Path) fmt.Println(u.Fragment) //要得到字符串中的k=v这种格式的查询参数，可以使用RawQuery //也可以将查询参数解析为一个map。已解析的查询参数 map 以查询字符串为键， //对应值字符串切片为值，所以如何只想得到一个键对应的第一个值，将索引位置设置为 [0] 就行了。 fmt.Println(u.RawQuery) m, _ := url.ParseQuery(u.RawQuery) fmt.Println(m) fmt.Println(m[\"k\"][0]) } ","date":"2021-03-23","objectID":"/go-instance-19/:2:0","tags":["golang"],"title":"Go Instance 19","uri":"/go-instance-19/"},{"categories":["实例"],"content":"Go Instance 18-随机数","date":"2021-03-23","objectID":"/go-instance-18/","tags":["golang"],"title":"Go Instance 18","uri":"/go-instance-18/"},{"categories":["实例"],"content":"随机数 Go的math/rand包提供了伪随机数生成器 package main import ( \"fmt\" \"math/rand\" \"time\" ) func main() { //rand.Intn返回一个随机整数n，0\u003c=n\u003c=100 fmt.Print(rand.Intn(100),\",\") fmt.Print(rand.Intn(100)) fmt.Println() //rand.Float64返回一个64位浮点数f，0.0\u003c=f\u003c=1.0 fmt.Println(rand.Float64()) //这个技巧可以用来生成其他范围的随机浮点数f，5.0\u003c=f\u003c=10 fmt.Print((rand.Float64()*5)+5, \",\") fmt.Print((rand.Float64()*5)+5) fmt.Println() //默认情况下，给定的种子是确定的，每次都会产生相同的随机数数字序列 //要产生变化的序列，需要给定一个变化的种子，需要注意的是 //如果是出于加密目的，需要使用随机数的话，请使用crypto/rand包，此方法不够安全 s1 := rand.NewSource(time.Now().UnixNano()) r1 := rand.New(s1) fmt.Println(r1) //调用上面rand.Source的函数和调用rand包中的函数是相同的 fmt.Print(r1.Intn(100), \",\") fmt.Print(r1.Intn(100)) fmt.Println() //如果使用相同种子生成的随机数生成器，将会产生相同的随机数列 s2 := rand.NewSource(42) r2 := rand.New(s2) fmt.Print(r2.Intn(100), \",\") fmt.Print(r2.Intn(100)) fmt.Println() s3 := rand.NewSource(42) r3 := rand.New(s3) fmt.Print(r3.Intn(100), \",\") fmt.Print(r3.Intn(100)) fmt.Println() } ","date":"2021-03-23","objectID":"/go-instance-18/:1:0","tags":["golang"],"title":"Go Instance 18","uri":"/go-instance-18/"},{"categories":["实例"],"content":"Go Instance 17-时间","date":"2021-03-23","objectID":"/go-instance-17/","tags":["golang"],"title":"Go Instance 17","uri":"/go-instance-17/"},{"categories":["实例"],"content":"时间 Go对时间和时间段提供了大量的支持 package main import ( \"fmt\" \"time\" ) func main() { p := fmt.Println //获得当前时间 now := time.Now() p(now) //提供年月日等信息，可以构建一个time。时间总是关联位置信息，例如时区 then := time.Date(2009, 11, 17, 20, 34, 58, 651387237, time.UTC) p(then) //提取出时间的各个组成部分 p(then.Year()) p(then.Month()) p(then.Day()) p(then.Hour()) p(then.Minute()) p(then.Second()) p(then.Nanosecond()) p(then.Location()) //输出时间的星期 p(then.Weekday()) //使用方法比较时间，精确到秒 p(then.Before(now)) p(then.After(now)) p(then.Equal(now)) //Sub返回一个duration来表示两个时间点的间隔时间 diff := now.Sub(then) p(diff) //计算不同单位下的时间长度值 p(diff.Hours()) p(diff.Minutes()) p(diff.Seconds()) p(diff.Nanoseconds()) //可以使用Add将时间后移一个时间间隔，或在时间间隔前加-，将时间前移一个时间间隔 p(then.Add(diff)) p(then.Add(-diff)) } ","date":"2021-03-23","objectID":"/go-instance-17/:1:0","tags":["golang"],"title":"Go Instance 17","uri":"/go-instance-17/"},{"categories":["实例"],"content":"时间戳 一般程序都有获取Unix时间的秒数，毫秒数或微秒数的需要 package main import ( \"fmt\" \"time\" ) func main() { //分别使用带Unix或者UnixNano的time.Now来获取从自协调世界时起到现在的秒数或纳秒数 now := time.Now() secs := now.Unix() nanos := now.UnixNano() fmt.Println(now) //UnixMillis是不存在的，所以要得到毫秒数，得自己转化 millis := nanos/1000000 fmt.Println(secs) fmt.Println(millis) fmt.Println(nanos) //也可以将秒数或毫秒数转化为时间 fmt.Println(time.Unix(secs, 0)) fmt.Println(time.Unix(0, nanos)) } ","date":"2021-03-23","objectID":"/go-instance-17/:2:0","tags":["golang"],"title":"Go Instance 17","uri":"/go-instance-17/"},{"categories":["实例"],"content":"时间格式化和解析 Go支持通过基于描述模板的时间格式化和解析 package main import ( \"fmt\" \"time\" ) func main() { p := fmt.Println now := time.Now() //按照RFC3339格式化 p(now.Format(time.RFC3339)) //时间解析使用Format相同的形式值 t1, _ := time.Parse(time.RFC3339, \"2021-03-23T11:01:37+08:00\") p(t1) //Format和Parse使用基于例子的形式来决定日期格式 //一般只需要使用time包内的格式，但是可以实现自定义模式 // 模式必须使用时间 Mon Jan 2 15:04:05 MST 2006来指定给定时间/字符串的格式化/解析方式。 // 时间一定要按照如下所示：2006为年，15 为小时，Monday 代表星期几，等等。 p(now.Format(\"03:04pm\")) p(now.Format(\"Mon Jan _2 15:04:05 2006\")) p(now.Format(\"2006-01-02T15:04:05.999999-07:00\")) format := \"3 04pm\" t2, _ := time.Parse(format, \"8 41pm\") p(t2) //对于纯数字表示的时间，可以使用标准的格式化字符串来提取时间值的组成 fmt.Printf(\"%d-%02d-%02dT%02d:%02d:%02d-00:00\\n\", now.Year(), now.Month(), now.Day(), now.Hour(), now.Minute(), now.Second()) //Parse函数在输入时间格式不正确会返回错误 ansic := \"Mon Jan _2 15:04:05 2006\" _, e := time.Parse(ansic, \"8:41PM\") fmt.Println(e) } ","date":"2021-03-23","objectID":"/go-instance-17/:3:0","tags":["golang"],"title":"Go Instance 17","uri":"/go-instance-17/"},{"categories":["实例"],"content":"Go Instance 16-Json","date":"2021-03-22","objectID":"/go-instance-16/","tags":["golang"],"title":"Go Instance 16","uri":"/go-instance-16/"},{"categories":["实例"],"content":"JSON Go提供内置的JSON编解码支持，包括内置或自定义类型与JSON数据之间的转化 package main import ( \"encoding/json\" \"fmt\" \"os\" ) type Response1 struct { Page int Fruits []string } type Response2 struct { Page int `json:\"page\"` Fruits []string `json:\"fruits\"` } func main() { //基本数据类型到JSON字符串的编码过程 bolB, _ := json.Marshal(true) fmt.Println(string(bolB)) intB, _ := json.Marshal(1) fmt.Println(string(intB)) fltB, _ := json.Marshal(3.14) fmt.Println(string(fltB)) strB, _ := json.Marshal(\"gopher\") fmt.Println(string(strB)) //切片和map编码成JSON数组和对象 slcD := []string{\"apple\", \"peach\", \"pear\"} slcB, _ := json.Marshal(slcD) fmt.Println(string(slcB)) mapD := map[string]int{\"apple\": 5, \"lettuce\": 7} mapB, _ := json.Marshal(mapD) fmt.Println(string(mapB)) //JSON包可以自动编码自定义类型 //编码仅输出可导出的字段，并且默认使用他们的名字作为JSON数据的键 res1D := \u0026Response1{ Page:1, Fruits:[]string{\"apple\", \"peach\", \"pear\"}, } res1B, _ := json.Marshal(res1D) fmt.Println(string(res1B)) //可以在结构体字段声明标签来自定义编码的JSON数据键名称 res2D := \u0026Response2{ Page:1, Fruits:[]string{\"apple\", \"peach\", \"pear\"}, } res2B, _ := json.Marshal(res2D) fmt.Println(string(res2B)) //JSON数据解码 byt := []byte(`{\"num\":6.13, \"strs\":[\"a\", \"b\"]}`) //提供一个JSON包可以存放解码数据的变量 var dat map[string]interface{} //实际的解码与错误检查 if err := json.Unmarshal(byt, \u0026dat); err != nil { panic(err) } fmt.Println(dat) //为了使用解码map中的值，可以将他们进行适当的类型转化 //将num的值转化为float64 num := dat[\"num\"].(float64) fmt.Println(num) //访问嵌套的值需要一系列的转化 strs := dat[\"strs\"].([]interface{}) str := strs[0].(string) fmt.Println(str) //解码JSON值到自定义类型 //这个功能的好处：可以为程序带来额外的类型安全加强，并且消除访问数据时的类型断言 str1 := `{\"page\": 1, \"fruits\": [\"apple\", \"pear\"]}` res := Response2{} json.Unmarshal([]byte(str1), \u0026res) fmt.Println(res) fmt.Println(res.Fruits[0]) //可以和os.Stdout一样，直接将JSON编码输出至os.Writer流中，或者作为HTTP响应体 enc := json.NewEncoder(os.Stdout) d := map[string]int{\"apple\": 5, \"lettuce\": 7} enc.Encode(d) } ","date":"2021-03-22","objectID":"/go-instance-16/:1:0","tags":["golang"],"title":"Go Instance 16","uri":"/go-instance-16/"},{"categories":["实例"],"content":"Go Instance 15-字符串格式化、正则表达式","date":"2021-03-22","objectID":"/go-instance-15/","tags":["golang"],"title":"Go Instance 15","uri":"/go-instance-15/"},{"categories":["实例"],"content":"字符串格式化 Go在传统的printf中对字符串格式化提供了优异的支持。 package main import ( \"fmt\" \"os\" ) type point struct { x, y int } func main() { //Go为常规Go值的格式设计了许多种打印方式。 p := point{1, 2} fmt.Printf(\"%v\\n\", p) //如果值是一个结构体，%+v的格式化输出内容包括结构体的字段名 fmt.Printf(\"%+v\\n\", p) //%#v形式则输出这个值的Go语法表示。例如值的运行源代码片段 fmt.Printf(\"%#v\\n\", p) //需要打印值的类型，使用%T fmt.Printf(\"%T\\n\", p) //格式化布尔值，%t fmt.Printf(\"%t\\n\", true) //格式化整型的多种方式 //使用%d进行标准的十进制格式化 fmt.Printf(\"%d\\n\", 123) //使用%b进行二进制格式化 fmt.Printf(\"%b\\n\", 14) //这个整数对应的字符 fmt.Printf(\"%c\\n\", 33) //%x提供十六进制编码 fmt.Printf(\"%x\\n\", 456) //对于浮点数同样有很多格式化选项 //使用%f进行最基本的十进制格式化 fmt.Printf(\"%f\\n\", 78.9) //%e和%E将浮点型格式化为科学计数法表示形式 fmt.Printf(\"%e\\n\", 123400000.0) fmt.Printf(\"%E\\n\", 123400000.0) //使用%s进行基本的字符串输出 fmt.Printf(\"%s\\n\", \"\\\"string\\\"\") //带有双引号的输出，使用%q fmt.Printf(\"%q\\n\", \"\\\"string\\\"\") //%x输出使用base-16编码的字符串，每个字节用两个字符表示 fmt.Printf(\"%x\\n\", \"hey this\") //输出一个指针的值%p fmt.Printf(\"%p\\n\", \u0026p) //当输出数字时，想要控制输出结果的宽度和精度 //可以在%后面使用数字来控制输出宽度 //默认结果使用右对齐并且通过空格来填充空白部分 fmt.Printf(\"|%6d|%6d|\\n\", 12, 345) //也可以指定浮点数的输出宽度，同时也可以通过宽度，精度的语法来指定输出的精度 fmt.Printf(\"|%6.2f|%6.2f|\\n\", 1.2, 3.45) //要左对齐%后面使用- fmt.Printf(\"|%-6.2f|%-6.2f|\\n\", 1.2, 3.45) //字符串输出时的宽度 fmt.Printf(\"|%6s|%6s|\\n\", \"foo\", \"b\") //要左对齐%后面使用- fmt.Printf(\"|%-6s|%-6s|\\n\", \"foo\", \"b\") //Printf通过os.Stdout输出格式化的字符串 //Sprintf格式化并返回一个字符串并不带任何输出 s := fmt.Sprintf(\"a %s\", \"string\") fmt.Println(s) //使用Fprint格式化并输出到io.Writers而不是os.Stdout fmt.Fprint(os.Stderr, \"an %s\\n\", \"error\") } ","date":"2021-03-22","objectID":"/go-instance-15/:1:0","tags":["golang"],"title":"Go Instance 15","uri":"/go-instance-15/"},{"categories":["实例"],"content":"正则表达式 Go提供内置的正则表达式。 package main import ( \"bytes\" \"fmt\" \"regexp\" ) func main() { //测试一个字段是否符合一个表达式 matched, _ := regexp.MatchString(\"p([a-z]+)ch\", \"peach\") fmt.Println(matched) //上面直接使用字符串，但是对于一些其他正则任务 //需要Compile一个优化的Regexp结构体 r, _ := regexp.Compile(\"p([a-z]+)ch\") //这个结构体有很多方法，这是类似前面的匹配测试 fmt.Println(r.MatchString(\"peach\")) //这是查找匹配字符串 fmt.Println(r.FindString(\"peach punch\")) //查找第一次匹配的字符串，返回的是匹配开始和结束的索引，而不是内容 fmt.Println(r.FindStringIndex(\"peach punch\")) //submatch返回完全匹配和局部匹配的字符串。例如这里会返回p([a-z]+)ch和([a-z]+)的信息 fmt.Println(r.FindStringSubmatch(\"peach punch\")) //返回完全匹配和局部匹配的索引位置 fmt.Println(r.FindStringSubmatchIndex(\"peach punch\")) //带All的这个函数返回所有的匹配项，而不仅仅是首次匹配项 fmt.Println(r.FindAllString(\"peach punch pinch\", -1)) //返回所有的完全匹配和局部匹配的索引位置 fmt.Println(r.FindAllStringSubmatchIndex(\"peach punch pinch\", -1)) //使用提供的正整数限制匹配个数 fmt.Println(r.FindAllString(\"peach punch pinch\", 2)) //也可以提供[]byte参数并将String从函数名中去掉 fmt.Println(r.Match([]byte(\"peach\"))) //创建正则表达式常量时，可以使用Compile的变体MustCompile //因为Compile返回两个值，不能用于常量 r = regexp.MustCompile(\"p([a-z]+)ch\") fmt.Println(r) //regexp包也可以用来替换部分字符串的其他值 fmt.Println(r.ReplaceAllString(\"a peach\", \"\u003cfruits\u003e\")) //Func变量允许传递匹配内容到一个给定的函数中 in := []byte(\"a peach\") out := r.ReplaceAllFunc(in, bytes.ToUpper) fmt.Println(string(out)) } ","date":"2021-03-22","objectID":"/go-instance-15/:2:0","tags":["golang"],"title":"Go Instance 15","uri":"/go-instance-15/"},{"categories":["实例"],"content":"Go Instance 14-组合函数、字符串函数","date":"2021-03-22","objectID":"/go-instance-14/","tags":["golang"],"title":"Go Instance 14","uri":"/go-instance-14/"},{"categories":["实例"],"content":"组合函数 我们经常需要程序在数据集上执行操作，比如选择满足条件的所有想，或者将所有项通过一个自定义函数映射到一个新的集合上 在某些语言中，会习惯使用泛型。Go不支持泛型，在Go中当你的程序或数据类型有需要时，通常是以组合的方式来提供操作函数 这是一些strings切片的组合函数实例。可以使用这些例子来构建自己的函数。注意有些时候直接使用内联组合操作代码会更加清晰，而不是创建并调用一个函数 package main import ( \"fmt\" \"strings\" ) //返回目标字段s出现的第一个位置，没有返回-1 func Index(s string, arr []string) int { for i, v := range arr { if s == v { return i } } return -1 } //如果目标s在切片中存在返回true func Include(s string, arr []string) bool { return Index(s, arr) \u003e= 0 } //如果切片中的字符串有一个满足条件f返回true func Any(arr []string, f func(string) bool) bool { for _, v := range arr { if f(v) { return true } } return false } //如果切片中的字符串所有都满足条件f返回true func All(arr []string, f func(string) bool) bool { for _, v := range arr { if !f(v) { return false } } return true } //返回一个包含所有切面中满足条件f的新切片 func Filer(arr []string, f func(string) bool) []string { result := make([]string, 0) for _, v := range arr{ if f(v) { result = append(result, v) } } return result } //返回一个对原始切片中所有字符串执行函数f的切片 func Map(arr []string, f func(string) string) []string { result := make([]string, 0) for _, v := range arr { result = append(result, f(v)) } return result } func main() { fruits := []string{\"peach\", \"apple\", \"pear\", \"plum\"} fmt.Println(Index(\"pear\", fruits)) fmt.Println(Include(\"grape\", fruits)) fmt.Println(Any(fruits, func(v string) bool { return strings.HasPrefix(v, \"p\") })) fmt.Println(All(fruits, func(v string) bool { return strings.HasPrefix(v, \"p\") })) fmt.Println(Filer(fruits, func(v string) bool { return strings.Contains(v, \"e\") })) //上面都是使用匿名函数，也可以使用类型正确的命名函数 fmt.Println(Map(fruits, strings.ToUpper)) } ","date":"2021-03-22","objectID":"/go-instance-14/:1:0","tags":["golang"],"title":"Go Instance 14","uri":"/go-instance-14/"},{"categories":["实例"],"content":"字符串函数 标准库的strings包提供了很多有用的字符相关的函数。这里是一些用来让你对这个包有个初步理解的例子 package main import ( \"fmt\" s \"strings\" ) //给fmt.Println起别名，之后会经常用到 var p = fmt.Println func main() { //这是一些strings中的函数例子。注意他们都是函数中的例子，不是字符串对自身的方法 //这意味着我们需要考虑在调用时传递字符作为第一个参数进行传递 p(\"Contains: \", s.Contains(\"test\", \"es\")) p(\"Count: \", s.Count(\"test\", \"t\")) p(\"HasPrefix: \", s.HasPrefix(\"test\", \"te\")) p(\"HasSuffix: \", s.HasSuffix(\"test\", \"st\")) p(\"Index: \", s.Index(\"test\", \"e\")) p(\"Join: \", s.Join([]string{\"a\", \"b\"}, \"-\")) p(\"Repeat: \", s.Repeat(\"a\", 5)) p(\"Replace: \", s.Replace(\"foo\", \"o\", \"O\", -1)) p(\"Replace: \", s.Replace(\"foo\", \"o\", \"O\", 1)) p(\"Split: \", s.Split(\"a-b-c-d-e\", \"-\")) p(\"ToLower: \", s.ToLower(\"TEST\")) p(\"ToUpper: \", s.ToUpper(\"test\")) } ","date":"2021-03-22","objectID":"/go-instance-14/:2:0","tags":["golang"],"title":"Go Instance 14","uri":"/go-instance-14/"},{"categories":["实例"],"content":"Go Instance 13-panic、defer","date":"2021-03-22","objectID":"/go-instance-13/","tags":["golang"],"title":"Go Instance 13","uri":"/go-instance-13/"},{"categories":["实例"],"content":"Panic panic意味着有些出乎意料的错误发生。通常用它表示程序正常运行中不该出现的，或者没有处理好的事务 package main import \"os\" func main() { //这里直接panic出一个错误 panic(\"a problem\") //panic的一个基本用法就是在一个函数返回了错误值但是并不知道（或不想）处理时停止运行 //这里是创建一个新文件时返回异常错误的panic用法 _, e := os.Create(\"F://test.txt\") if e != nil { panic(e) } } ","date":"2021-03-22","objectID":"/go-instance-13/:1:0","tags":["golang"],"title":"Go Instance 13","uri":"/go-instance-13/"},{"categories":["实例"],"content":"Defer defer用来确保一个函数调用在程序执行结束前执行。通常用来执行一些清理工作 package main import ( \"fmt\" \"os\" ) //本例为创建一个文件，对其进行写操作，结束后关闭 func main() { //创建文件，进行写操作，结束时关闭文件 f := createFile(\"F:/test/test.txt\") defer closeFile(f) writeFile(f) } func createFile(s string) *os.File { fmt.Println(\"creating\") file, err := os.Create(s) if err != nil { panic(err) } return file } func closeFile(f *os.File) { fmt.Println(\"closing\") f.Close() } func writeFile(f *os.File) { fmt.Println(\"writing\") fmt.Fprintln(f, \"data ok\") } ","date":"2021-03-22","objectID":"/go-instance-13/:2:0","tags":["golang"],"title":"Go Instance 13","uri":"/go-instance-13/"},{"categories":["学习"],"content":"redis面试02","date":"2021-03-18","objectID":"/redis-interview-02/","tags":["redis"],"title":"Redis Interview 02","uri":"/redis-interview-02/"},{"categories":["学习"],"content":"过期键的删除策略 ","date":"2021-03-18","objectID":"/redis-interview-02/:1:0","tags":["redis"],"title":"Redis Interview 02","uri":"/redis-interview-02/"},{"categories":["学习"],"content":"Redis的过期键的删除策略 Redis是一个key-value数据库，我们可以在Redis中设置键的过期时间。Redis的过期策略就是指当前Redis中的缓存key过期了，Redis如何处理。 通常过期策略有以下三种： 定时过期：每个设置了过期时间的key都需要创建一个定时器，过到期时间就会立即清除。该策略可以立即清除过期的数据，对内存很友好；但是会占用大量的CPU资源去处理过期的数据，从而影响缓存的相应时间和吞吐量。 惰性过期：只有当访问一个key时，才会判断这个key是否过期，过期则立即清除。该策略可以最大化的节省CPU资源，却对内存非常不友好。极端情况下可能出现大量过期的key没有再次被访问，从而不会被删除，占用大量内存。 定期过期：每隔一定时间，会扫描一定数量数据库的expires字典中一定数量的key，并清除其中已经过期的key。该策略是前两种的折中策略。通过调整定时扫描的时间间隔和每次扫描的限定耗时，可以在不同情况下使得CPU和内存资源达到最优的平衡效果。 （expires字典会保存所有设置了过期时间的key的过期时间和数据，其中，key是指向键空间中的某个键的指针，value是该键的毫秒精度Unix时间戳表示的过期时间，键空间是指该Redis集群中保存的所有键） Redis中同时使用了惰性过期和定期过期两种过期方式。 ","date":"2021-03-18","objectID":"/redis-interview-02/:1:1","tags":["redis"],"title":"Redis Interview 02","uri":"/redis-interview-02/"},{"categories":["学习"],"content":"Redis key的过期时间和永久有效分别怎么设置 EXPIRE和PERSIST命令 ","date":"2021-03-18","objectID":"/redis-interview-02/:1:2","tags":["redis"],"title":"Redis Interview 02","uri":"/redis-interview-02/"},{"categories":["学习"],"content":"通过EXPIRE来设置key的过期时间，那么对过期的数据怎么处理 除了缓存服务器自带的缓存失效策略之外（Redis中有6中策略可以选择），还可以根据具体业务自定义的缓存淘汰，常见的策略有两种： 定时去清理过期缓存 当有用户请求时，再判断这个所用到的缓存是否过期，过期的话就去底层系统得到新数据并更新缓存。 ","date":"2021-03-18","objectID":"/redis-interview-02/:1:3","tags":["redis"],"title":"Redis Interview 02","uri":"/redis-interview-02/"},{"categories":["学习"],"content":"内存相关 ","date":"2021-03-18","objectID":"/redis-interview-02/:2:0","tags":["redis"],"title":"Redis Interview 02","uri":"/redis-interview-02/"},{"categories":["学习"],"content":"MySQL里有2000w数据，redis中只存20w的数据，如何保证redis中的数据都是热点数据 redis内存数据集大小上升到一定大小的时候，就会施行数据淘汰策略 ","date":"2021-03-18","objectID":"/redis-interview-02/:2:1","tags":["redis"],"title":"Redis Interview 02","uri":"/redis-interview-02/"},{"categories":["学习"],"content":"Redis的内存淘汰策略有哪些 Redis的内存淘汰策略是指在Redis的用于缓存的内存不足，怎么处理需要新写入且需要申请额外空间的数据 全局的键空间选择性移除： noeviction：当内存不足容纳写入新数据时，新写入操作会报错 allkeys-lru：当内存不足容纳写入新数据时，在键空间中，移除最近最少使用的key（这个是最常用的） allkeys-random：当内存不足容纳写入新数据时，在键空间随机移除某个key 设置过期时间的键空间选择性移除 volatile-lru：当内存不足容纳写入新数据时，在设置了过期时间的键空间中，移除最近最少使用的key volatile-random：当内存不足容纳写入新数据时，在设置了过期时间的键空间中，随机移除某个key volatile-ttl：当内存不足容纳写入新数据时，在设置了过期时间的键空间中，有更早过期的key优先移除 ","date":"2021-03-18","objectID":"/redis-interview-02/:2:2","tags":["redis"],"title":"Redis Interview 02","uri":"/redis-interview-02/"},{"categories":["学习"],"content":"Redis如何做内存优化 可以利用Hash，Set，Zset，List等集合类型数据。因为通常情况下很多小的key-value可以用更紧凑的方式放在一起。尽量使用散列表（hash），散列表使用的内存非常小。 ","date":"2021-03-18","objectID":"/redis-interview-02/:2:3","tags":["redis"],"title":"Redis Interview 02","uri":"/redis-interview-02/"},{"categories":["学习"],"content":"线程模型 ","date":"2021-03-18","objectID":"/redis-interview-02/:3:0","tags":["redis"],"title":"Redis Interview 02","uri":"/redis-interview-02/"},{"categories":["学习"],"content":"Redis线程模型 Redis基于Reactor模式开发了网络时间处理器，这个处理器被称为文件时间处理器。它的组成结构为4部分多个套接字，IO多路复用程序，文件事件分派器，事件处理器。因为文件事件分配器队列的消费是单线程的，所以Redis才叫单线程模型。 ","date":"2021-03-18","objectID":"/redis-interview-02/:3:1","tags":["redis"],"title":"Redis Interview 02","uri":"/redis-interview-02/"},{"categories":["学习"],"content":"事务 ","date":"2021-03-18","objectID":"/redis-interview-02/:4:0","tags":["redis"],"title":"Redis Interview 02","uri":"/redis-interview-02/"},{"categories":["学习"],"content":"什么是事务 事务是一个单独的隔离操作，事务中的所有命令都会序列化，按一定顺序执行。事务在执行的过程中，不会被其他客户端发来的命令请求打断。 事务是一个原子操作。事务中的命令要么全部执行要么都不执行。 ","date":"2021-03-18","objectID":"/redis-interview-02/:4:1","tags":["redis"],"title":"Redis Interview 02","uri":"/redis-interview-02/"},{"categories":["学习"],"content":"Redis事务概念 Redis事务的本质是通过MULTI，EXEC，WATCH等一组命令的集合。事务支持一次执行多条指令，一个事务中的所有命令都会被序列化。在事务执行过程中，会按照序列串行化执行队列中的命令，其他客户端的请求不会插入到事务执行命令序列中。 总结：Redis事务就是一次性、顺序性、排他性的执行一个队列里的一系列命令。 ","date":"2021-03-18","objectID":"/redis-interview-02/:4:2","tags":["redis"],"title":"Redis Interview 02","uri":"/redis-interview-02/"},{"categories":["学习"],"content":"Redis事务的三个命令 事务开始 MULTI 命令入队 事务结束 EXEC ","date":"2021-03-18","objectID":"/redis-interview-02/:4:3","tags":["redis"],"title":"Redis Interview 02","uri":"/redis-interview-02/"},{"categories":["学习"],"content":"Redis保证原子性吗？支持回滚吗？ Redis中单条命令是原子性的，但是事务不保证原子性不支持回滚。事务中的命令只要没有语法错误，事务中的命令都会依次执行。 ","date":"2021-03-18","objectID":"/redis-interview-02/:4:4","tags":["redis"],"title":"Redis Interview 02","uri":"/redis-interview-02/"},{"categories":["学习"],"content":"集群方案 ","date":"2021-03-18","objectID":"/redis-interview-02/:5:0","tags":["redis"],"title":"Redis Interview 02","uri":"/redis-interview-02/"},{"categories":["学习"],"content":"哨兵模式 哨兵主要功能： 集群监控：负责监控master和slave是否正常工作。 消息通知：如果某个实例有故障，哨兵负责发送消息作为报警通知给管理员 故障转移：如果master挂了，会投票选一个slave作为master 配置中心：如果故障转移了，通知client客户端新的master地址 哨兵模式用于实现Redis集群的高可用，本身也是分布式的，是以集群运行工作的。 故障转移时，判断一个主机是否宕机，需要大部分哨兵同意，这涉及分布式选举。 即使部分哨兵失效了，哨兵集群还是能正常工作的。 哨兵的核心知识： 哨兵至少要有三个实例来保证健壮性 哨兵+redis主从的部署结构，不会保证数据零丢失，只能保证Redis集群的高可用性 ","date":"2021-03-18","objectID":"/redis-interview-02/:5:1","tags":["redis"],"title":"Redis Interview 02","uri":"/redis-interview-02/"},{"categories":["学习"],"content":"缓存异常 ","date":"2021-03-18","objectID":"/redis-interview-02/:6:0","tags":["redis"],"title":"Redis Interview 02","uri":"/redis-interview-02/"},{"categories":["学习"],"content":"缓存雪崩 缓存雪崩是指缓存同一时间大面积失效，所以后面的请求都会落在数据库上，造成数据库短时间内承受大量请求而崩掉。 解决方案 缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。 一般并发量不是特别多的时候，使用最多的是加锁排队 给每个缓存数据添加缓存标记，记录缓存是否失效，如果标记失效，更新缓存。 ","date":"2021-03-18","objectID":"/redis-interview-02/:6:1","tags":["redis"],"title":"Redis Interview 02","uri":"/redis-interview-02/"},{"categories":["学习"],"content":"缓存穿透 缓存穿透是指缓存和数据库中都没有数据，导致所有的请求都落在数据库上，造成数据短时间承受大量请求而崩掉 解决方案： 接口层添加校验，如用户鉴权校验，id作为基础校验，id小于等于0直接拦截 从缓存中取不到数据，在数据库中也取不到数据，这时可以将key-value写成key-null，缓存有效时间可以写短一点，（设置太长可能导致正常情况也没法使用）。这样可以防止攻击用户反复使用一个id攻击。 采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被这个bitmap拦截掉，从而避免对底层存储系统的查询压力。 ","date":"2021-03-18","objectID":"/redis-interview-02/:6:2","tags":["redis"],"title":"Redis Interview 02","uri":"/redis-interview-02/"},{"categories":["学习"],"content":"缓存击穿 缓存击穿是指缓存中没有但数据库中有的数据（一般是缓存时间过期），这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库取数据，引起数据库压力瞬间增大，造成过大压力。 和雪崩不同的是：缓存击穿指并发差同一条数据，缓存雪崩是指不同的数据都过期了，很多数据查不到从而查数据库 解决方案： 设置热点数据永不过期 加互斥锁 ","date":"2021-03-18","objectID":"/redis-interview-02/:6:3","tags":["redis"],"title":"Redis Interview 02","uri":"/redis-interview-02/"},{"categories":["学习"],"content":"缓存预热 缓存预热就是指系统上线后，将相关的缓存数据直接加载到缓存系统。这样就可以避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题，用户直接查询事先被预热的缓存数据 解决方案： 直接写个缓存刷新页面，上线时手工操作一下 数据量不大，可以在项目启动的时候自动进行加载 自动刷新缓存 ","date":"2021-03-18","objectID":"/redis-interview-02/:6:4","tags":["redis"],"title":"Redis Interview 02","uri":"/redis-interview-02/"},{"categories":["学习"],"content":"缓存降级 当访问量剧增，服务出现问题（如响应时间慢或不响应）或非核心服务影响到核心流程的性能时，仍然要保证服务还是可用的，即使是有损服务，系统可以根据一些关键数据进行自动降级，也可以配置开关实现人工降级 缓存降级的最终目标是保证核心服务可用，即使是有损的，而且有些服务是无法降级的（如加入购物车，结算） 在进行降级之前要对系统进行梳理，看看系统是不是可以弃车保帅；从而梳理出哪些必须誓死保护，哪些可以降级，比如可以参考日志级别设置预案 一般：比如有些服务偶尔因为网络抖动或者服务正在上线而超时，可以自动降级 警告：有些服务在一段时间内成功率有波动（如在95%~100%之间），可以自动降级或人工降级，并发送警告 错误：比如可用率低于90%，或者数据库连接池被打爆了，或者访问量忽然间猛增到系统能承受的最大阈值，此时可以根据情况自动降级或人工降级 严重错误：比如因为特殊原因数据错误，此时需要紧急人工降级 服务降级的目的，是为了防止Redis服务故障，导致数据库跟着一起发生雪崩问题。因此对于不重要的缓存数据，可以采取服务降级策略，例如一个比较常见的做法就是，Redis出现问题，不去数据库查询，而是直接返回默认值给用户。 ","date":"2021-03-18","objectID":"/redis-interview-02/:6:5","tags":["redis"],"title":"Redis Interview 02","uri":"/redis-interview-02/"},{"categories":["学习"],"content":"热点数据和冷数据 热点数据，缓存才有价值 对于冷数据而言，大部分数据可能还没有再次访问就已经被挤出内存，不仅占用内存，而且价值不大。频繁修改的数据，看情况考虑使用缓存 对于热点数据，缓存以后可能读取数十万次或百万次 缓存数据更新前至少读取两次，缓存才有意义。这个是最基本的策略，如果缓存还没有其作用就失效了，那就太没有价值了。 那存不存在，修改频率很高，但是又不得不考虑缓存的场景？存在，如这个读取接口对数据库压力很大，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮 ","date":"2021-03-18","objectID":"/redis-interview-02/:6:6","tags":["redis"],"title":"Redis Interview 02","uri":"/redis-interview-02/"},{"categories":["学习"],"content":"缓存热点key 缓存中的一个Key（比如一个促销商品），在某个时间点过期的时候，恰好在这个时间点对这个Key有大量的并发请求发送过来，这些请求发现缓存过期，一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮 解决方案： 对缓存查询加锁，如果key不存在，就加锁，然后查DB入缓存，然后解锁。其他进程如果发现有锁就等待，然后等解锁后返回锁具或者进入DB查询 ","date":"2021-03-18","objectID":"/redis-interview-02/:6:7","tags":["redis"],"title":"Redis Interview 02","uri":"/redis-interview-02/"},{"categories":["学习"],"content":"redis学习04","date":"2021-03-15","objectID":"/redis-study-04/","tags":["redis"],"title":"Redis Study 04","uri":"/redis-study-04/"},{"categories":["学习"],"content":"Redis主从复制 ","date":"2021-03-15","objectID":"/redis-study-04/:1:0","tags":["redis"],"title":"Redis Study 04","uri":"/redis-study-04/"},{"categories":["学习"],"content":"概念 主从复制，是指将一台Redis服务器的数据，复制到其他的Redis服务器。前者称为主节点（master/leader），后者称为从节点（slave/follower）。数据的复制是单向的，只能从主节点到从节点。master以写为主，salve以读为主。 默认情况下，每台Redis服务器都是主节点。且每个主节点可以有多个从节点（或没有从节点），但是一个从节点只能有一个主节点 主从复制包括： 数据冗余：主从复制实现了数据的热备份，是持久化的一种数据冗余方式 故障修复：当主节点出现问题，可以由从节点提供服务，实现快速的故障修复，实际上是一种服务的冗余 负载均衡：在主从复制的基础上，配合读写分离，可以由主节点提供写服务，从节点提供读服务（即写Redis数据时应用连接主节点，读Redis数据是应用连接从节点），分担服务器负载；尤其在写少读多的情况下，通过多个节点分担读负载，可以大大提高Redis服务的并发量 高可用（集群）基石：除了上述作用以外，主从复制还是哨兵和集群能够实施的基础，因此说主从复制是Redis的高可用的基础。 一般来说，要将Redis运用于工程项目中，只使用一台Redis是万万不能的，原因如下： 从结构上，单个Redis服务器会发生单点故障，并且一台服务器要处理所有的请求负载，压力较大。 从容量上，单个Redis服务器内存容量有限，就算一台Redis服务器内存容量为256GB，也不能将所有内存作为Redis存储内存，一般来说，单台Redis最大使用内存不应该超过20GB 一般电商网站上的商品，一般都是一次上传，无数次浏览，说专业点就是多读少写 主从复制，读写分离！80%的情况下都是在进行读操作！减缓服务器压力！架构中经常使用一主二从！ ","date":"2021-03-15","objectID":"/redis-study-04/:1:1","tags":["redis"],"title":"Redis Study 04","uri":"/redis-study-04/"},{"categories":["学习"],"content":"环境配置 只配置从库，不用配置主库 127.0.0.1:6379\u003e info replication # 查看当前库的信息 # Replication role:master # 角色 connected_slaves:0 # 连接的从机个数 master_replid:c3d733dbffb09746cf8ef0b4b87ce62406dd0c83 master_replid2:0000000000000000000000000000000000000000 master_repl_offset:0 second_repl_offset:-1 repl_backlog_active:0 repl_backlog_size:1048576 repl_backlog_first_byte_offset:0 repl_backlog_histlen:0 复制3个配置文件，然后修改对应的配置信息 端口号 pid文件名 日志名 dump.rdb文件 修改完毕后启动，启动3个Redis集群 redis主从复制配置\u0026ldquo;redis主从复制配置\u0026rdquo; \"\rredis主从复制配置\r ","date":"2021-03-15","objectID":"/redis-study-04/:1:2","tags":["redis"],"title":"Redis Study 04","uri":"/redis-study-04/"},{"categories":["学习"],"content":"一主二从 默认情况下，每台Redis服务器都是主节点；我们一般情况下只要配置从机就可以了 127.0.0.1:6380\u003e SLAVEOF 127.0.0.1 6379 # 选择主机 OK 127.0.0.1:6380\u003e info replication # Replication role:slave # 当前角色是从机 master_host:127.0.0.1 # 主机ip master_port:6379 # 主机端口号 master_link_status:up master_last_io_seconds_ago:2 master_sync_in_progress:0 slave_repl_offset:14 slave_priority:100 slave_read_only:1 connected_slaves:0 master_replid:60116b0ccf67baa49701e78ea9cbb17c2673dded master_replid2:0000000000000000000000000000000000000000 master_repl_offset:14 second_repl_offset:-1 repl_backlog_active:1 repl_backlog_size:1048576 repl_backlog_first_byte_offset:1 repl_backlog_histlen:14 # 配置完两台从机 127.0.0.1:6379\u003e info replication # Replication role:master connected_slaves:2 slave0:ip=127.0.0.1,port=6380,state=online,offset=1148,lag=0 slave1:ip=127.0.0.1,port=6381,state=online,offset=1148,lag=0 master_replid:60116b0ccf67baa49701e78ea9cbb17c2673dded master_replid2:0000000000000000000000000000000000000000 master_repl_offset:1148 second_repl_offset:-1 repl_backlog_active:1 repl_backlog_size:1048576 repl_backlog_first_byte_offset:1 repl_backlog_histlen:1148 真实的从主配置应该在配置文件中，这样的话是永久的，这里使用命令配置，暂时的。 主机可以写，从机不能写只能读！主机中的所有信息都会被从机自动保存 主机断开连接，从机依旧可以连到主机，但没有写操作。如果主机重新连接了，从机依旧可以直接获取主机写的信息! 如果使用命令行配置主从，如果从机重启了，就会变回主机！只要变回从机，就能立马从主机获取值 ","date":"2021-03-15","objectID":"/redis-study-04/:1:3","tags":["redis"],"title":"Redis Study 04","uri":"/redis-study-04/"},{"categories":["学习"],"content":"redis学习04","date":"2021-03-15","objectID":"/redis-study-03/","tags":["redis"],"title":"Redis Study 03","uri":"/redis-study-03/"},{"categories":["学习"],"content":"三大特殊数据类型 ","date":"2021-03-15","objectID":"/redis-study-03/:1:0","tags":["redis"],"title":"Redis Study 03","uri":"/redis-study-03/"},{"categories":["学习"],"content":"geospatial（地理位置） Redis的GEO ####################################################### # geoadd 添加geo # geopos 获取geo 127.0.0.1:6379\u003e GEOADD china:city 116.40 39.90 beijing (integer) 1 127.0.0.1:6379\u003e GEOADD china:city 121.47 31.23 shanghai 106.50 29.53 chongqin (integer) 2 127.0.0.1:6379\u003e GEOADD china:city 120.16 30.24 hangzhou 108.96 34.26 xian (integer) 2 127.0.0.1:6379\u003e GEOPOS china:city beijing chongqin 1) 1) \"116.39999896287918091\" 2) \"39.90000009167092543\" 2) 1) \"106.49999767541885376\" 2) \"29.52999957900659211\" ####################################################### # geodist 两点之间的距离 127.0.0.1:6379\u003e GEODIST china:city beijing shanghai km # 查看北京到上海的距离 \"1067.3788\" ####################################################### # georadius 获取坐标点周围的数据 127.0.0.1:6379\u003e GEORADIUS china:city 110 30 1000 km # 获取坐标点位110,30方圆1000km在china:city数据 1) \"chongqin\" 2) \"xian\" 3) \"hangzhou\" 127.0.0.1:6379\u003e GEORADIUS china:city 110 30 500 km 1) \"chongqin\" 2) \"xian\" ####################################################### # georadiusbymember 以城市为中心方圆的数据 127.0.0.1:6379\u003e GEORADIUSBYMEMBER china:city beijing 100 km 1) \"beijing\" 127.0.0.1:6379\u003e GEORADIUSBYMEMBER china:city beijing 1000 km 1) \"beijing\" 2) \"xian\" 127.0.0.1:6379\u003e GEORADIUSBYMEMBER china:city hanghai 1000 km (error) ERR could not decode requested zset member 127.0.0.1:6379\u003e GEORADIUSBYMEMBER china:city shanghai 1000 km 1) \"hangzhou\" 2) \"shanghai\" ####################################################### # geohash 以hash返回数据的经纬度 127.0.0.1:6379\u003e GEOHASH china:city beijing 1) \"wx4fbxxfke0\" ####################################################### # geo底层实现原理其实是zset 127.0.0.1:6379\u003e ZRANGE china:city 0 -1 # 查看全部元素 1) \"chongqin\" 2) \"xian\" 3) \"hangzhou\" 4) \"shanghai\" 5) \"beijing\" 127.0.0.1:6379\u003e ZREM china:city beijing # 移除元素 (integer) 1 127.0.0.1:6379\u003e ZRANGE china:city 0 -1 1) \"chongqin\" 2) \"xian\" 3) \"hangzhou\" 4) \"shanghai\" ","date":"2021-03-15","objectID":"/redis-study-03/:1:1","tags":["redis"],"title":"Redis Study 03","uri":"/redis-study-03/"},{"categories":["学习"],"content":"hyperloglog 基数：一个set不重复元素的数量 hyperloglog主要用来做统计 如果可以容错可以使用这个。这个空间占用少。 ####################################################### # pfadd 添加元素 # pfcount 获得元素个数 # pfmerge 将两个set整合到一个新的集合 127.0.0.1:6379\u003e PFADD myset a b c d e f g h i j k (integer) 1 127.0.0.1:6379\u003e PFCOUNT myset (integer) 11 127.0.0.1:6379\u003e PFADD myset2 b s d j o l m n u (integer) 1 127.0.0.1:6379\u003e PFCOUNT myset2 (integer) 9 127.0.0.1:6379\u003e PFMERGE myset3 myset myset2 OK 127.0.0.1:6379\u003e PFCOUNT myset3 (integer) 17 ","date":"2021-03-15","objectID":"/redis-study-03/:1:2","tags":["redis"],"title":"Redis Study 03","uri":"/redis-study-03/"},{"categories":["学习"],"content":"bitmaps 位存储 只有存储0和1 ####################################################### # setbit 添加数据 # getbit 获得数据 # bitcount 统计个数 127.0.0.1:6379\u003e SETBIT sign 0 1 (integer) 0 127.0.0.1:6379\u003e SETBIT sign 1 1 (integer) 0 127.0.0.1:6379\u003e SETBIT sign 2 0 (integer) 0 127.0.0.1:6379\u003e SETBIT sign 3 0 (integer) 0 127.0.0.1:6379\u003e SETBIT sign 4 1 (integer) 0 127.0.0.1:6379\u003e GETBIT sign 3 (integer) 0 127.0.0.1:6379\u003e GETBIT sign 4 (integer) 1 127.0.0.1:6379\u003e BITCOUNT sign (integer) 3 ","date":"2021-03-15","objectID":"/redis-study-03/:1:3","tags":["redis"],"title":"Redis Study 03","uri":"/redis-study-03/"},{"categories":["学习"],"content":"事务 Redis事务本质：一组命令的集合。一个事务中的所有命令会被序列化，在事务执行的过程中，会按顺序执行。 一次性、顺序性、排他性。执行一些命令 Redis单条命令保持原子性，事务不保证原子性 Redis事务： 开始事务（） 命令入队（） 执行事务（） ####################################################### # multi 开始事务 # exec 执行事务 127.0.0.1:6379\u003e MULTI OK 127.0.0.1:6379\u003e set k1 v1 QUEUED 127.0.0.1:6379\u003e set k2 v2 QUEUED 127.0.0.1:6379\u003e get k2 QUEUED 127.0.0.1:6379\u003e set k3 v3 QUEUED 127.0.0.1:6379\u003e EXEC 1) OK 2) OK 3) \"v2\" 4) OK ####################################################### # discard 放弃事务（相当于回滚） 127.0.0.1:6379\u003e MULTI OK 127.0.0.1:6379\u003e set k4 v4 QUEUED 127.0.0.1:6379\u003e set k5 v5 QUEUED 127.0.0.1:6379\u003e DISCARD OK 127.0.0.1:6379\u003e get k4 (nil) ","date":"2021-03-15","objectID":"/redis-study-03/:2:0","tags":["redis"],"title":"Redis Study 03","uri":"/redis-study-03/"},{"categories":["学习"],"content":"编译型异常（代码有问题，命令有错），事务中的命令都不会执行 127.0.0.1:6379\u003e MULTI OK 127.0.0.1:6379\u003e set k1 v1 QUEUED 127.0.0.1:6379\u003e set k2 v2 QUEUED 127.0.0.1:6379\u003e set k3 v3 QUEUED 127.0.0.1:6379\u003e GETSET k4 # 错误命令 (error) ERR wrong number of arguments for 'getset' command 127.0.0.1:6379\u003e set k4 v4 QUEUED 127.0.0.1:6379\u003e set k5 v5 QUEUED 127.0.0.1:6379\u003e EXEC # 执行事务报错 (error) EXECABORT Transaction discarded because of previous errors. 127.0.0.1:6379\u003e get k5 # 所有命令都不会执行 (nil) ","date":"2021-03-15","objectID":"/redis-study-03/:2:1","tags":["redis"],"title":"Redis Study 03","uri":"/redis-study-03/"},{"categories":["学习"],"content":"运行时异常，如果队列中存在语法性（语法没有问题），那么执行命令的时候其他命令是可以正常执行的，错误命令抛出异常 127.0.0.1:6379\u003e set k1 v1 OK 127.0.0.1:6379\u003e MULTI OK 127.0.0.1:6379\u003e INCR k1 # 会执行报错 QUEUED 127.0.0.1:6379\u003e set k2 v2 QUEUED 127.0.0.1:6379\u003e set k3 v3 QUEUED 127.0.0.1:6379\u003e get k3 QUEUED 127.0.0.1:6379\u003e EXEC 1) (error) ERR value is not an integer or out of range # 虽然第一条命令报错了，但其他还是正常执行了 2) OK 3) OK 4) \"v3\" ","date":"2021-03-15","objectID":"/redis-study-03/:2:2","tags":["redis"],"title":"Redis Study 03","uri":"/redis-study-03/"},{"categories":["学习"],"content":"Redis锁 ","date":"2021-03-15","objectID":"/redis-study-03/:3:0","tags":["redis"],"title":"Redis Study 03","uri":"/redis-study-03/"},{"categories":["学习"],"content":"悲观锁 很悲观，认为什么时候都会出现问题，无论做什么都会加锁 ","date":"2021-03-15","objectID":"/redis-study-03/:3:1","tags":["redis"],"title":"Redis Study 03","uri":"/redis-study-03/"},{"categories":["学习"],"content":"乐观锁 很乐观，认为什么时候都不会出现问题，所以不会上锁，更新的时候去判断一下，在此期间是否有人修改过值 主要通过获取version 更新的时候比较第一次获取的version 正常执行成功 127.0.0.1:6379\u003e set money 100 OK 127.0.0.1:6379\u003e set out 0 OK 127.0.0.1:6379\u003e watch money # 监视money对象 OK 127.0.0.1:6379\u003e MULTI # 事务开始，事务执行期间数据没有发生变化，事务正常执行 OK 127.0.0.1:6379\u003e DECR money QUEUED 127.0.0.1:6379\u003e INCR out QUEUED 127.0.0.1:6379\u003e EXEC 1) (integer) 99 2) (integer) 1 测试多线程修改值，使用watch可以当做redis的乐观锁操作 127.0.0.1:6379\u003e watch money #监视money OK 127.0.0.1:6379\u003e MULTI OK 127.0.0.1:6379\u003e DECRBY money 20 QUEUED 127.0.0.1:6379\u003e INCRBY out 20 QUEUED 127.0.0.1:6379\u003e EXEC (nil) 执行前另一个事务修改值 127.0.0.1:6379\u003e INCRBY money 300 (integer) 399 ","date":"2021-03-15","objectID":"/redis-study-03/:3:2","tags":["redis"],"title":"Redis Study 03","uri":"/redis-study-03/"},{"categories":["学习"],"content":"redis.conf详解 启动的时候就通过配置文件来启动 ","date":"2021-03-15","objectID":"/redis-study-03/:4:0","tags":["redis"],"title":"Redis Study 03","uri":"/redis-study-03/"},{"categories":["学习"],"content":"单位 redis单位\u0026ldquo;redis单位\u0026rdquo; \"\rredis单位\r 配置文件，unit单位，对大小写不敏感 ","date":"2021-03-15","objectID":"/redis-study-03/:4:1","tags":["redis"],"title":"Redis Study 03","uri":"/redis-study-03/"},{"categories":["学习"],"content":"包含 redis包含\u0026ldquo;redis包含\u0026rdquo; \"\rredis包含\r 导入文件 ","date":"2021-03-15","objectID":"/redis-study-03/:4:2","tags":["redis"],"title":"Redis Study 03","uri":"/redis-study-03/"},{"categories":["学习"],"content":"网络 bind 127.0.0.1 # 绑定的ip protected-mode yes # 保护模式是否开启 port 6379 # 端口号 ","date":"2021-03-15","objectID":"/redis-study-03/:4:3","tags":["redis"],"title":"Redis Study 03","uri":"/redis-study-03/"},{"categories":["学习"],"content":"通用GENERAL daemonize yes # 以守护进程的方式运行，默认是no pidfile /var/run/redis_6379.pid # 如果以后台的方式运行，我们就需要指定一个pid文件 ","date":"2021-03-15","objectID":"/redis-study-03/:4:4","tags":["redis"],"title":"Redis Study 03","uri":"/redis-study-03/"},{"categories":["学习"],"content":"日志 redis日志\u0026ldquo;redis日志\u0026rdquo; \"\rredis日志\r logfile \"\" # 日志的文件位置名 databases 16 # 数据库数量，默认是16个数据库 always-show-logo yes # 是否总是显示logo ","date":"2021-03-15","objectID":"/redis-study-03/:4:5","tags":["redis"],"title":"Redis Study 03","uri":"/redis-study-03/"},{"categories":["学习"],"content":"快照 持久化，在规定的时间执行了多少次操作，则会持久化到文件.rdb或.aof中 redis是内存数据库，如果没有持久化，数据库断点即失 # 如果900内至少有1个key进行修改，就会进行持久化操作 save 900 1 # 如果300内有10个key进行修改，就会进行持久化操作 save 300 10 # 如果60内有10000个key进行修改，就会进行持久化操作 save 60 10000 stop-writes-on-bgsave-error yes # 持久化如果出错是否还需要继续运行 rdbcompression yes # 是否压缩rdb文件，需要消耗一些cpu资源 rdbchecksum yes # 保存rdb文件的时候，进行错误的检查校验 dir ./ # rdb文件的保存路径 ","date":"2021-03-15","objectID":"/redis-study-03/:4:6","tags":["redis"],"title":"Redis Study 03","uri":"/redis-study-03/"},{"categories":["学习"],"content":"REPLICATION 复制 ","date":"2021-03-15","objectID":"/redis-study-03/:4:7","tags":["redis"],"title":"Redis Study 03","uri":"/redis-study-03/"},{"categories":["学习"],"content":"SECURITY 安全 ","date":"2021-03-15","objectID":"/redis-study-03/:4:8","tags":["redis"],"title":"Redis Study 03","uri":"/redis-study-03/"},{"categories":["学习"],"content":"限制CLIENTS maxclients 10000 # 设置能连接上redis的最多客户端数量 maxmemory \u003cbytes\u003e # redis配置的最大内存容量 maxmemory-policy noeviction # 内存达到上限的处理策略 1. volatile-lru：只对设置了过期时间的key进行LRU（默认值） 2. allkeys-lru：删除LRU算法的key 3. volatile-lfu：只对设置了过期时间的key进行LFU 4. allkeys-lfu：删除LFU算法的key 5. volatile-random：随机删除即将过期的key 6. allkeys-random：随机删除 7. volatile-ttl：删除即将过期的 8. noeviction：永不过期，返回错误 ","date":"2021-03-15","objectID":"/redis-study-03/:4:9","tags":["redis"],"title":"Redis Study 03","uri":"/redis-study-03/"},{"categories":["学习"],"content":"APPEND ONLY模式 aof持久化 appendonly no # 默认是不开启aof模式 appendfilename \"appendonly.aof\" # 持久化文件的名字 # appendfsync always # 每次修改都会sync。消耗性能 appendfsync everysec # 每秒执行一次sync。可能会丢失这1s的数据 # appendfsync no # 不执行sync，这个时候操作系统自己同步数据，速度最快 ","date":"2021-03-15","objectID":"/redis-study-03/:4:10","tags":["redis"],"title":"Redis Study 03","uri":"/redis-study-03/"},{"categories":["学习"],"content":"Redis持久化 Redis是内存数据库，如果不将内存中的数据库状态保存到磁盘，那么一旦服务器进程退出，服务器中的数据库状态也会消失。所以redis提供了持久化功能 ","date":"2021-03-15","objectID":"/redis-study-03/:5:0","tags":["redis"],"title":"Redis Study 03","uri":"/redis-study-03/"},{"categories":["学习"],"content":"RDB 什么是RDB 在指定的时间间隔内将内存中的数据集体快照写入磁盘中，也就是快照，恢复时是将快照文件直接读到内存中。 Redis会单独创建一个（fork）一个子进程进行持久化，会将数据写入到一个临时的文件中，待持久化过程都结束了，再用这个临时文件替换掉上次持久化好的文件。整个过程中，主进程不会进行任何IO操作。这就确保了极高的性能。如果需要大规模数据的恢复，且对数据恢复的完整性不是很敏感，RDB要比AOF高效。RDB缺点是最后一次持久化的数据可能丢失。 RDB保存的dump.rdb文件，在conf文件中进行配置 dbfilename dump.rdb 触发机制 save规则满足的情况下，会自动触发rdb规则 执行flushall命令也会触发rdb规则 退出redis，也会产生rdb文件 备份就会生成dump.rdb 如何恢复rdb文件 只需要将rdb文件放在启动目录下即可，redis启动的时候回自动检查dump.rdb恢复其中的数据。 查看需要存在的位置 127.0.0.1:6379\u003e clear 127.0.0.1:6379\u003e config get dir 1) \"dir\" 2) \"/root\" # 如果目录下存在dump.rdb文件，启动的时候就会自动恢复其中的数据 几乎默认的配置就够用了 优点： 适合大规模的数据恢复！ 如果对数据的完整性要求不高 缺点： 需要一定的时间间隔进行操作，如果redis意外宕机了，这个最后一次修改数据就没了 fork进程的时候会占用一定的内容空间 ","date":"2021-03-15","objectID":"/redis-study-03/:5:1","tags":["redis"],"title":"Redis Study 03","uri":"/redis-study-03/"},{"categories":["学习"],"content":"AOF（Append Only File） 什么是AOF： 将执行过的所有命令记录下来 以日志的形式来记录每个写操作，将Redis执行过程中的所有指令记录下来（读操作不记录），只许追加文件，但不可以改写文件，Redis启动之初会读取该文件重新构造数据。换言之，Redis重启的话就是根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作。 AOF 保存的是appendonly.aof文件 默认是不开启的，需要手动进行配置，只许将appendonly改为yes就开启的AOF 重启，Redis就生效了 如果appendonly.aof文件有错，redis是启动不了的，需要修复aof文件。redis提供了一个工具redis-check-aof –fix 如果文件正常，重启就可以直接恢复了 优点： 每一次修改都同步，文件完整会更好 每秒同步一次，可能会丢失一秒的数据 从不同步，效率最高 缺点： 相对于数据文件来说，aof远大于rdb，修复速度也比rdb慢 aof运行效率比rdb慢，所以默认的是rdb持久化 ","date":"2021-03-15","objectID":"/redis-study-03/:5:2","tags":["redis"],"title":"Redis Study 03","uri":"/redis-study-03/"},{"categories":["学习"],"content":"Redis订阅发布 订阅端 127.0.0.1:6379\u003e SUBSCRIBE cc # 订阅一个频道 Reading messages... (press Ctrl-C to quit) 1) \"subscribe\" 2) \"cc\" 3) (integer) 1 # 等待读取推送的信息 1) \"message\" #消息 2) \"cc\" #频道 3) \"hello,world\" #具体内容 发送端 127.0.0.1:6379\u003e PUBLISH cc hello,world # 发布者发布消息到频道 (integer) 1 ","date":"2021-03-15","objectID":"/redis-study-03/:6:0","tags":["redis"],"title":"Redis Study 03","uri":"/redis-study-03/"},{"categories":["学习"],"content":"redis学习02","date":"2021-03-12","objectID":"/redis-study-02/","tags":["redis"],"title":"Redis Study 02","uri":"/redis-study-02/"},{"categories":["学习"],"content":"五大数据类型 ","date":"2021-03-12","objectID":"/redis-study-02/:1:0","tags":["redis"],"title":"Redis Study 02","uri":"/redis-study-02/"},{"categories":["学习"],"content":"Stirng（字符串） ####################################################### # set # get # exists # append 127.0.0.1:6379\u003e set key1 v1 # 设置key1 OK 127.0.0.1:6379\u003e get key1 # 获得值 \"v1\" 127.0.0.1:6379\u003e exists key1 # 判断key是否存在 (integer) 1 127.0.0.1:6379\u003e append key1 \"hello\" # 追加字符串，如果当前key不存在相当于set key (integer) 7 127.0.0.1:6379\u003e get key1 \"v1hello\" ####################################################### # strlen 127.0.0.1:6379\u003e strlen key1 # 获取字符串长度 (integer) 7 127.0.0.1:6379\u003e append key1 \",cc\" (integer) 10 127.0.0.1:6379\u003e strlen key1 (integer) 10 127.0.0.1:6379\u003e get key1 \"v1hello,cc\" ####################################################### # 步长 i++ 127.0.0.1:6379\u003e incr views # 自增1 (integer) 1 127.0.0.1:6379\u003e get views \"1\" 127.0.0.1:6379\u003e decr views # 自减1 (integer) 0 127.0.0.1:6379\u003e incrby views 10 # 设置步长，指定增量 (integer) 10 127.0.0.1:6379\u003e get views \"10\" 127.0.0.1:6379\u003e DECRBY views 5 (integer) 5 127.0.0.1:6379\u003e GET views \"5\" ####################################################### # 字符串范围 127.0.0.1:6379\u003e set key1 \"hello,cc\" OK 127.0.0.1:6379\u003e GETRANGE key1 0 3 # 截取字符串， [0,3] \"hell\" 127.0.0.1:6379\u003e GETRANGE key1 0 -1 # 获取全部字符串，相当于get key \"hello,cc\" # 替换 127.0.0.1:6379\u003e set key2 abcdefg OK 127.0.0.1:6379\u003e GET key2 \"abcdefg\" 127.0.0.1:6379\u003e SETRANGE key2 1 xx # 替换指定位置开始的字符串 (integer) 7 127.0.0.1:6379\u003e GET key2 \"axxdefg\" ####################################################### # setex (set with expire) 设置过期时间 # setnx (set if not exist) 不存在才设置（在分布式锁中常使用） 127.0.0.1:6379\u003e SETEX key3 30 \"hello\" # 设置key3为hello，30秒后过期 OK 127.0.0.1:6379\u003e ttl key3 # 查看剩余时间 (integer) 22 127.0.0.1:6379\u003e get key3 \"hello\" 127.0.0.1:6379\u003e SETNX mykey redis # 如果mykey不存在，创建mykey (integer) 1 127.0.0.1:6379\u003e get mykey \"redis\" 127.0.0.1:6379\u003e SETNX mykey mongodb # 如果mykey存在，创建失败 (integer) 0 127.0.0.1:6379\u003e get mykey \"redis\" 127.0.0.1:6379\u003e ttl key3 (integer) -2 127.0.0.1:6379\u003e get key3 (nil) ####################################################### # mset （同时设置多个值） # mget （同时获取多个值） 127.0.0.1:6379[1]\u003e mset k1 v1 k2 v2 k3 v3 # 同时设置多个值 OK 127.0.0.1:6379[1]\u003e keys * 1) \"k1\" 2) \"k3\" 3) \"k2\" 127.0.0.1:6379[1]\u003e mget k1 k2 k3 # 同时获取多个值 1) \"v1\" 2) \"v2\" 3) \"v3\" 127.0.0.1:6379[1]\u003e mset k1 v1 k4 v4 OK 127.0.0.1:6379[1]\u003e keys * 1) \"k1\" 2) \"k4\" 3) \"k3\" 4) \"k2\" 127.0.0.1:6379[1]\u003e mget k1 k2 k3 k4 1) \"v1\" 2) \"v2\" 3) \"v3\" 4) \"v4\" 127.0.0.1:6379[1]\u003e msetnx k1 v1 k5 v5 # msetnx是一个原子性操作，要么都成功，要么都失败 (integer) 0 127.0.0.1:6379[1]\u003e keys * 1) \"k1\" 2) \"k4\" 3) \"k3\" 4) \"k2\" ####################################################### # 对象 127.0.0.1:6379[1]\u003e set user:1 {name:zhangsan,age:3} # 设置一个user:1对象，值为json字符来保存一个对象 OK 127.0.0.1:6379[1]\u003e mset user:1:name zhangsan user:1:age 3 # 这里的key是一个巧妙的设计：user:{id}:{filed}，如此设计在redis中是完全ok的 OK 127.0.0.1:6379[1]\u003e mget user:1:name user:1:age 1) \"zhangsan\" 2) \"3\" ####################################################### # getset 先get后set 127.0.0.1:6379[1]\u003e GETSET db redis # 如果不存在值，返回nil，并设置值 (nil) 127.0.0.1:6379[1]\u003e get db \"redis\" 127.0.0.1:6379[1]\u003e GETSET db mongodb # 如果存在值，返回原来的值，并做更新操作 \"redis\" 127.0.0.1:6379[1]\u003e get db \"mongodb\" ","date":"2021-03-12","objectID":"/redis-study-02/:1:1","tags":["redis"],"title":"Redis Study 02","uri":"/redis-study-02/"},{"categories":["学习"],"content":"List 列表是一种基本的数据类型 在Redis里面，我们可以把list完成，栈、队列、堵塞队列。 ####################################################### # lpush # lpop # lrange 127.0.0.1:6379[1]\u003e LPUSH list one # 将一个值或多个值，插入到列表头部 (integer) 1 127.0.0.1:6379[1]\u003e LPUSH list two (integer) 2 127.0.0.1:6379[1]\u003e LPUSH list three (integer) 3 127.0.0.1:6379[1]\u003e LRANGE list 0 -1 # 获取list中的值 1) \"three\" 2) \"two\" 3) \"one\" 127.0.0.1:6379[1]\u003e LRANGE list 0 1 # 通过区间获取具体的值 1) \"three\" 2) \"two\" 127.0.0.1:6379[1]\u003e RPUSH list right # 将一个或多个值放到列表的尾部 (integer) 4 127.0.0.1:6379[1]\u003e LRANGE list 0 -1 1) \"three\" 2) \"two\" 3) \"one\" 4) \"right\" 127.0.0.1:6379[1]\u003e LPOP list # 移除列表的第一个元素 \"three\" 127.0.0.1:6379[1]\u003e RPOP list # 移除列表的最后一个元素 \"right\" 127.0.0.1:6379[1]\u003e LRANGE list 0 -1 1) \"two\" 2) \"one\" ####################################################### # lindex # llen 127.0.0.1:6379[1]\u003e LINDEX list 0 # 通过下标获取list中的某一个值 \"two\" 127.0.0.1:6379[1]\u003e LINDEX list 1 \"one\" 127.0.0.1:6379\u003e LPUSH list one (integer) 1 127.0.0.1:6379\u003e LPUSH list two (integer) 2 127.0.0.1:6379\u003e LPUSH list three (integer) 3 127.0.0.1:6379\u003e LLEN list # 返回列表的长度 (integer) 3 ####################################################### # lrem 127.0.0.1:6379\u003e LRANGE list 0 -1 1) \"three\" 2) \"three\" 3) \"two\" 4) \"one\" 127.0.0.1:6379\u003e LREM list 1 one # 移除list集合中指定个数的value (integer) 1 127.0.0.1:6379\u003e LRANGE list 0 -1 1) \"three\" 2) \"three\" 3) \"two\" 127.0.0.1:6379\u003e LREM list 2 three (integer) 2 127.0.0.1:6379\u003e LRANGE list 0 -1 1) \"two\" ####################################################### # trim修剪 127.0.0.1:6379\u003e RPUSH mylist hello (integer) 1 127.0.0.1:6379\u003e RPUSH mylist hello1 (integer) 2 127.0.0.1:6379\u003e RPUSH mylist hello2 (integer) 3 127.0.0.1:6379\u003e RPUSH mylist hello3 (integer) 4 127.0.0.1:6379\u003e LRANGE mylist 0 -1 1) \"hello\" 2) \"hello1\" 3) \"hello2\" 4) \"hello3\" 127.0.0.1:6379\u003e LTRIM mylist 1 2 # 通过下标截取指定长度，这个list已经改变，只剩下截取的元素 OK 127.0.0.1:6379\u003e LRANGE mylist 0 -1 1) \"hello1\" 2) \"hello2\" ####################################################### # rpoplpush 127.0.0.1:6379\u003e LRANGE mylist 0 -1 1) \"hello1\" 2) \"hello2\" 127.0.0.1:6379\u003e RPOPLPUSH mylist myotherlist # 移动列表的最后一个元素到其他表中 \"hello2\" 127.0.0.1:6379\u003e LRANGE mylist 0 -1 # 查看原来的表 1) \"hello1\" 127.0.0.1:6379\u003e LRANGE myotherlist 0 -1 # 查看新的表 1) \"hello2\" ####################################################### # exists # lset 将列表指定下标的值，替换为另外一个值，更新操作 127.0.0.1:6379\u003e exists list # 判断列表是否存在 (integer) 0 127.0.0.1:6379\u003e lset list 0 item # 不存在，更新，报错 (error) ERR no such key 127.0.0.1:6379\u003e LPUSH list value (integer) 1 127.0.0.1:6379\u003e lset list 0 item # 存在，更新当前下标的值 OK 127.0.0.1:6379\u003e LRANGE list 0 -1 1) \"item\" 127.0.0.1:6379\u003e lset list 1 other # 列表不存在，也报错 (error) ERR index out of range ####################################################### # linsert 将某个具体的value插入列表中某个元素的前面或者后面 127.0.0.1:6379\u003e LPUSH mylist hello (integer) 1 127.0.0.1:6379\u003e LPUSH mylist world (integer) 2 127.0.0.1:6379\u003e LINSERT mylist before world other (integer) 3 127.0.0.1:6379\u003e LRANGE mylist 0 -1 1) \"other\" 2) \"world\" 3) \"hello\" 127.0.0.1:6379\u003e LINSERT mylist after world other1 (integer) 4 127.0.0.1:6379\u003e LRANGE mylist 0 -1 1) \"other\" 2) \"world\" 3) \"other1\" 4) \"hello\" 小结： list实际上是一个链表，before Node after，left，right都可以插入 如果key不存在，创建新的链表 如果key存在，新增内容 如果移除了key，空链表，也代表不存在 在两边插入或改动值，效率最高。中间元素，相对来说效率会低一点 使用场景： 消息排队 消息队列 ","date":"2021-03-12","objectID":"/redis-study-02/:1:2","tags":["redis"],"title":"Redis Study 02","uri":"/redis-study-02/"},{"categories":["学习"],"content":"Set（集合） Set中的值是不能重复的 ####################################################### # sadd # smembers # sismember 127.0.0.1:6379\u003e sadd myset \"hello\" # set集合中添加元素 (integer) 1 127.0.0.1:6379\u003e sadd myset cc (integer) 1 127.0.0.1:6379\u003e SMEMBERS myset # 查看指定set所有值 1) \"cc\" 2) \"hello\" 127.0.0.1:6379\u003e SISMEMBER myset cc # 判断某一个值在不在set中 (integer) 1 127.0.0.1:6379\u003e SISMEMBER myset a (integer) 0 ####################################################### # scard # 获取set集合中的内容元素个数 127.0.0.1:6379\u003e scard myset # 获取set集合元素个数 (integer) 2 127.0.0.1:6379\u003e SMEMBERS myset 1) \"cc\" 2) \"hello\" 127.0.0.1:6379\u003e SADD myset cc # set 已存在元素 (integer) 0 127.0.0.1:6379\u003e SADD myset cc1 (integer) 1 127.0.0.1:6379\u003e SCARD myset (integer) 3 127.0.0.1:6379\u003e SMEMBERS myset 1) \"cc\" 2) \"hello\" 3) \"cc1\" ####################################################### # srem 移除set集合里的指定元素 127.0.0.1:6379\u003e srem myset hello (integer) 1 127.0.0.1:6379\u003e SMEMBERS myset 1) \"cc\" 2) \"cc1\" ####################################################### # srandmember 随机抽选出几个元素 127.0.0.1:6379\u003e SRANDMEMBER myset # 随机抽选一个元素 \"cc\" 127.0.0.1:6379\u003e SRANDMEMBER myset \"cc1\" 127.0.0.1:6379\u003e SRANDMEMBER myset 2 # 随机抽选出两个元素 1) \"cc\" 2) \"cc1\" ####################################################### # spop 随机移除几个元素 127.0.0.1:6379\u003e SMEMBERS myset 1) \"cc\" 2) \"cc1\" 127.0.0.1:6379\u003e spop myset \"cc1\" 127.0.0.1:6379\u003e spop myset \"cc\" ####################################################### # smove 将指定的值移动到另一个集合 127.0.0.1:6379\u003e SMEMBERS myset 1) \"cc\" 2) \"world\" 3) \"hello\" 127.0.0.1:6379\u003e SADD myset2 set2 (integer) 1 127.0.0.1:6379\u003e smove myset myset2 cc (integer) 1 127.0.0.1:6379\u003e SMEMBERS myset 1) \"world\" 2) \"hello\" 127.0.0.1:6379\u003e SMEMBERS myset2 1) \"cc\" 2) \"set2\" ####################################################### # 数字集合类（差集、并集、交集） 127.0.0.1:6379\u003e sadd key1 a (integer) 1 127.0.0.1:6379\u003e sadd key1 b (integer) 1 127.0.0.1:6379\u003e sadd key1 c (integer) 1 127.0.0.1:6379\u003e sadd key2 c (integer) 1 127.0.0.1:6379\u003e sadd key2 d (integer) 1 127.0.0.1:6379\u003e sadd key2 e (integer) 1 127.0.0.1:6379\u003e SDIFF key1 key2 # 差集 1) \"a\" 2) \"b\" 127.0.0.1:6379\u003e SINTER key1 key2 # 交集 共同好友实现 1) \"c\" 127.0.0.1:6379\u003e SUNION key1 key2 # 并集 1) \"a\" 2) \"b\" 3) \"c\" 4) \"e\" 5) \"d\" set是无序不重复集合，抽随机 ","date":"2021-03-12","objectID":"/redis-study-02/:1:3","tags":["redis"],"title":"Redis Study 02","uri":"/redis-study-02/"},{"categories":["学习"],"content":"Zset 在set的基础上，增加了一个值，set k1 v1，zset k2 score v2 ####################################################### zadd # 添加一个或多个值 zrange # 遍历查询 127.0.0.1:6379\u003e zadd myset 1 one (integer) 1 127.0.0.1:6379\u003e zadd myset 2 two 3 three (integer) 2 127.0.0.1:6379\u003e ZRANGE myset 0 -1 1) \"one\" 2) \"two\" 3) \"three\" ####################################################### # zrangebyscore 根据score排序 127.0.0.1:6379\u003e zset salary 2000 a (error) ERR unknown command `zset`, with args beginning with: `salary`, `2000`, `a`, 127.0.0.1:6379\u003e zadd salary 2000 a (integer) 1 127.0.0.1:6379\u003e zadd salary 5000 b (integer) 1 127.0.0.1:6379\u003e zadd salary 500 c (integer) 1 127.0.0.1:6379\u003e ZRANGEBYSCORE salary -inf +inf #显示全部用户，从小到大 1) \"c\" 2) \"a\" 3) \"b\" 127.0.0.1:6379\u003e ZRANGEBYSCORE salary -inf +inf withscores #显示全部用户并且附带成绩 1) \"c\" 2) \"500\" 3) \"a\" 4) \"2000\" 5) \"b\" 6) \"5000\" 127.0.0.1:6379\u003e ZREVRANGE salary 0 -1 withscores # 显示全部用户，从大到小 1) \"b\" 2) \"5000\" 3) \"c\" 4) \"500\" ####################################################### # zrem 移除指定元素 # zcard 获取集合中的个数 127.0.0.1:6379\u003e ZRANGEBYSCORE salary -inf +inf 1) \"c\" 2) \"a\" 3) \"b\" 127.0.0.1:6379\u003e ZREM salary a (integer) 1 127.0.0.1:6379\u003e ZRANGEBYSCORE salary -inf +inf 1) \"c\" 2) \"b\" 127.0.0.1:6379\u003e zcard salary (integer) 2 ####################################################### # zcount 获取指定区间的个数 127.0.0.1:6379\u003e zadd myset 1 hello (integer) 1 127.0.0.1:6379\u003e zadd myset 2 world 3 c (integer) 2 127.0.0.1:6379\u003e ZCOUNT myset 1 3 (integer) 3 ","date":"2021-03-12","objectID":"/redis-study-02/:1:4","tags":["redis"],"title":"Redis Study 02","uri":"/redis-study-02/"},{"categories":["学习"],"content":"Hash ####################################################### # hset set一个具体的value # hget get一个具体的value # hmset set多个具体的value # hmget get多个具体的value # hgetall get所有 # hdel 删除hash指定key字段！对应的value值也就消失了 127.0.0.1:6379\u003e hset myhash field1 c (integer) 1 127.0.0.1:6379\u003e HGET myhash field1 \"c\" 127.0.0.1:6379\u003e HMSET myhash field1 hello field2 world OK 127.0.0.1:6379\u003e HMGET myhash field1 field2 1) \"hello\" 2) \"world\" 127.0.0.1:6379\u003e HGETALL myhash 1) \"field1\" 2) \"hello\" 3) \"field2\" 4) \"world\" 127.0.0.1:6379\u003e HGETALL myhash 1) \"field2\" 2) \"world\" 3) \"field1\" 4) \"hello\" 127.0.0.1:6379\u003e HDEL myhash field1 (integer) 1 127.0.0.1:6379\u003e HGETALL myhash 1) \"field2\" 2) \"world\" ####################################################### # hlen 获取hash表的字符字段 127.0.0.1:6379\u003e hgetall myhash 1) \"field2\" 2) \"world\" 127.0.0.1:6379\u003e hlen myhash (integer) 1 ####################################################### # hexists 判断hash中指定字段是否存在 127.0.0.1:6379\u003e hgetall myhash 1) \"field2\" 2) \"world\" 127.0.0.1:6379\u003e HEXISTS myhash field2 (integer) 1 127.0.0.1:6379\u003e HEXISTS myhash field1 (integer) 0 ####################################################### # hkeys 只获得所有的field # hvals 只获得所有的value 127.0.0.1:6379\u003e HKEYS myhash 1) \"field2\" 127.0.0.1:6379\u003e HVALS myhash 1) \"world\" ####################################################### # hincrby 步长 自增 127.0.0.1:6379\u003e hset myhash field3 5 (integer) 1 127.0.0.1:6379\u003e HINCRBY myhash field3 1 (integer) 6 127.0.0.1:6379\u003e HINCRBY myhash field3 -1 (integer) 5 ####################################################### # hsetnx 没有元素则创建，有元素失败 127.0.0.1:6379\u003e HSETNX myhash field4 hello (integer) 1 127.0.0.1:6379\u003e HSETNX myhash field4 hello1 (integer) 0 map集合， key-map，本质和string类型有太大区别，还是一个简单的key-value 使用场景： hash变更数据，hash更适合对象的存储，string更适合字符串的存储 ","date":"2021-03-12","objectID":"/redis-study-02/:1:5","tags":["redis"],"title":"Redis Study 02","uri":"/redis-study-02/"},{"categories":["学习"],"content":"redis学习01","date":"2021-03-11","objectID":"/redis-study-01/","tags":["redis"],"title":"Redis Study 01","uri":"/redis-study-01/"},{"categories":["学习"],"content":"NoSQL的四大分类 ","date":"2021-03-11","objectID":"/redis-study-01/:1:0","tags":["redis"],"title":"Redis Study 01","uri":"/redis-study-01/"},{"categories":["学习"],"content":"KV键值对 新浪：Redis 美团：Redis+Tair 阿里、百度：Redis+Memecache ","date":"2021-03-11","objectID":"/redis-study-01/:1:1","tags":["redis"],"title":"Redis Study 01","uri":"/redis-study-01/"},{"categories":["学习"],"content":"文档型数据库 MongoDB（一般必须掌握） MongoDB是一个基于分布式文件存储的数据库，C++编写，用来处理大量文档 MongoDB是一个介于关系型数据库和非关系型数据库之间的产品，MongoDB是非关系型数据库中功能最丰富的，最像关系型数据库的 ConthDB（国外，不需了解） ","date":"2021-03-11","objectID":"/redis-study-01/:1:2","tags":["redis"],"title":"Redis Study 01","uri":"/redis-study-01/"},{"categories":["学习"],"content":"列存储数据库 HBase 分布式文件系统 ","date":"2021-03-11","objectID":"/redis-study-01/:1:3","tags":["redis"],"title":"Redis Study 01","uri":"/redis-study-01/"},{"categories":["学习"],"content":"图关系数据库 不是存放图形，是存放关系的 Neo4j、infoGrid ","date":"2021-03-11","objectID":"/redis-study-01/:1:4","tags":["redis"],"title":"Redis Study 01","uri":"/redis-study-01/"},{"categories":["学习"],"content":"Redis概述 ","date":"2021-03-11","objectID":"/redis-study-01/:2:0","tags":["redis"],"title":"Redis Study 01","uri":"/redis-study-01/"},{"categories":["学习"],"content":"Redis是什么 Redis（Remote Dictionary Server）远程字典服务 是一个开源的使用C语言编写、支持网络，可基于内存亦可持久化的日志型，Key-Value的数据库，提供多种语言的API redis会周期性的把更新的数据写进磁盘或者把修改操作写入追加的记录文件，并在此基础上实现master-slave（主从）同步 ","date":"2021-03-11","objectID":"/redis-study-01/:2:1","tags":["redis"],"title":"Redis Study 01","uri":"/redis-study-01/"},{"categories":["学习"],"content":"Redis能干嘛 内存存储，持久化，内存中是断点即失的，所以说持久化很重要（rdb，aof） 效率高，可以用于高速缓存 发布订阅系统 地图信息分析 计时器，计数器 。。。 ","date":"2021-03-11","objectID":"/redis-study-01/:2:2","tags":["redis"],"title":"Redis Study 01","uri":"/redis-study-01/"},{"categories":["学习"],"content":"Redis特性 多样的数据类型 持久化 集群 事务 。。。 ","date":"2021-03-11","objectID":"/redis-study-01/:2:3","tags":["redis"],"title":"Redis Study 01","uri":"/redis-study-01/"},{"categories":["学习"],"content":"测试Redis性能 ","date":"2021-03-11","objectID":"/redis-study-01/:3:0","tags":["redis"],"title":"Redis Study 01","uri":"/redis-study-01/"},{"categories":["学习"],"content":"使用benchmark性能测试 使用Redis-benchmark性能测试 ","date":"2021-03-11","objectID":"/redis-study-01/:3:1","tags":["redis"],"title":"Redis Study 01","uri":"/redis-study-01/"},{"categories":["学习"],"content":"Redis基础知识 ","date":"2021-03-11","objectID":"/redis-study-01/:4:0","tags":["redis"],"title":"Redis Study 01","uri":"/redis-study-01/"},{"categories":["学习"],"content":"Redis基本操作命令 Redis默认有16个数据库 默认使用第0个数据库 select index，切换数据库 DBSIZE，查看当前数据库大小 keys *，查看当前数据库所有的key flushdb，清除当前数据库 flushall，清除所有数据库 set name cc，set key exists name，判断当前的key是否存在 move name，移除当前的key expire name 10，设置key的过期时间单位秒 ttl name，查看key的剩余时间 get name，获得key type name，查看key的类型 ","date":"2021-03-11","objectID":"/redis-study-01/:4:1","tags":["redis"],"title":"Redis Study 01","uri":"/redis-study-01/"},{"categories":["学习"],"content":"Redis是单线程的 Redis是很快的。官方表示Redis是基于内存操作的，CPU并不是Redis的瓶颈Redis是根据机器的内存和网络带宽，可以使用单线程就使用单线程。 ","date":"2021-03-11","objectID":"/redis-study-01/:4:2","tags":["redis"],"title":"Redis Study 01","uri":"/redis-study-01/"},{"categories":["学习"],"content":"Redis为什么单线程还这么快 误区1：高性能的服务器一定是多线程的 误区2：多线程（CPU上下文切换）一定比单线程效率高 核心，Redis是将所有的数据全部存放在内存中，所以使用单线程去操作效率就是最高的。多线程（CPU上下文切换：耗时操作），对于内存系统来说，没有上下文切换效率就是最高的。多次读写都是在一个CPU上，在内存情况下，这个就是最优的方案。 ","date":"2021-03-11","objectID":"/redis-study-01/:4:3","tags":["redis"],"title":"Redis Study 01","uri":"/redis-study-01/"},{"categories":["学习"],"content":"redis面试01","date":"2021-03-11","objectID":"/redis-interview-01/","tags":["redis"],"title":"Redis Interview 01","uri":"/redis-interview-01/"},{"categories":["学习"],"content":"概述 ","date":"2021-03-11","objectID":"/redis-interview-01/:1:0","tags":["redis"],"title":"Redis Interview 01","uri":"/redis-interview-01/"},{"categories":["学习"],"content":"什么是Redis Redis是一个使用C语言编写的，开源的（BSD许可）高性能非关系型（NoSQL）的键值对数据库。 Redis可以存储键和五种不同类型的值之间的映射。键的类型只能为字符串，值支持5种数据类型：字符串，列表，集合，散列表，有序集合。 与传统数据库不同的是Redis的数据是存在内存中的，所以读写速度非常快，因此Redis被广泛引用与缓存方向，每秒可以处理11万写操作，8万读操作，是已知性能最快的Key-Value DB。另外，Redis也经常用来做分布式锁。除此之外，Redis支持事务、持久化、LUA脚本、LRU驱动事件、多种集群方案。 ","date":"2021-03-11","objectID":"/redis-interview-01/:1:1","tags":["redis"],"title":"Redis Interview 01","uri":"/redis-interview-01/"},{"categories":["学习"],"content":"Redis有哪些优缺点 优点 读写性能优异，Redis能写的速度是11w次/秒，写的速度是8w次/秒 支持数据持久化，支持RDB和AOF两种持久化方式 支持事务，Redis的所有操作都是原子性的，同时Redis还支持对几个操作合并后的原子性操作 数据结构丰富，除了支持String类型的Value外还支持hash、set、zset、list等数据结构 支持主从复制，主机会自动将数据同步到从机，可以进行读写分离 缺点 数据库容量容易受到物理内存限制，不能作为海量数据的高性能读写，因此Redis适合的场景主要局限在较小数据量的高性能操作和运算上。 Redis不具备自动容错和回复功能，主机从机宕机都会导致前端部分读写请求失败，需要等待机器重启或手动切换前端的IP才能回复 主机宕机，宕机前有部分数据未及时同步到从机，切换IP后还会引入数据不一致的问题，降低了系统的可用性。 Redis较难支持在线扩容，在集群容量到达上限时在线扩容会变得很复杂，为避免这一问题，运维人员在系统上线时必须确保有足够的空间，这对资源造成了很大的浪费 ","date":"2021-03-11","objectID":"/redis-interview-01/:1:2","tags":["redis"],"title":"Redis Interview 01","uri":"/redis-interview-01/"},{"categories":["学习"],"content":"为什么要用Redis 高性能： 假如用户第一次访问数据库中的某些数据，这个过程会比较慢，因为是从硬盘上读取的。将用户访问的数据缓存在缓存中，这样下次再访问这些数据会直接从缓存中获取。操作缓存就是直接操作内存，所以速度相当快，如果数据库中的对应数据改变的之后，同步改变缓存中的对应数据即可。 高并发： 直接操作缓存能够承受的请求是远远大于直接访问数据库的，所以可以考虑把数据库中的部分数据转移到缓存中去，这样用户的一部分请求会直接到缓存这里而不用经过数据库。 ","date":"2021-03-11","objectID":"/redis-interview-01/:1:3","tags":["redis"],"title":"Redis Interview 01","uri":"/redis-interview-01/"},{"categories":["学习"],"content":"为什么要用Redis而不用map/guava做缓存 缓存分为本地缓存和分布式缓存。以Java为例，使用自带的map或guava实现的是本地缓存，最主要的特点是轻量以及快速，生命周期随着jvm的销毁而结束，并且在多实例的情况下，每一个实例需要各自保存一份缓存，缓存不具备一致性。 使用Redis或Memcache之类的称为分布式缓存，在多实例的情况下，各实例共用一份缓存数据，缓存具有一致性。确定需要保持redis或memcache服务的高可用，整个程序架构上较为复杂。 ","date":"2021-03-11","objectID":"/redis-interview-01/:1:4","tags":["redis"],"title":"Redis Interview 01","uri":"/redis-interview-01/"},{"categories":["学习"],"content":"Redis为什么这么快 完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)。 数据结构简单，对数据操作也简单，Redis中的数据结构是专门进行设计的。 采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或多线程导致的切换而消耗CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗。 使用多路I/O复用模型，非阻塞IO。 使用底层模型不同，他们之间底层的实现方式以及与客户端之间通信的应用协议不一样，Redis直接自己构建了VM机制，因为一般的系统调用系统函数的话，会浪费一定时间去移动和请求。 ","date":"2021-03-11","objectID":"/redis-interview-01/:1:5","tags":["redis"],"title":"Redis Interview 01","uri":"/redis-interview-01/"},{"categories":["学习"],"content":"数据类型 ","date":"2021-03-11","objectID":"/redis-interview-01/:2:0","tags":["redis"],"title":"Redis Interview 01","uri":"/redis-interview-01/"},{"categories":["学习"],"content":"Redis有哪些数据类型 Redis主要有5种数据类型，包括String，List，Set，Zset，Hash，满足大部分的使用要求 数据类型 可以存储的值 操作 应用场景 String 字符串、整数或浮点型 对整个字符串或者字符串的其中一部分执行操作。对整数和浮点数执行自增或自减操作 做简单的键值对缓存 List 列表 从两端压入或弹出元素，对单个或多个元素进行修剪，只保留一个范围内的元素 存储一些列表型的数据结构，类似粉丝列表，文章的评论列表之类的数据 Set 无序集合 添加、获取、移除单个元素，检查一个元素是否在集合中。计算交集、并集、差集从集合里面随机获取元素 交集、并集、差集的操作，比如交集，可以把两个人的粉丝表整成一个交集 Hash 包含键值对的无序散列表 添加、获取、删除单个键值对，获取所有键值对，检查某个键是否存在 结构化的数据，比如一个对象 Zset 有序集合 添加、获取、删除元素。根据分值范围或者成员来获取元素。计算一个键的排名 去重但可以排序，如获取排名前几名的用户 ","date":"2021-03-11","objectID":"/redis-interview-01/:2:1","tags":["redis"],"title":"Redis Interview 01","uri":"/redis-interview-01/"},{"categories":["学习"],"content":"Redis的应用场景 ","date":"2021-03-11","objectID":"/redis-interview-01/:3:0","tags":["redis"],"title":"Redis Interview 01","uri":"/redis-interview-01/"},{"categories":["学习"],"content":"计数器 可以对string进行自增或自减运算，从而实现计数器功能。Redis这种内存型数据库的读写性能特别高，最适合存储频繁读写的计数量 ","date":"2021-03-11","objectID":"/redis-interview-01/:3:1","tags":["redis"],"title":"Redis Interview 01","uri":"/redis-interview-01/"},{"categories":["学习"],"content":"缓存 将热点数据放在内存中，设置内存的最大使用以及淘汰策略来保证缓存的命中率 ","date":"2021-03-11","objectID":"/redis-interview-01/:3:2","tags":["redis"],"title":"Redis Interview 01","uri":"/redis-interview-01/"},{"categories":["学习"],"content":"会话缓存 可以使用Redis来同一存储多态应用服务器的会话信息。当服务器不在存储用户的会话信息，也就不再具有状态，一个用户可以请求任意一个应用服务器，从而更容易实现高可用性以及可伸缩性 ","date":"2021-03-11","objectID":"/redis-interview-01/:3:3","tags":["redis"],"title":"Redis Interview 01","uri":"/redis-interview-01/"},{"categories":["学习"],"content":"全页缓存（FPC） 除基本的会话token之外，Redis还提供很简单的FPC平台。以Megento为例，Megento提供一个插件来使用Redis作为全页缓存后端。此外，对WordPress的用户来说，Pantheon有一个非常好的插件wp-redis，这个插件可以帮助以最快速度加载已经浏览过的页面。 ","date":"2021-03-11","objectID":"/redis-interview-01/:3:4","tags":["redis"],"title":"Redis Interview 01","uri":"/redis-interview-01/"},{"categories":["学习"],"content":"查找表 例如DNS记录就很适合用Redis进行存储。查找表和缓存类似，也是利用了Redis快速查找的特性。但是查找表的内容不能失效，而缓存内容可以失效，因为缓存不作为可靠的数据来源 ","date":"2021-03-11","objectID":"/redis-interview-01/:3:5","tags":["redis"],"title":"Redis Interview 01","uri":"/redis-interview-01/"},{"categories":["学习"],"content":"消息队列（发布/订阅功能） List是一个双向链表，可以通过lpush和rpop写入和读取消息。不过最好使用kafka，RabbitMQ等消息中间件。 ","date":"2021-03-11","objectID":"/redis-interview-01/:3:6","tags":["redis"],"title":"Redis Interview 01","uri":"/redis-interview-01/"},{"categories":["学习"],"content":"分布式锁实现 在分布式场景下，无法使用单机环境下的锁对多个节点上的进程进行同步。可以使用Redis自带的SETNX命令实现分布式锁，除此之外还可以使用官方提供的RedLock分布式锁实现 ","date":"2021-03-11","objectID":"/redis-interview-01/:3:7","tags":["redis"],"title":"Redis Interview 01","uri":"/redis-interview-01/"},{"categories":["学习"],"content":"其他 Set可以实现交集、并集等操作，从而实现共同好友等功能。Zset可以实现有序性操作，从而实现排行榜的功能。 ","date":"2021-03-11","objectID":"/redis-interview-01/:3:8","tags":["redis"],"title":"Redis Interview 01","uri":"/redis-interview-01/"},{"categories":["学习"],"content":"持久化 ","date":"2021-03-11","objectID":"/redis-interview-01/:4:0","tags":["redis"],"title":"Redis Interview 01","uri":"/redis-interview-01/"},{"categories":["学习"],"content":"什么是Redis持久化 持久化就是把内存的数据写到磁盘，防止服务宕机，内存数据丢失 ","date":"2021-03-11","objectID":"/redis-interview-01/:4:1","tags":["redis"],"title":"Redis Interview 01","uri":"/redis-interview-01/"},{"categories":["学习"],"content":"Redis的持久化机制是什么？各自的优缺点？ Redis提供两种持久化机制RDB（默认）和AOF机制 RDB：是Redis DataBase缩写快照 RDB是Redis默认的持久化方式。按照一定时间将内存的数据以快照的形式保存到硬盘中，对应产生的数据文件为dump.rdb。通过配置文件中的save参数来定义快照的周期 RDB机制\u0026ldquo;RDB机制\u0026rdquo; \"\rRDB机制\r 优点： 只有一个文件dump.rdb，方便持久化 容灾性好，一个文件可以保存在安全磁盘 性能最大化，fork子进程来完成写操作，让主程序继续执行命令，所以是IO最大化。使用单独子进程来进行持久化，主进程不会进行任何IO操作，保证了Redis的高性能 相对于数据集大时，比AOF的启动效率更高 缺点 数据安全性低。RDB是间隔一段时间进行持久化，如果持久化之间Redis发生故障，会发生数据丢失。所以这种方式更适合数据要求不严谨的时候 AOF（Append Only File）持久化：将Redis执行的每次写命令记录到单独的日志文件中，当重启Redis会重新将持久化的日志中文件恢复数据。 AOF机制\u0026ldquo;AOF机制\u0026rdquo; \"\rAOF机制\r 当两种方式同时打开时，数据恢复Redis会优先 优点： 数据安全，aof持久化可以配置appendfsync属性，有always，每进行一个命令操作就记录到aof文件中一次 通过append模式写文件，即使中途遇到宕机，也可以通过redis-check-aof工具解决数据一致性的问题 AOF机制的rewrite模式。AOF文件没被rewrite之前（文件过大会对命令进行合并或重写），可以删除其中的某些命令（比如误操作的flushall） 缺点 AOF文件比RDB文件大，且恢复速度慢 数据量大的时候，比rdb启动效率低 两者的区别 AOF文件比RDB更新频率高，优先使用AOF还原数据 AOF比RDB更安全也更大 RDB性能比AOF好 ","date":"2021-03-11","objectID":"/redis-interview-01/:4:2","tags":["redis"],"title":"Redis Interview 01","uri":"/redis-interview-01/"},{"categories":["学习"],"content":"如何选择合适的持久化方式 一般来说，如果想达到足以媲美PostgreSQL的数据安全性，应该同时使用两种持久化功能。在这种情况下，Redis重启的时候会优先载入AOF文件来恢复原始数据，因为通常情况下AOF保存的数据要比RDB文件保存的数据更完整 如果非常关心数据，但仍然可以承受数分钟内的数据丢失，可以只使用AOF持久化 许多用户只使用AOF持久化，但是不推荐这种方式，因为定时生成RDB快照非常便利于进行数据库备份，并且RDB恢复数据的速度要比AOF的速度快得多，除此之外，使用RDB还可以避免AOF程序的bug 如果只希望数据在服务器运行时存在时，可以不使用任何持久化方式。 ","date":"2021-03-11","objectID":"/redis-interview-01/:4:3","tags":["redis"],"title":"Redis Interview 01","uri":"/redis-interview-01/"},{"categories":["学习"],"content":"Redis持久化数据和缓存怎么做扩容 如果Redis被当做缓存使用，使用一致性的hash实现动态扩容缩容 如果Redis被当做一个持久化存储使用，必须使用固定的key-to-nodes映射关系，节点数量一旦确定不能变化。否则的话(即Redis节点需要动态变化的情况），必须使用可以在运行时进行数据再平衡的一套系统，而当前只有Redis集群可以做到这样。 ","date":"2021-03-11","objectID":"/redis-interview-01/:4:4","tags":["redis"],"title":"Redis Interview 01","uri":"/redis-interview-01/"},{"categories":["学习"],"content":"mysql面试05","date":"2021-03-11","objectID":"/mysql-interview-05/","tags":["mysql"],"title":"Mysql Interview 05","uri":"/mysql-interview-05/"},{"categories":["学习"],"content":"mysql面试04","date":"2021-03-10","objectID":"/mysql-interview-04/","tags":["mysql"],"title":"Mysql Interview 04","uri":"/mysql-interview-04/"},{"categories":["学习"],"content":"MySQL锁 ","date":"2021-03-10","objectID":"/mysql-interview-04/:1:0","tags":["mysql"],"title":"Mysql Interview 04","uri":"/mysql-interview-04/"},{"categories":["学习"],"content":"MVCC总结 MVCC（多版本并发控制）指的就是在使用READ COMMITTED，REPEATABLE READ这两种隔离级别的事务在执行普通的select操作时访问记录的版本链的过程。可以使不同事务的读-写，写-读操作并发执行，从而提升系统性能。READ COMMITTED、REPEATABLE READ这两个隔离级别一个很大的不同就是：生成ReadView的时机不同，READ COMMITTED是每一次进行普通SELECT操作前都会生成一次ReadView。而REPEATABLE READ只会在第一次进行普通SELECT的时候生成ReadView。之后的查询重复使用这个ReadView。 ","date":"2021-03-10","objectID":"/mysql-interview-04/:1:1","tags":["mysql"],"title":"Mysql Interview 04","uri":"/mysql-interview-04/"},{"categories":["学习"],"content":"MySQL锁的介绍 按照锁的粒度来说，MySQL主要包含三种锁：全局锁，表级锁，行级锁 全局锁，锁的是整个database，由MySQL的Sql layer层实现 表级锁，锁的是整张表，由MySQL的Sql layer层实现 行级锁，锁的是某行数据，也可能锁的是行之间的间隙，由存储引擎实现 按照锁的功能来分，可以分为共享锁和排他锁 共享锁：也称S锁，加了S锁，允许其他事务再加S锁，但是不允许其他事务加X锁。加锁方式select … lock in share mode 排他锁：也称X锁，加了X锁，不允许其他事务再加X锁或S锁。加锁方式：select … for update(delete|insert) ","date":"2021-03-10","objectID":"/mysql-interview-04/:1:2","tags":["mysql"],"title":"Mysql Interview 04","uri":"/mysql-interview-04/"},{"categories":["学习"],"content":"不同粒度锁的比较 表级锁：开销小，加锁快。不会出现死锁，锁定粒度大，发生锁冲突概率最高，并发度最低。 这些存储引擎通过总是一次性同时获取所有需要锁以及总是按相同顺序获取表锁避免死锁 表级锁主要适合以查询为主，并发数量少，只有少量按索引条件更新数据的应用，如WEB应用 行级锁：开销大，加锁慢。会出现死锁，锁定粒度最小，发生锁冲突概率最低，并发度也最高 最大程度支持并发，同时也带来了最大的锁开销 在InnoDB中，除单个SQL组成的事务外，锁是逐步获取的，这就决定了在InnoDB发生死锁是可能的 行级锁只是在存储引擎层实现，而MySQL服务层没有实现。行级锁更适合于有大量按索引条件并发更新少量不同数据，同时又有并发查询的应用，如一些在线事务处理系统 ","date":"2021-03-10","objectID":"/mysql-interview-04/:1:3","tags":["mysql"],"title":"Mysql Interview 04","uri":"/mysql-interview-04/"},{"categories":["学习"],"content":"InnoDB锁模式 InnoDB实现了以下两种锁 共享锁（S）：允许一个事务去读行，阻止其他事务获得相同数据集的排他锁 排他锁（X）：允许获得排他锁的事务更新数据，阻止其他事务获得相同数据集的共享锁和排他锁 为了允许行锁和表锁共存，实现多粒度锁机制，InnoDB还有两种内部使用的意向锁，这两种锁都是表锁 意向共享锁（IS）：事务打算个数据行加行共享锁，事务在给一个数据行加共享锁前必须先取得该表的IS锁 意向排他锁（IX）：事务打算给数据行加行排他锁，事务在给一个数据行加排他锁前必须先取得该表的IX锁 锁与锁之间如果相容，MySQL会给予锁，不相容则会阻塞。 ","date":"2021-03-10","objectID":"/mysql-interview-04/:1:4","tags":["mysql"],"title":"Mysql Interview 04","uri":"/mysql-interview-04/"},{"categories":["学习"],"content":"InnoDB加锁方式 意向锁是InnoDB自动加的，不需用户干预 对于UPDATE、DELETE和INSERT语句，InnoDB会自动给涉及数据集加共享锁或排他锁 对于普通SELECT语句，InnoDB不会加任何锁；事务可以通过以下语句显式给记录集加共享锁或排他锁： 共享锁（S）：SELECT * FROM table_name WHERE … LOCK IN SHARE MODE。其他session仍然可以查询记录，并也可以对该记录加SHARE MODE的共享锁。但如果当前事务需要对该记录进行更新操作，则很有可能造成死锁。 排他锁（X）：SELECT * FROM table_name WHERE … FOR UPDATE。其他session可以查询该记录。但是不能对该记录加共享锁或排他锁，而是等待获得锁。 隐式锁定 InnoDB在事务执行过程中，使用两阶段锁协议： 随时都可以执行锁定，InnoDB会根据隔离级别在需要的时候自行加锁； 锁只有在执行commit或rollback的时候才会释放，并且所有的锁都是在同一时刻被释放。 显示锁定 select … lock in share mode //共享锁 in share mode子句在作用就是将查找到的数据加上一个share锁，这个就是表示其他的事务只能进行简单的select操作，并不能够进行DML操作。 select … lock in share mode使用场景：为了确保自己查到的数据没有被其他事务正在修改，也就是确保查到的数据是最新的数据，并且不允许其他事务来修改数据。但是自己不一定能修改数据，因为有可能其他事务也对这些数据使用了in share mode的方式上了S锁 select … for update //排他锁 在执行这个select查询语句的时候，会将相应的索引访问条目进行上排他锁（X锁），也就是说这个语句对应的锁就相当于update带来的效果 select … for update 的使用场景：为了让自己查到的数据确保是最新的数据，并且查到后的数据只允许自己来修改的时候，需要用到for update子句 性能影响 select … for update语句，相当于一个UPDATE语句。在业务繁忙的情况下，如果事务没有及时的commit或rollback可能会造成其他事务长时间的等待，从而影响数据库的并发使用效率。 select … lock in share mode语句是给一个查找语句上一个共享锁（S）的功能，它允许其他事务也对该事务上S锁，但是不能够允许对数据进行修改。如果不及时的commit或rollback也可能造成大量的事务等待。 InnoDB行锁实现方式 InnoDB行锁是通过给索引上的索引项加锁来实现的，这一点MySQL和Oracle完全不同，后者是通过在数据块中对相应数据行加锁来实现的。InnoDB这种行锁实现特点意味着：只用通过索引条件检索数据，InnoDB才使用行锁，否则InnoDB将使用表锁。 不论是主键索引，唯一索引还是普通索引，InnoDB都会使用行锁来对数据加锁 只有在执行计划中真正使用了索引，才能使用行锁：即使在条件中使用了索引字段，但是否使用索引来检索数据是有MySQL通过判断不同执行计划的代价来决定的，如果MySQL认为全表扫描效率更高，比如对一些很小的表，MySQL就不会使用索引，这种情况下InnoDB将使用表锁，而不是使用行锁。因此在分析锁冲突的时候可以检查SQL的执行计划（可以通过explain检查SQL的执行计划），已确认是否真正使用了索引。 ","date":"2021-03-10","objectID":"/mysql-interview-04/:1:5","tags":["mysql"],"title":"Mysql Interview 04","uri":"/mysql-interview-04/"},{"categories":["学习"],"content":"乐观锁和悲观锁 悲观锁是指在数据处理过程中是数据处于锁定状态。在MySQL中使用悲观锁，必须关闭MySQL自动提交，set autocommit = 0，MySQL默认使用自动提交模式，即使你执行一个更新操作，MySQL会自动将结果提交。 select … for update 是MySQL提供实现悲观锁的方式。执行后该数据将被锁定，直到获得该锁的事务提交或回滚后，锁才能释放。其他要执行该数据的事务才能执行。 乐观锁相对于悲观锁来说，一般来说是不会造成冲突，所以只有在数据提交更新的时候，才会正式对数据的冲突与否进行检测。如果发现冲突了，则让返回错误信息，让用户决定如何去做。 利用数据版本号（version）机制是乐观锁最常用的一种实现方式，一般通过为数据库添加一个version字段，当读取数据的时候，将version字段的数据一同读出，数据每更新一次，对此version值+1。当提交更新的时候，判断数据库对应的当前的版本信息是否与第一次去出来的版本信息相等，相等则予以更新，不相等认为是过期的数据，返回更新失败。 ","date":"2021-03-10","objectID":"/mysql-interview-04/:1:6","tags":["mysql"],"title":"Mysql Interview 04","uri":"/mysql-interview-04/"},{"categories":["学习"],"content":"mysql面试03","date":"2021-03-09","objectID":"/mysql-interview-03/","tags":["mysql"],"title":"Mysql Interview 03","uri":"/mysql-interview-03/"},{"categories":["学习"],"content":"MySQL索引 ","date":"2021-03-09","objectID":"/mysql-interview-03/:1:0","tags":["mysql"],"title":"Mysql Interview 03","uri":"/mysql-interview-03/"},{"categories":["学习"],"content":"MySQL目前主要有以下几种索引类型 普通索引 最基本的索引，没有任何限制，有以下几种创建方式： 直接创建索引 CREATE INDEX index_name ON table(column(length)) 修改表结构的方式添加索引 ALTER TABLE table_name ADD INDEX index_name ON (column(length)) 创建表的时候同时创建索引 CREATE TABLE `table` ( `id` int(11) NOT NULL AUTO_INCREMENT, `title` char(255) CHARACTER NOT NULL, `content` TEXT CHARACTER NULL, `time` int(10) NULL DEFAULT NULL, PRIMARY KEY (`id`), INDEX index (title(length)) ) 删除索引 DROP INDEX index_name ON table 唯一索引 与前面的普通索引类似。不同的是，索引列的值必须唯一，但允许有空值。如果是组合索引，则列值的组合必须唯一，有以下几种创建方式 创建唯一索引 CREATE UNIQUE INDEX index_name ON table(column(length)) 修改表结构 ALTER TABLE table_name ADD UNIQUE index_name ON table(column(length)) 创建表的时候直接指定 CREATE TABLE `table` ( `id` int(11) NOT NULL AUTO_INCREMENT, `title` char(255) CHATACTER NOT NULL, `content` text CHARACTER NULL, `time` int(10) NULL DEFAULT NULL, UNIQUE indexName (title(length)) ) 主键索引 是一种特殊的唯一索引，一个表只能有一个主键，不允许有空值，一般建表的时候同时创建主键索引 CREATE TABLE `table` ( `id` int(10) NOT NULL AUTO_INCREMENT, `title` char(255) NOT NULL, PRIMARY KEY (`id`) ) 组合索引 多个字段上创建索引，只有在查询条件中使用了创建索引时的第一个字段，索引才会被使用，使用组合索引遵循最左前缀集合 ALTER TABLE `table` ADD INDEX city_name_age(city, name, age) 全文索引 主要用来查找文本中的关键字，而不是直接与索引中的值进行比较。fulltext（全文索引）跟其他索引大不相同，它更像是一个搜索引擎，而不是简单的where语句的参数匹配。fulltext索引配合match against操作使用，而不是一般的where+like。它可以在create table，alter table，create index使用。不过目前只用char，varchar，text列上可以创建全文索引。值得一提的是，在数据量比较大的时候，先将数据放入一个没有全文索引的表中，然后再用CREATE index创建fulltext（全文索引），要比先为一张表建立fulltext全文索引然后再将数据写入快得多。 创建表的时候添加全文索引 CREATE TABLE `table` ( `id` int(11) NOT NULL AUTO_INCREMENT, `title` char(255) CHARACTER NOT NULL, `content` text CHARACTER NULL, `time` int(10) NULL DEFAULT NULL, PRIMARY KEY (`id`), FULLTEXT (content) ) 修改表结构添加全文索引 ALTER TABLE table ADD FULLTEXT index_content(content) 直接创建索引 CREATE FULLTEXT INDEX index_content ON table(content) ","date":"2021-03-09","objectID":"/mysql-interview-03/:1:1","tags":["mysql"],"title":"Mysql Interview 03","uri":"/mysql-interview-03/"},{"categories":["学习"],"content":"缺点 虽然索引大大提高了查询速度，同时会降低表的更新速度，如对表进行delete，update，insert。因为更新表时，不仅要保存数据，还要保存一下索引文件。 建立索引会建立占用磁盘空间的索引文件。一般这个问题不太严重，但如果在一个大表上创建多种组合索引，索引文件会增长很快。 索引只是提高效率的一个因素，如果有大数据量的表，就需要花时间研究建立优秀索引，或优化查询语句。 ","date":"2021-03-09","objectID":"/mysql-interview-03/:1:2","tags":["mysql"],"title":"Mysql Interview 03","uri":"/mysql-interview-03/"},{"categories":["学习"],"content":"注意事项 索引不会包含有null值的列。只要列中包含null值都将不会被包含在索引中，复合索引中只要有一列含有null值，那么这一列对于索引就是无效的。所以在设计数据库的时候尽量不要让字段的默认值为null。 使用短索引 对串列进行索引，如果可能就指定一个前缀长度。例如：一个char(255)的列，如果在前10个或20个字符内，多数值是唯一的，那么就不需要对整列进行索引。短索引不仅可以提高查询速度还可以节省磁盘空间和I/O操作。 索引列排序 查询只用一个索引，因此如果where已经使用了索引，那么order by就不会在使用索引。因此数据库默认排序符合可以符合要求的情况下不要使用排序操作。尽量不要包含多个列的排序，如果需要最好给这些列创建复合索引。 like语句操作 一般情况下不推荐使用like，如果非使用不可，如何使用也是一个问题，like“%aaa%”不会使用索引而like“aaa%”可以使用索引。 不要在列上进行运算 这将导致索引失效而进行全表扫描，例如 SELECT * FROM table_name WHERE YEAR(column_name) \u003c 2017 不使用not in和\u003c\u003e操作 ","date":"2021-03-09","objectID":"/mysql-interview-03/:1:3","tags":["mysql"],"title":"Mysql Interview 03","uri":"/mysql-interview-03/"},{"categories":["学习"],"content":"mysql索引类型normal，unique，fulltext的区别是什么 normal：表示普通索引 unique：表示唯一的，不允许出现重复的索引，如果该字段信息不会出现重复。例如使用身份证号作为索引，可以设置为unique fulltext：表示全文搜索的索引，fulltext用于搜索很长一片文章的时候，效果最好。如果就一两行字，使用普通的index也可以。 总结，索引的类别由建立索引的字段内容特性来决定，通常normal最常见。 ","date":"2021-03-09","objectID":"/mysql-interview-03/:1:4","tags":["mysql"],"title":"Mysql Interview 03","uri":"/mysql-interview-03/"},{"categories":["学习"],"content":"实际操作中，应选取表中哪些字段作为索引 建立索引上有7大原则： 选择唯一性索引 为经常需要排序、分组和联合操作的字段建立索引 为常作为查询条件的字段建立索引 限制索引数目 尽量使用数据量小的索引 尽量使用前缀来索引 删除不再使用或很少使用的索引 ","date":"2021-03-09","objectID":"/mysql-interview-03/:1:5","tags":["mysql"],"title":"Mysql Interview 03","uri":"/mysql-interview-03/"},{"categories":["学习"],"content":"聚集索引和非聚集索引区别 聚集索引一个表只有一个，非聚集索引一个表可以有多个 聚集索引存储记录在物理上是连续存在的，而非聚集索引在逻辑上是连续的，物理存储并不连续 ","date":"2021-03-09","objectID":"/mysql-interview-03/:1:6","tags":["mysql"],"title":"Mysql Interview 03","uri":"/mysql-interview-03/"},{"categories":["学习"],"content":"mysql面试02","date":"2021-03-09","objectID":"/mysql-interview-02/","tags":["mysql"],"title":"Mysql Interview 02","uri":"/mysql-interview-02/"},{"categories":["学习"],"content":"事务的四大特性（ACID）原子性，一致性，隔离性，持久性？ ","date":"2021-03-09","objectID":"/mysql-interview-02/:1:0","tags":["mysql"],"title":"Mysql Interview 02","uri":"/mysql-interview-02/"},{"categories":["学习"],"content":"原子性 根据定义，原子性是指一个事务是一个不可分割的工作单位，其中操作要么都做，要么都不做。不存在中间状态。 ","date":"2021-03-09","objectID":"/mysql-interview-02/:1:1","tags":["mysql"],"title":"Mysql Interview 02","uri":"/mysql-interview-02/"},{"categories":["学习"],"content":"一致性 根据定义一致性是指事务执行前后，数据处于一种合法的状态，这种状态是语义上的而不是语法上的。 ","date":"2021-03-09","objectID":"/mysql-interview-02/:1:2","tags":["mysql"],"title":"Mysql Interview 02","uri":"/mysql-interview-02/"},{"categories":["学习"],"content":"隔离性 根据定义，隔离性是指多个事务并发执行时，事务内部操作和其他事务是隔离的，并发执行的各个事务之间不能互相干扰。 ","date":"2021-03-09","objectID":"/mysql-interview-02/:1:3","tags":["mysql"],"title":"Mysql Interview 02","uri":"/mysql-interview-02/"},{"categories":["学习"],"content":"持久性 根据定义，持久性是指事务一旦提交，它对数据库的改变就应该是永久性的。接下来其他操作或故障不应该对其有任何影响。 ","date":"2021-03-09","objectID":"/mysql-interview-02/:1:4","tags":["mysql"],"title":"Mysql Interview 02","uri":"/mysql-interview-02/"},{"categories":["学习"],"content":"数据库隔离级别，每个级别会引发什么问题，mysql默认是什么级别的 ","date":"2021-03-09","objectID":"/mysql-interview-02/:2:0","tags":["mysql"],"title":"Mysql Interview 02","uri":"/mysql-interview-02/"},{"categories":["学习"],"content":"脏读 脏读是指在一个事务中读到另一个未提交事务的数据。 当一个事务正在多次修改某个数据而这个事务中多次修改都尚未提交，此时另一个并发事务来访问该数据，就会造成两个事务得到的数据不一致。 举个例子：A在一个转账事务中，转了100给B，此时，B读到了这个转账数据，然后做了一些操作（发货给A或其他操作），可这个时候A的事务并没有提交，如果A回滚了事务，就会发生数据问题。这就是脏读。 ","date":"2021-03-09","objectID":"/mysql-interview-02/:2:1","tags":["mysql"],"title":"Mysql Interview 02","uri":"/mysql-interview-02/"},{"categories":["学习"],"content":"不可重复读 不可重复读是指对于数据库中的某个数据，一个事务范围内多次查询却返回了不同的数据。这是由于在查询间隔，被另一个事务修改并提交了。 例如：事务T1读取某一数据，而事务T2马上修改数据并提交给数据库，事务T1再次读取就得到了不同的结果，发生了不可重复读。 不可重复读和脏读的区别是，脏读是某一事务读取了另一个事务未提交的脏数据，不可重复读则是读取了前一事务提交的数据 ","date":"2021-03-09","objectID":"/mysql-interview-02/:2:2","tags":["mysql"],"title":"Mysql Interview 02","uri":"/mysql-interview-02/"},{"categories":["学习"],"content":"幻读 幻读是指事务非独立执行时发生的一种现象。 例如：事务T1对一个表中的所有的行的某一数据做了从1修改为2的操作，这时事务T2又对这个表中插入了一行数据项，而这个数据项还是1并且提交给了数据库。而事务T1如果再次查看刚刚修改的数据，会发现还有一行未修改，其实这行是T2添加的，就好像产生了幻觉。这就是幻读。 幻读和不可重复读的区别，幻读和不可重复读都是读取另一个以提交的事务（这点就和脏读不同），不同的是，不可重复读查询的都是同一个数据项，而幻读是针对一批数据整体（比如数据个数） ","date":"2021-03-09","objectID":"/mysql-interview-02/:2:3","tags":["mysql"],"title":"Mysql Interview 02","uri":"/mysql-interview-02/"},{"categories":["学习"],"content":"MySQL提供的四种隔离模式 Serializable（串行化）：可以避免脏读，不可重复读和幻读的发生。 Repeatable read（可重复读）：可以避免脏读，不可重复读的发生。 Read committed（读已提交）：可避免脏读的发生。 Read uncommitted（读未提交）：最低级别，都无法避免。 以上四种模式最高是Serializable级别，最低是Read uncommitted级别。级别越高效率越低。像是Serializable这样的级别就是以锁表的方式使得其他事务只能在锁外等待。MySQL数据库默认的级别为Read committed ","date":"2021-03-09","objectID":"/mysql-interview-02/:2:4","tags":["mysql"],"title":"Mysql Interview 02","uri":"/mysql-interview-02/"},{"categories":["学习"],"content":"MySQL常见的三种存储引擎（InnoDB、MyISAM、MEMORY）的区别 ","date":"2021-03-09","objectID":"/mysql-interview-02/:3:0","tags":["mysql"],"title":"Mysql Interview 02","uri":"/mysql-interview-02/"},{"categories":["学习"],"content":"InnoDB 支持事务，支持外键，支持崩溃修复能力和并发控制。如果需要对事务的完整性要求比较高（比如银行），要求实现并发控制（比如售票），那选择InnoDB有很大优势。如果需要频繁的更新，删除操作的数据库，也可以选择InnoDB，因为支持事务的提交（commit）和回滚（rollback） ","date":"2021-03-09","objectID":"/mysql-interview-02/:3:1","tags":["mysql"],"title":"Mysql Interview 02","uri":"/mysql-interview-02/"},{"categories":["学习"],"content":"MyISAM 插入数据快，空间和内存使用比较低。如果表主要是用于插入新数据和读出记录，那么选择MyISAM能实现处理高效率。如果应用的完整性和并发性要求比较低，也可以使用。 ","date":"2021-03-09","objectID":"/mysql-interview-02/:3:2","tags":["mysql"],"title":"Mysql Interview 02","uri":"/mysql-interview-02/"},{"categories":["学习"],"content":"MEMORY 所有数据都在内存中，数据的处理快，但是安全性不高，如果需要很快的读写速度，对数据的安全性要求较低，可以选择MEMORY。其对表的大小有所要求，不能建立太大的表。所以这类数据库只使用在相对较小的数据库表。 ","date":"2021-03-09","objectID":"/mysql-interview-02/:3:3","tags":["mysql"],"title":"Mysql Interview 02","uri":"/mysql-interview-02/"},{"categories":["学习"],"content":"MySQL的MyISAM和InnoDB两种存储引擎在事务、锁级别，各自的使用场景 ","date":"2021-03-09","objectID":"/mysql-interview-02/:4:0","tags":["mysql"],"title":"Mysql Interview 02","uri":"/mysql-interview-02/"},{"categories":["学习"],"content":"MyISAM特点 不支持行锁（MyISAM只有表锁），读取时对需要读到的所有表进行加锁，写入时则对表加排它锁 不支持事务 不支持外键 不支持崩溃后安全修复 在表有读取查询时，支持往表中插入新数据 支持BLOG和TEXT的前500个字符索引，支持全文索引 支持延时更新索引，极大的提升写入性能 对于不会进行修改的表，支持压缩表，极大的减少对磁盘空间的占用 ","date":"2021-03-09","objectID":"/mysql-interview-02/:4:1","tags":["mysql"],"title":"Mysql Interview 02","uri":"/mysql-interview-02/"},{"categories":["学习"],"content":"InnoDB特点 支持行锁，采用MVCC来支持高并发，有可能死锁 支持事务 支持外键 支持崩溃后的安全修复 不支持全文索引 ","date":"2021-03-09","objectID":"/mysql-interview-02/:4:2","tags":["mysql"],"title":"Mysql Interview 02","uri":"/mysql-interview-02/"},{"categories":["学习"],"content":"各自的使用场景 MyISAM管理非事务表。它提供高速存储和检索，以及全文搜索能力。如果应用中需要执行大量的SELECT查询时，那么MyISAM是更好的选择。 InnoDB用于事务处理应用程序，具有众多特性，包括ACID事务支持。如果应用中需要大量的INSERT或UPDATE操作，则应该使用InnoDB，这样可以提高多用户并发操作的性能。 但是实际场景中，针对具体问题具体分析，一般遵循以下几个问题？ 数据库是否有外键 是否需要事务支持 是否需要全文索引 数据库经常使用什么查询模式？在写多读少的应用中还是InnoDB插入性能更稳定，在并发情况下也基本，如果是对读取速度要求比较快的应用还是选MyISAM 数据库的数据大小？大尺寸倾向与InnoDB，因为有事务日志，故障修复 ","date":"2021-03-09","objectID":"/mysql-interview-02/:4:3","tags":["mysql"],"title":"Mysql Interview 02","uri":"/mysql-interview-02/"},{"categories":["学习"],"content":"SQL查询语句（where，join，limit，group by，having）执行先后顺序 一个查询语句同时出现以上关键词时执行顺序是： 执行where xxx对全表数据做筛选，返回第一个结果集 针对第一个结果集使用group by分组，返回第二个结果集 针对第二个结果集中的每一组数据执行select xxx，有几组就执行几次，返回第三个结果集 针对第三个结果集执行having xxx进行筛选，返回第四个结果集 针对第四个结果集排序 总结一个顺序：我（W）哥（G）是（SH）偶（O）像（W-\u003eG-\u003eS-\u003eH-\u003eO） ","date":"2021-03-09","objectID":"/mysql-interview-02/:5:0","tags":["mysql"],"title":"Mysql Interview 02","uri":"/mysql-interview-02/"},{"categories":["学习"],"content":"什么是临时表，临时表什么时候删除 ","date":"2021-03-09","objectID":"/mysql-interview-02/:6:0","tags":["mysql"],"title":"Mysql Interview 02","uri":"/mysql-interview-02/"},{"categories":["学习"],"content":"什么是临时表 MySQL用于存储一些中间结果集的表，临时表只在当前连接可见，当关闭连接时，MySQL会自动删除表并释放所有空间。 ","date":"2021-03-09","objectID":"/mysql-interview-02/:6:1","tags":["mysql"],"title":"Mysql Interview 02","uri":"/mysql-interview-02/"},{"categories":["学习"],"content":"为什么会产生临时表 一般是由于复杂的SQL导致临时表被大量创建 ","date":"2021-03-09","objectID":"/mysql-interview-02/:6:2","tags":["mysql"],"title":"Mysql Interview 02","uri":"/mysql-interview-02/"},{"categories":["学习"],"content":"临时表的分类 临时表分为两种，一种是内存临时表，一种是磁盘临时表。内存临时表采用的是MEMORY存储引擎，磁盘临时表采用的是MyISAM存储引擎（磁盘临时表也可以使用InnoDB存储引擎，通过参数来控制使用那种存储引擎，从MySQL5.7.6版本后默认为InnoDB存储引擎，之前版本一直默认的是MyISAM存储引擎） ","date":"2021-03-09","objectID":"/mysql-interview-02/:6:3","tags":["mysql"],"title":"Mysql Interview 02","uri":"/mysql-interview-02/"},{"categories":["学习"],"content":"下面操作会使用到临时表 union查询 对于视图操作，比如使用一些TEMPTABLE算法，union或aggregation 子查询 join包括not in，exist等 查询产生的派生表 复杂的group by或order by insert，select同一个表，mysql会产生一个临时表缓存select行 多个表更新 GROUP_CONCAT()或COUNT(DISTINCT) ","date":"2021-03-09","objectID":"/mysql-interview-02/:6:4","tags":["mysql"],"title":"Mysql Interview 02","uri":"/mysql-interview-02/"},{"categories":["学习"],"content":"MySQL以下操作会阻止内存临时表的建立，直接使用磁盘临时表 表含有BLOG或TEXT列 使用union或union all时，select子句有大于512字节的列 Show columns或desc表时，有LOB或TEXT GROUP BY或DISTINCY子句中包含列大于512字节的列 ","date":"2021-03-09","objectID":"/mysql-interview-02/:6:5","tags":["mysql"],"title":"Mysql Interview 02","uri":"/mysql-interview-02/"},{"categories":["学习"],"content":"MySQL B+Tree索引和Hash索引的区别 ","date":"2021-03-09","objectID":"/mysql-interview-02/:7:0","tags":["mysql"],"title":"Mysql Interview 02","uri":"/mysql-interview-02/"},{"categories":["学习"],"content":"区别 由于Hash索引结构的特殊性，其检索效率特别高，索引的检索可以一次定位，不想B-Tree索引需要从根节点到枝节点，最后才能访问到叶节点这样多次访问，所以Hash索引的查询效率是要远高于B-Tree索引 ","date":"2021-03-09","objectID":"/mysql-interview-02/:7:1","tags":["mysql"],"title":"Mysql Interview 02","uri":"/mysql-interview-02/"},{"categories":["学习"],"content":"为何采用B-Tree而不采用Hash 任何事物都有两面性，Hash索引也一样，虽然Hash索引效率高，但是Hash索引本身由于其特殊性也带来了很多限制和弊端，主要有以下这些 Hash索引仅仅能满足于“=”，“in”和“\u003c=\u003e”查询，不能使用范围查询。 由于Hash索引比较的是Hash运算之后的Hash值，所以只能使用等值过滤，不能用于基于范围的过滤，因为经过相应的Hash算法处理后的Hash值的大小关系，并不能保证和Hash运算前完全一样 Hash索引无法用来避免数据的排序操作。 由于Hash索引中存放是经过Hash计算之后的Hash值，而且Hash值的大小关系还不一定和Hash运算之前的键值完全一样，所以数据库无法通过索引的数据来避免任何排序运算 Hash索引不能利用部分索引键查询 对于组合索引，Hash索引在计算Hash值的时候是组合索引键合并后再一起计算Hash值，而不是单独计算Hash值，所以通过组合索引的前面一个或几个索引键进行查询的时候，Hash索引也无法被利用。 Hash索引在任何时候都不能避免表扫描 Hash索引是将索引键通过Hash运算后，将Hash运算结果和所对应的指针信息存放在一个Hash表中由于不同的索引键中存在相同的Hash值，所以即使满足某个Hash键值数据的记录条数也无法从Hash索引中直接完成查询，还是要通过访问表中的实际数据进行相应的比较，并得到相应的结果。 Hash索引遇到大量Hash值相等的情况后性能就不一定比B-Tree高 对于选择性较低的索引键，如果创建Hash索引，那么将会存在大量记录指针信息存于同一个Hash值相关联。这样会浪费多次表数据访问，造成整体性能低下。 ","date":"2021-03-09","objectID":"/mysql-interview-02/:7:2","tags":["mysql"],"title":"Mysql Interview 02","uri":"/mysql-interview-02/"},{"categories":["学习"],"content":"mysql面试01","date":"2021-03-08","objectID":"/mysql-interview-01/","tags":["mysql"],"title":"Mysql Interview 01","uri":"/mysql-interview-01/"},{"categories":["学习"],"content":"drop、delete和truncate分别在什么场景下使用？对比一下区别 ","date":"2021-03-08","objectID":"/mysql-interview-01/:1:0","tags":["mysql"],"title":"Mysql Interview 01","uri":"/mysql-interview-01/"},{"categories":["学习"],"content":"drop table 属于DDL 不可回滚 不可带where 表内容结构删除 删除速度快 ","date":"2021-03-08","objectID":"/mysql-interview-01/:1:1","tags":["mysql"],"title":"Mysql Interview 01","uri":"/mysql-interview-01/"},{"categories":["学习"],"content":"truncate table 属于DDL 不可回滚 不可带where 表内容删除 速度快 ","date":"2021-03-08","objectID":"/mysql-interview-01/:1:2","tags":["mysql"],"title":"Mysql Interview 01","uri":"/mysql-interview-01/"},{"categories":["学习"],"content":"delete from 属于DML 可回滚 可带where 表结构在，表内容看具体where 删除速度慢 ","date":"2021-03-08","objectID":"/mysql-interview-01/:1:3","tags":["mysql"],"title":"Mysql Interview 01","uri":"/mysql-interview-01/"},{"categories":["学习"],"content":"使用场景 不再需要一张表的时候，使用drop 想删除部分数据行时候，使用delete，并且带上where子句 想保留表结构而删除所有数据时，使用truncate ","date":"2021-03-08","objectID":"/mysql-interview-01/:1:4","tags":["mysql"],"title":"Mysql Interview 01","uri":"/mysql-interview-01/"},{"categories":["学习"],"content":"mysql优化01","date":"2021-03-08","objectID":"/mysql-optimize-01/","tags":["mysql"],"title":"Mysql Optimize 01","uri":"/mysql-optimize-01/"},{"categories":["学习"],"content":"优化的方面 表设计 范式 存储引擎 字段类型 功能 索引 缓存 分区 sql语句 合理的sql 经验 架构 主从复制 负载均衡 读写分离 ","date":"2021-03-08","objectID":"/mysql-optimize-01/:1:0","tags":["mysql"],"title":"Mysql Optimize 01","uri":"/mysql-optimize-01/"},{"categories":["生活"],"content":"简历","date":"2021-03-07","objectID":"/resume/","tags":["简历"],"title":"Resume","uri":"/resume/"},{"categories":["生活"],"content":"个人信息 姓名：陈进煌 性别：男 年龄：24 手机号：18759882615 邮箱：2219316464@qq.com 专业：计算机科学与技术 应聘岗位：Golang开发工程师 ","date":"2021-03-07","objectID":"/resume/:1:0","tags":["简历"],"title":"Resume","uri":"/resume/"},{"categories":["生活"],"content":"工作及教育经历 厦门美城行动科技有限公司 2019-08~至今 软件研发部-后端开发 厦门青叶软件股份有限公司 2019-03~2019-07 软件研发部-后端开发 厦门通元微智能科技有限公司 2018-03~2018~11 软件研发部-软件测试 三明学院 2014-09~2018-07 计算机科学与技术 ","date":"2021-03-07","objectID":"/resume/:2:0","tags":["简历"],"title":"Resume","uri":"/resume/"},{"categories":["生活"],"content":"专业技能 熟悉Golang，了解Java等编程语言 熟悉MySQL数据库 了解缓存系统Redis 了解网络编程，TCP/IP协议 熟悉Beego框架 了解React和Ant Design 了解Git版本控制 ","date":"2021-03-07","objectID":"/resume/:3:0","tags":["简历"],"title":"Resume","uri":"/resume/"},{"categories":["生活"],"content":"项目经历 厦门美城行动管理系统 后端开发 2019-08~至今 项目介绍：这个项目是公司的后台管理系统。该系统主要是对公司对应的小程序和app提供数据的统计展示和管理等。系统后端是采用Beego框架，数据库使用MySQL，部分功能使用到Redis进行缓存。系统前端采用React框架，大部分使用Ant Design的UI组件。 我的职责： 根据实际业务需求，与产品经理确定具体功能及展现方式。 依据具体功能进行数据表的设计。 实现具体功能编写管理系统前端展示代码，与产品进行确认。 根据前端界面确定后台的接口，进行后台代码数据操作代码的编写。 若小程序，app有该功能相关的，为其提供相应的接口。 提交Git，交付测试进行测试。 根据测试提交的bug对代码进行调试修改。 主要实现功能： 考试模块 这个功能实现功能如下： 1、题库管理，在题库中对试卷题目，答案等进行数据操作。 2、试卷管理，编辑试卷名称等具体信息，从题库中筛选题目，从用户列表中筛选用户参与该试卷考试。 3、分数排行榜，对试卷分数进行统计，排行及数据展示。 功能难点： 1、用户小程序上提交试卷后展示考试成绩 2、试卷修改时，用户提交过的试卷内容不变 难点解决： 1、使用redis对答案数据进行缓存，用户提交后根据试卷id获取对应缓存数据，进行对比，统计分数并返回。 2、将用户提交的试卷数据序列化进行保存，展示时再反序列化。 大件垃圾订单模块 这个功能实现功能如下： 1、大件垃圾基本设置，根据不同的类型，对不同情况下价格的定制。 2、大件订单管理，管理人员分配订单给回收人员，回收人员通过小程序了解订单详情并完成。 3、回收人员管理，对回收人员添加身份标识和。 船人网管理系统 后端开发 2019-03~2019-07 项目介绍：这个项目是一个关于船舶的后台管理系统。该系统主要是船舶及其周边产品的租赁及售卖网站的后台管理。系统后端是用的SpringMVC+SpringBoot+Mybatis，数据库使用MySQL，前端采用Vue框架。 我的职责 根据测试提交的对代码进行调试修改 根据产品需求实现Vue页面展示 实现接口功能 通元微软件测试 软件测试 2018-03~2018-11 项目介绍：指静脉或指纹+云平台+移动端APP 我的职责 云平台、PC端程序及移动端的功能测试及接口测试 产品功能测试，根据需求、测试方案进行测试用例的设计编写 根据测试结果评估软件质量，提供测试报告 ","date":"2021-03-07","objectID":"/resume/:4:0","tags":["简历"],"title":"Resume","uri":"/resume/"},{"categories":["实例"],"content":"Go Instance 12-排序","date":"2021-03-03","objectID":"/go-instance-12/","tags":["golang"],"title":"Go Instance 12","uri":"/go-instance-12/"},{"categories":["实例"],"content":"sort自带排序 Go 的 sort 包实现了内置和用户自定义数据类型的排序功能 package main import ( \"fmt\" \"sort\" ) func main() { //排序方法是正对内置数据类型的；这里是一个字符串的例子。 // 注意排序是原地更新的，所以他会改变给定的序列并且不返回一个新值。 strs := []string{\"c\", \"b\", \"d\", \"a\"} sort.Strings(strs) fmt.Println(strs) //一个 int 排序的例子。 ints := []int{4,2,3,1} sort.Ints(ints) fmt.Println(ints) //我们也可以使用 sort 来检查一个序列是不是已经是排好序的。 sorted := sort.IntsAreSorted(ints) fmt.Println(sorted) } ","date":"2021-03-03","objectID":"/go-instance-12/:1:0","tags":["golang"],"title":"Go Instance 12","uri":"/go-instance-12/"},{"categories":["实例"],"content":"使用函数自定义排序 使用和集合的自然排序不同的方法对集合进行排序。例如按字母的长度而不是首字母顺序对字符串排序。 package main import ( \"fmt\" \"sort\" ) //为了在Go中使用自定义函数进行排序，需要定义一个对应类型 //这里创建一个为内置[]string类型的别名ByLength类型 type ByLength []string //在类型中实现了sort.Interface 的Len，Less，Swap方法 //这样就可以使用sort包内通用的Sort方法了，Len和Swap通常在各个类型中差不多 //Less将控制实际的自定义排序逻辑 //在这个例子中按字符串的长度来进行排序，所以这里用到了len(s[i])和len(s[j]) func (s ByLength) Len() int { return len(s) } func (s ByLength) Less(i int, j int) bool { return len(s[i]) \u003c len(s[j]) } func (s ByLength) Swap(i int, j int) { s[i], s[j] = s[j], s[i] } func main() { //将原始的fruits转型成ByLength来实现自定义排序 //然后对这个转型的切片使用sort.Sort方法 fruits := []string{\"peach\", \"banana\", \"kiwi\"} sort.Sort(ByLength(fruits)) fmt.Println(fruits) } ","date":"2021-03-03","objectID":"/go-instance-12/:2:0","tags":["golang"],"title":"Go Instance 12","uri":"/go-instance-12/"},{"categories":["实例"],"content":"Go Instance 11-Go协程状态","date":"2021-02-28","objectID":"/go-instance-11/","tags":["golang"],"title":"Go Instance 11","uri":"/go-instance-11/"},{"categories":["实例"],"content":"Go协程状态 在前面的例子中，我们用互斥锁进行了明确的锁定来让共享的state 跨多个 Go 协程同步访问。另一个选择是使用内置的 Go协程和通道的的同步特性来达到同样的效果。这个基于通道的方法和 Go 通过通信以及 每个 Go 协程间通过通讯来共享内存，确保每块数据有单独的 Go 协程所有的思路是一致的。 package main import ( \"fmt\" \"math/rand\" \"sync/atomic\" \"time\" ) //在这个例子中，state将被一个单独的协程拥有 //这就能保证数据在并行读取时不会混乱，为了对state进行读取或写入 //其他Go协程将发送一条数据到拥有的Go协程中，然后接受对应的回复 //结构体readOp和writeOp封装这些状态，并且是拥有Go协程响应的一个方式 type readOp struct { key int resp chan int } type writeOp struct { key int value int resp chan bool } func main() { //计算执行操作的次数 var ops int64 = 0 //reads和writes通道分别将被其他Go协程用来发布读和写请求 reads := make(chan *readOp) writes := make(chan *writeOp) //这个就是拥有state的协程。这个协程的state是私有的 //这个Go协程反复响应到达的请求 //先响应到达的请求，然后返回一个值到响应通道resp表示操作成功 go func() { var state = make(map[int]int) for { select { case read := \u003c- reads: read.resp \u003c- state[read.key] case write := \u003c- writes: state[write.key] = write.value write.resp \u003c- true } } }() //启动100个协程通过reads通道发起对state所有者Go协程的读取请求 //每个读取请求需要构建一个readOp，发送它到reads通道中，并通过给定的resp接收结果 for i := 0; i \u003c 100; i++ { go func() { for { read := \u0026 readOp{ key: rand.Intn(5), resp: make(chan int), } reads \u003c- read \u003c- read.resp atomic.AddInt64(\u0026ops, 1) } }() } //用相同的方法启动10个写操作 for i := 0; i \u003c 10; i++ { go func() { for { write := \u0026writeOp{ key: rand.Intn(5), value: rand.Intn(100), resp: make(chan bool), } writes \u003c- write \u003c- write.resp atomic.AddInt64(\u0026ops, 1) } }() } //让Go协程先跑1秒 time.Sleep(time.Second) //最后获取并显示ops值 opsfinal := atomic.LoadInt64(\u0026ops) fmt.Println(opsfinal) } ","date":"2021-02-28","objectID":"/go-instance-11/:1:0","tags":["golang"],"title":"Go Instance 11","uri":"/go-instance-11/"},{"categories":["实例"],"content":"Go Instance 10-原子计数器，互斥锁","date":"2021-02-28","objectID":"/go-instance-10/","tags":["golang"],"title":"Go Instance 10","uri":"/go-instance-10/"},{"categories":["实例"],"content":"原子计数器 Go中最主要的状态管理方法是通过通道之间的通信完成的。在工作池的例子中有遇到，但是还是有一些其他方式来管理状态。如何使用sync/atomic包在多个Go协程中进行原子计数 package main import ( \"fmt\" \"runtime\" \"sync/atomic\" \"time\" ) //原子计数器 func main() { //使用一个无符号整型(永远是正整数)来代表这个计数器 var ops uint64 = 0 //为了模拟并发更新，启动50个协程，对计数器每个1毫秒进行一次加一操作 for i := 0; i \u003c 50; i++ { go func() { for { //使用AddUint64来让计数器自动增加，使用\u0026语法来抛出ops内存地址 atomic.AddUint64(\u0026ops, 1) //允许其他Go协程执行 runtime.Gosched() } }() } //等待1秒,让Go协程有时间运行 time.Sleep(time.Second) //在计数器还在被其他Go协程更新时,安全的使用 //通过LoadUint将当前值拷贝到opsfinal //LoadUint64 需要的是内存地址 opsfinal := atomic.LoadUint64(\u0026ops) fmt.Println(opsfinal) } ","date":"2021-02-28","objectID":"/go-instance-10/:1:0","tags":["golang"],"title":"Go Instance 10","uri":"/go-instance-10/"},{"categories":["实例"],"content":"互斥锁 相较于简单的原子计数器，对于更复杂的情况，可以使用一个互斥锁在Go协程里安全的访问数据 package main import ( \"fmt\" \"math/rand\" \"runtime\" \"sync\" \"sync/atomic\" \"time\" ) func main() { //在这个例子中state是一个map var state = make(map[int]int) //这里的mutex将同步对mutex的访问 var mutex = \u0026sync.Mutex{} //为了比较基于互斥锁的处理方式和其他方式，ops将记录对state的操作次数 var ops int64 = 0 //运行100Go协程同时读取state for i := 0; i \u003c 100; i++ { go func() { total := 0 for { //每次循环读取，使用一个键进行访问 //Lock()这个mutex来确保对state的独占访问，读取选定键的值 //Unlock()这个state并使ops+1 key := rand.Intn(5) //fmt.Println(\"key:\", key) mutex.Lock() total += state[key] mutex.Unlock() atomic.AddInt64(\u0026ops, 1) //为了确保这个Go协程不会在调度中饿死 //每次操作后明确使用runtime.Gosched()进行释放 //这个释放一般是自动处理的，例如每个通道操作后或者time.Sleep的阻塞调用后相似 //但在这个例子中需要手动处理 runtime.Gosched() } }() } //运行10个Go协程来模拟写操作，使用和读取相同模式 for i := 0; i \u003c 10; i++ { go func() { for { key := rand.Intn(5) value := rand.Intn(100) mutex.Lock() state[key] = value mutex.Unlock() atomic.AddInt64(\u0026ops, 1) runtime.Gosched() } }() } //让这10个Go协程对state和mutex的操作运行1秒 time.Sleep(time.Second) //获取并输出最终操作数 opsFinal := atomic.LoadInt64(\u0026ops) fmt.Println(\"ops:\", opsFinal) //对state使用一个最终锁，显示是如何结束的 mutex.Lock() fmt.Println(state) mutex.Unlock() } ","date":"2021-02-28","objectID":"/go-instance-10/:2:0","tags":["golang"],"title":"Go Instance 10","uri":"/go-instance-10/"},{"categories":["实例"],"content":"Go Instance 09-速率限制","date":"2021-02-27","objectID":"/go-instance-09/","tags":["golang"],"title":"Go Instance 09","uri":"/go-instance-09/"},{"categories":["实例"],"content":"速率限制 速率限制(英) 是一个重要的控制服务资源利用和质量的途径。Go 通过 Go 协程、通道和打点器优美的支持了速率限制。 package main import ( \"fmt\" \"time\" ) func main() { //基本速率限制 //如果想限制接收请求处理，可以将这些请求发送到一个相同通道 requests := make(chan int, 5) for i := 1; i \u003c= 5; i++ { requests \u003c- i } close(requests) //这个tick通道将每200毫秒接收一个值，这个是速率限制任务中的管理器 tick := time.Tick(time.Millisecond * 200) //通过在每次请求前阻塞tick通道的一个接收，限制每隔200毫秒接收一个值 for row := range requests { \u003c-tick fmt.Println(\"request:\", row, time.Now()) } //有时候想临时进行速率限制，并且不影响整体速率控制可以使用通道缓冲来实现 //burstyLimter通道用来进行3次临时的脉冲型速率限制 burstyLimter := make(chan time.Time, 3) //将需要临时改变值传入 for i := 0; i \u003c 3; i++ { burstyLimter \u003c- time.Now() } //每个200毫秒添加一个新值到通道内，直到达到3个限制 go func() { for t := range time.Tick(time.Millisecond * 200) { burstyLimter \u003c- t } }() //现在模拟5个接入请求 //刚开始3个受临时的脉冲影响 burstyRequests := make(chan int, 5) for i := 0; i \u003c 5; i++ { burstyRequests \u003c- i } close(burstyRequests) for row := range burstyRequests { \u003c- burstyLimter fmt.Println(\"request2: \", row, time.Now()) } } 运行程序，将看到第一批请求意料之中的大约每 200ms 处理一次。第二批请求，我们直接连续处理了 3 次，这是由于这个“脉冲”速率控制，然后大约每 200ms 处理其余的 2 个。 ","date":"2021-02-27","objectID":"/go-instance-09/:1:0","tags":["golang"],"title":"Go Instance 09","uri":"/go-instance-09/"},{"categories":["实例"],"content":"Go Instance 08-模拟工作池","date":"2021-02-26","objectID":"/go-instance-08/","tags":["golang"],"title":"Go Instance 08","uri":"/go-instance-08/"},{"categories":["实例"],"content":"工作池 在这个例子中，将看到如何使用GO协程和通道实现一个工作池 package main import ( \"fmt\" \"time\" ) //这是将要在多个并发实例中支持的任务 //这些执行者将从jobs通道接收任务，并通过results发送对应结果 //让每个任务睡1秒，模拟耗时任务 func worker(i int, jobs \u003c-chan int, results chan\u003c- int) { for j := range jobs{ fmt.Printf(\"worker %d processing job %d \\n\", i, j ) time.Sleep(time.Second) results \u003c- j } } func main() { //使用worker工作池并收集结果，需要两个通道 jobs := make(chan int, 100) results := make(chan int, 100) //这里启动三个worker，初始是阻塞的，因为还没有任务 for i := 1; i \u003c= 3; i++ { go worker(i, jobs, results) } //发送9个任务，然后close表示这些就是所有任务了 for i := 1; i \u003c= 9; i++ { jobs \u003c- i } close(jobs) //收集所有任务的返回值 for i := 1; i \u003c= 9; i++ { \u003c-results } } 执行这个程序，显示9个任务被多个worker执行。整个程序处理所有任务仅执行了3秒，因为是3个worker并行的 ","date":"2021-02-26","objectID":"/go-instance-08/:1:0","tags":["golang"],"title":"Go Instance 08","uri":"/go-instance-08/"},{"categories":["实例"],"content":"Go Instance 07-Go定时器和打点器","date":"2021-02-25","objectID":"/go-instance-07/","tags":["golang"],"title":"Go Instance 07","uri":"/go-instance-07/"},{"categories":["实例"],"content":"定时器 当需要在后面一个时刻运行Go代码，或者在某段时间内重复运行。Go内置的定时器和打点器让这些很容易实现 package main import ( \"fmt\" \"time\" ) func main() { //定时器表示在未来某一时刻的独立事件 //提供定时器需要的时间，定时器将提供一个用于通知的通道 //这里设置定时器将等待2秒 timer1 := time.NewTimer(time.Second * 2) //\u003c-timer1.C 直到这个定时器的通道C明确的发送了定时器失效的值之前，一直阻塞 \u003c-timer1.C fmt.Println(\"Timer 1 expired\") //如果需要的仅仅是等待，可以使用Sleep //定时器有用的原因之一是可以在定时器失效前取消定时器 timer2 := time.NewTimer(time.Second * 2) go func() { \u003c- timer2.C fmt.Println(\"Timer 2 expired\") }() stop := timer2.Stop() if stop { fmt.Println(\"Timer 2 stop\") } } 第一个定时器将在程序开始后2秒失效，第二个在其还没失效前就被停止了 ","date":"2021-02-25","objectID":"/go-instance-07/:1:0","tags":["golang"],"title":"Go Instance 07","uri":"/go-instance-07/"},{"categories":["实例"],"content":"打点器 定时器是当你想要在未来某一时刻执行一次时使用，打点器是当你想要在固定的时间间隔重复执行准备的。这是一个打点器的例子，它将定时执行，直到我们将它停止 package main import ( \"fmt\" \"time\" ) func main() { //打点器和定时器的机制有点相似：一个通道用来发送数据。 // 这里我们在这个通道上使用内置的 range 来迭代值每隔500ms 发送一次的值。 ticker := time.NewTicker(time.Millisecond * 500) go func() { for t := range ticker.C { fmt.Println(\"Tick at \", t) } }() //打点器可以和定时器一样被停止。一旦一个打点停止了，将不能再从它的通道中接收到值。 // 我们将在运行后 1600ms停止这个打点器。 time.Sleep(time.Millisecond * 1000) ticker.Stop() fmt.Println(\"Ticker stopped\") } ","date":"2021-02-25","objectID":"/go-instance-07/:2:0","tags":["golang"],"title":"Go Instance 07","uri":"/go-instance-07/"},{"categories":["生活"],"content":"学习进度","date":"2021-02-25","objectID":"/learning-process/","tags":["我的"],"title":"Learning Process","uri":"/learning-process/"},{"categories":["生活"],"content":"狂神说java java零基础学习视频通俗易懂(p27) ","date":"2021-02-25","objectID":"/learning-process/:1:0","tags":["我的"],"title":"Learning Process","uri":"/learning-process/"},{"categories":["生活"],"content":"Tears-Tearing Google资深工程师带你通关golang/go语言(p43) ","date":"2021-02-25","objectID":"/learning-process/:2:0","tags":["我的"],"title":"Learning Process","uri":"/learning-process/"},{"categories":["生活"],"content":"崔永华csdn博客 单元测试案例 学习go语言必备案例(4) ","date":"2021-02-25","objectID":"/learning-process/:3:0","tags":["我的"],"title":"Learning Process","uri":"/learning-process/"},{"categories":["实例"],"content":"Go Instance 06-defer+recover解决panic","date":"2021-02-23","objectID":"/go-instance-06/","tags":["golang"],"title":"Go Instance 06","uri":"/go-instance-06/"},{"categories":["实例"],"content":"defer+recover解决panic导致程序崩溃 ","date":"2021-02-23","objectID":"/go-instance-06/:1:0","tags":["golang"],"title":"Go Instance 06","uri":"/go-instance-06/"},{"categories":["实例"],"content":"案例1 如果我们起了一个协程，但这个协程出现了panic，但我们没有捕获这个协程，就会造成程序的崩溃，这时可以在goroutine中使用recover来捕获panic，进行处理，这样主线程不会受到影响 package main import ( \"fmt\" \"time\" ) func sayhello() { for i := 0; i \u003c 10; i++ { fmt.Println(\"hello\") time.Sleep(time.Second) } } func test() { //使用defer+recover defer func() { //捕获test抛出的panic if err := recover(); err != nil { fmt.Println(\"test 发生错误：\", err) } }() var myMap map[int]string myMap[0] = \"golang\" } func main() { go sayhello() go test() for i := 0; i \u003c 10; i++ { fmt.Println(\"main() ok=\", i) time.Sleep(time.Second) } } ","date":"2021-02-23","objectID":"/go-instance-06/:1:1","tags":["golang"],"title":"Go Instance 06","uri":"/go-instance-06/"},{"categories":["实例"],"content":"Go Instance 05-select解决通道堵塞","date":"2021-02-23","objectID":"/go-instance-05/","tags":["golang"],"title":"Go Instance 05","uri":"/go-instance-05/"},{"categories":["实例"],"content":"使用select解决从管道取数据堵塞问题 使用select解决从管道取数据堵塞的问题，语法如下： select语法\u0026ldquo;select语法\u0026rdquo; \"\rselect语法\r package main import ( \"fmt\" \"time\" ) func main() { //定义一个管道，可以放10个int类型数据 intChan := make(chan int, 10) for i := 0; i \u003c 10; i++ { intChan \u003c- i } //定义一个管道，可以放5个string类型数据 stringChan := make(chan string, 5) for i := 0; i \u003c 5; i++ { stringChan \u003c- \"hello\" + fmt.Sprintf(\"%d\", i) } //传统的方法遍历管道时，如果不关闭会阻塞而导致deadlock //实际开发中，不好确定什么时候关闭通道 //这时可以使用select方式解决 //label for { select { //管道不关闭不会deadlock，会自动到下一个case匹配 case v := \u003c-intChan: fmt.Printf(\"从intChan读取的数据%d\\n\", v) time.Sleep(time.Second) case v := \u003c-stringChan: fmt.Printf(\"从stringChan读取的数据%v\\n\", v) time.Sleep(time.Second) default: fmt.Printf(\"取不到数据\\n\") time.Sleep(time.Second) return //break label } } } ","date":"2021-02-23","objectID":"/go-instance-05/:1:0","tags":["golang"],"title":"Go Instance 05","uri":"/go-instance-05/"},{"categories":["实例"],"content":"Go Instance 04-goroutine和channel","date":"2021-02-23","objectID":"/go-instance-04/","tags":["golang"],"title":"Go Instance 04","uri":"/go-instance-04/"},{"categories":["实例"],"content":"goroutine和channel ","date":"2021-02-23","objectID":"/go-instance-04/:1:0","tags":["golang"],"title":"Go Instance 04","uri":"/go-instance-04/"},{"categories":["实例"],"content":"goroutine和channel协同工作 具体要求 开启一个writeData协程，向管道intChan中写入50个整数 开启一个readData协程，从管道intChan中读取writeData写入的数据 注意writeData和readData操作的是同一个管道 主线程需要等待writeData和readData协程都完成工作才能退出管道 思路分析 思路分析\u0026ldquo;思路分析\u0026rdquo; \"\r思路分析\r package main import \"fmt\" func writeData(intChan chan int) { for i := 1; i \u003c= 50; i++ { intChan \u003c-i fmt.Println(\"write:\", i) } close(intChan) } func readData(intChan chan int, exitChan chan bool) { for { n, ok := \u003c-intChan if !ok { break } fmt.Println(\"read:\", n) } exitChan \u003c- true close(exitChan) } func main() { intChan := make(chan int, 50) exitChan := make(chan bool, 1) go writeData(intChan) go readData(intChan, exitChan) for { _, ok := \u003c-exitChan if !ok { break } } } 读和写频率不一样也没有问题 package main import ( \"fmt\" \"time\" ) func writeData(intChan chan int) { for i := 0; i \u003c 50; i++ { intChan \u003c- i fmt.Println(\"write:\", i) } close(intChan) } func readData(intChan chan int, exitChan chan bool) { for { v, ok := \u003c-intChan if !ok { break } time.Sleep(time.Second) fmt.Println(\"read:\", v) } exitChan \u003c- true close(exitChan) } func main() { intChan := make(chan int, 10) exitChan := make(chan bool, 1) go writeData(intChan) go readData(intChan, exitChan) for { if _, ok := \u003c-exitChan; !ok{ break } } } 注意：如果只向管道写入数据而没有读取，就会造成堵塞而deadlock ","date":"2021-02-23","objectID":"/go-instance-04/:1:1","tags":["golang"],"title":"Go Instance 04","uri":"/go-instance-04/"},{"categories":["学习"],"content":"Go Study 15-channel","date":"2021-02-22","objectID":"/go-study-15/","tags":["golang"],"title":"Go Study 15","uri":"/go-study-15/"},{"categories":["学习"],"content":"channel ","date":"2021-02-22","objectID":"/go-study-15/:1:0","tags":["golang"],"title":"Go Study 15","uri":"/go-study-15/"},{"categories":["学习"],"content":"channel ","date":"2021-02-22","objectID":"/go-study-15/:1:1","tags":["golang"],"title":"Go Study 15","uri":"/go-study-15/"},{"categories":["学习"],"content":"buffered channel(带缓冲区的channel) ","date":"2021-02-22","objectID":"/go-study-15/:1:2","tags":["golang"],"title":"Go Study 15","uri":"/go-study-15/"},{"categories":["学习"],"content":"range(关闭channel) ","date":"2021-02-22","objectID":"/go-study-15/:1:3","tags":["golang"],"title":"Go Study 15","uri":"/go-study-15/"},{"categories":["学习"],"content":"理论基础Communication Sequential Process(CSP) ","date":"2021-02-22","objectID":"/go-study-15/:1:4","tags":["golang"],"title":"Go Study 15","uri":"/go-study-15/"},{"categories":["学习"],"content":"案例 ","date":"2021-02-22","objectID":"/go-study-15/:2:0","tags":["golang"],"title":"Go Study 15","uri":"/go-study-15/"},{"categories":["学习"],"content":"channel(通道) 通道是连接多个Go协程的管道，可以从一个Go协程将值发送到通道，然后在别的Go协程中接收 package main import ( \"fmt\" ) func channel1() { //使用make(chan val-type)创建一个新的通道 //通道类型就是传递值的类型 message := make(chan string) //使用 channel \u003c- 语法发送一个新的值到通道中 go func() { message \u003c- \"ping\" }() fmt.Println(message) //使用 \u003c- channel 语法从通道中获取一个值 msg := \u003c- message fmt.Println(msg) } func main() { channel1() } 运行程序时，通过通道，消息“ping”成功的从一个Go协程传到另一个。默认发送和接收操作是阻塞的，直到发送方和接收方都准备完毕。这个特性允许不使用任何其他的同步操作，可以在程序结尾等待消息“ping” ","date":"2021-02-22","objectID":"/go-study-15/:2:1","tags":["golang"],"title":"Go Study 15","uri":"/go-study-15/"},{"categories":["学习"],"content":"通道缓冲 默认通道是无缓冲的，这意味着只有在对应的接收(\u003c-chan)通道准备好接收时才允许发送(chan\u003c-)。可缓冲通道允许在没有接收方的情况下，缓存限定数量的值 package main import ( \"fmt\" ) func channel2() { //这里make了一个通道，最多允许缓存2个值 message := make(chan string, 2) //因为这个通道有缓冲区，即使没有一个对应的并发接收方，也可以继续发送 message \u003c- \"buffered\" message \u003c- \"channel\" //接收时，也可以接收两个值 fmt.Println(\u003c-message) fmt.Println(\u003c-message) } func main() { channel2() } ","date":"2021-02-22","objectID":"/go-study-15/:2:2","tags":["golang"],"title":"Go Study 15","uri":"/go-study-15/"},{"categories":["学习"],"content":"通道同步 可以使用通道来同步Go协程间的执行状态。这里使用阻塞的接收方式来等待一个Go协程的运行结束 package main import ( \"fmt\" \"time\" ) func channel3() { //创建一个缓存为1的bool类型通道 done := make(chan bool, 1) //运行一个worker Go协程，并给予用于通知的通道 go worker(done) //程序将在接收到通道中worker发出的通知前一直阻塞 \u003c-done } //这是一个我们将要在 Go 协程中运行的函数。 // done 通道将被用于通知其他 Go 协程这个函数已经工作完毕 func worker(done chan bool) { fmt.Println(\"working...\") time.Sleep(time.Second) fmt.Println(\"done\") //发送一个值来通知完工啦。 done \u003c- true } func main() { channel3() } 如果将done \u003c- true这行代码从程序中移除，程序甚至会在worker还没开始运行就结束 ","date":"2021-02-22","objectID":"/go-study-15/:2:3","tags":["golang"],"title":"Go Study 15","uri":"/go-study-15/"},{"categories":["学习"],"content":"通道方向 当使用通道作为函数参数时，可以指定通道是不是只用来接收或发送值。这个特性提升了程序的类型安全性 package main import ( \"fmt\" ) func channel4() { pings := make(chan string, 1) pongs := make(chan string, 1) ping(pings, \"message\") pong(pings, pongs) fmt.Println(\u003c-pongs) } //ping函数定义一个只允许发送数据的通道 //尝试使用这个函数来接收数据会得到一个编译时错误 func ping(pings chan\u003c- string, str string) { pings \u003c- str } //pong函数允许通道pings接收函数，通道pongs发送函数 func pong(pings \u003c-chan string, pongs chan\u003c- string) { msg := \u003c-pings pongs \u003c- msg } func main() { channel4() } ","date":"2021-02-22","objectID":"/go-study-15/:2:4","tags":["golang"],"title":"Go Study 15","uri":"/go-study-15/"},{"categories":["学习"],"content":"通道选择器 Go的通道选择器可以同时等待多个通道操作。Go协程和通道以及选择器的结合是Go的一个强大特性 package main import ( \"fmt\" \"time\" ) func main() { //创建2个通道，从这两个选择 c1 := make(chan string, 1) c2 := make(chan string, 1) //c1通道在1秒后接收值，这个模拟Go协程中阻塞的RPC操作 go func() { time.Sleep(time.Second) c1 \u003c- \"one\" }() //c2通道在2秒后接收值 go func() { time.Sleep(time.Second * 2) c2 \u003c- \"two\" }() //使用select关键字来同时等待这两个值，并打印各自的值 for i :=0; i \u003c 2; i++ { select { case msg := \u003c-c1: fmt.Println(msg) case msg := \u003c-c2: fmt.Println(msg) } } } 注意两个协程并发运行，程序总共仅运行2秒左右 ","date":"2021-02-22","objectID":"/go-study-15/:2:5","tags":["golang"],"title":"Go Study 15","uri":"/go-study-15/"},{"categories":["学习"],"content":"超时处理 超时对于一个连接外部资源，或者其他一些需要花费执行时间操作的程序而言是很重要的。得益于通道和select，在Go中实现超时操作是简洁而优雅的 package main import ( \"fmt\" \"time\" ) func main() { //在这个例子中，执行一个外部调用，在2秒后通过通道c1返回执行结果 c1 := make(chan string, 1) go func() { time.Sleep(time.Second * 2) c1 \u003c- \"result 1\" }() //使用select实现超时操作 //result := \u003c-c1等待结果，\u003c-Time.After等待超时1秒后发送的值 //由于select默认处理第一个已准备好的接收操作，如果这个操作超过允许的1秒的话，将会执行超时case select { case result := \u003c- c1: fmt.Println(result) case \u003c-time.After(time.Second * 1): fmt.Println(\"result1 超时\") } //执行一个外部调用，2秒后通过通道c2返回执行结果 c2 := make(chan string, 1) go func() { time.Sleep(time.Second * 2) c2 \u003c- \"result 2\" }() //将超时延长至3秒，如果操作小于3秒将执行result输出case select { case result := \u003c-c2: fmt.Println(result) case \u003c-time.After(time.Second * 3): fmt.Println(\"result2超时\") } } 运行程序，首先显示运行超时的操作，然后是成功接收的。使用select超时方式需要使用通道传递结果。这对于一般情况是个好方式，因为其他重要的Go特性是基于通道和select的 ","date":"2021-02-22","objectID":"/go-study-15/:2:6","tags":["golang"],"title":"Go Study 15","uri":"/go-study-15/"},{"categories":["学习"],"content":"非阻塞式通道操作 常规的通过通道发送和接收数据是阻塞的。然而，可以使用带default子句select来实现非阻塞的发送、接收，甚至是非阻塞的多路select package main import \"fmt\" //这是一个非阻塞接收的例子 func main() { message := make(chan string, 1) signal := make(chan string, 1) //如果message有值存在，select将值传到msg中 //如果不存在直接执行default select { case msg := \u003c-message: fmt.Println(\"received message:\", msg) default: fmt.Println(\"no message receives\") } //这个非阻塞方法，如果msg成功向message传值，执行case //否则执行default msg := \"hi\" select { case message \u003c- msg: fmt.Println(\"sent message:\", msg) default: fmt.Println(\"no message sent\") } signal \u003c- \"world\" //可以在default前使用多个case子句实现一个多路的非阻塞的选择器 //这里尝试在message和signal上同时使用非阻塞的接收操作 //如果case1和case2都满足，随机执行case1或case2 select { case msg := \u003c-message: fmt.Println(\"receives message:\", msg) case sign := \u003c-signal: fmt.Println(\"receives signal:\", sign) default: fmt.Println(\"no activity\") } } ","date":"2021-02-22","objectID":"/go-study-15/:2:7","tags":["golang"],"title":"Go Study 15","uri":"/go-study-15/"},{"categories":["学习"],"content":"通道的关闭 关闭一个通道意味着不能再向这个通道发送值了。这个特性可以用来给这个通道接收方传达工作已经完成的消息 package main import \"fmt\" func main() { //在这个例子中，将使用一个jobs通道来传递main()中Go协程任务执行的结果信息到一个工作Go协程中 //当没有多余任务给这个工作Go协程时，可以close这个jobs通道 job := make(chan int, 5) done := make(chan bool, 1) //这是工作Go协程，使用j, more := \u003c-job循环从job接收数据 //在接收的这个特殊的二值形式的值中，如果job已经关闭，并且通道中的所有值都已经接收完毕 //那么more的值将是false。当完成所有任务时，将使用这个特性通过done通道去进行通知 go func() { for { j, more := \u003c-job if more { fmt.Println(\"received job:\", j) } else { fmt.Println(\"received all jobs\") done \u003c- true return } } }() //这里使用job发送3个任务到工作函数中，然后关闭job for i := 1; i \u003c= 3; i++ { job \u003c- i fmt.Println(\"sent job:\", i) } close(job) fmt.Println(\"sent all job\") //使用通道同步方法等待任务结束 \u003c-done } ","date":"2021-02-22","objectID":"/go-study-15/:2:8","tags":["golang"],"title":"Go Study 15","uri":"/go-study-15/"},{"categories":["学习"],"content":"通道遍历 可以使用range语法来遍历从通道中取得的值。一个非空通道是可以关闭的，但是通道中的值仍然可以被接收到 package main import \"fmt\" func main() { //遍历在queue通道中的两个值 queue := make(chan string, 2) queue \u003c- \"one\" queue \u003c- \"two\" close(queue) //这个range迭代从queue中得到的每个值 //因为close了通道，这个通道会在接收完第二个值后结束 //如果没有close，那么这个循环将继续阻塞执行，等待接收第三个值 for elem := range queue { fmt.Println(elem) } } ","date":"2021-02-22","objectID":"/go-study-15/:2:9","tags":["golang"],"title":"Go Study 15","uri":"/go-study-15/"},{"categories":["实例"],"content":"Go Instance 03-字符操作","date":"2021-02-22","objectID":"/go-instance-03/","tags":["golang"],"title":"Go Instance 03","uri":"/go-instance-03/"},{"categories":["实例"],"content":"字符操作 ","date":"2021-02-22","objectID":"/go-instance-03/:1:0","tags":["golang"],"title":"Go Instance 03","uri":"/go-instance-03/"},{"categories":["实例"],"content":"案例1 统计一个文本文件的字符个数 package main import ( \"bufio\" \"fmt\" \"io\" \"os\" ) //定义一个结构体保存统计结果 type charCount struct { //英文个数 chCount int //空格个数 spaceCount int //数字个数 numCount int //其他个数 otherCount int } func main() { /** 思路：打开一个文件，创建一个Reader 每读取一行，统计字符保存到结构体中 */ file, err := os.Open(\"fileOperations/abc.txt\") if err != nil { fmt.Println(\"file open err:\", err) } reader := bufio.NewReader(file) fileC := charCount{} //循环读取file内容 for { s, err := reader.ReadString('\\n') //为了兼容中文转化为rune for _, r := range []rune(s) { switch { case r \u003e= 'a' \u0026\u0026 r \u003c= 'z': fallthrough case r \u003e= 'A' \u0026\u0026 r \u003c= 'Z': fileC.chCount++ case r \u003e '0' \u0026\u0026 r \u003c '9': fileC.numCount++ case r == ' ' || r == '\\t': fileC.spaceCount++ default: fileC.otherCount++ } } if err == io.EOF { break } } fmt.Printf(\"file has chcount: %d, numcount: %d, spaceCount: %d, otherCount: %d\", fileC.chCount, fileC.numCount, fileC.spaceCount, fileC.otherCount) } ","date":"2021-02-22","objectID":"/go-instance-03/:1:1","tags":["golang"],"title":"Go Instance 03","uri":"/go-instance-03/"},{"categories":["实例"],"content":"将数据序列化成json字符串 ","date":"2021-02-22","objectID":"/go-instance-03/:2:0","tags":["golang"],"title":"Go Instance 03","uri":"/go-instance-03/"},{"categories":["实例"],"content":"将数据(结构体，Map，Slice，基础数据类型)序列化成json字符串 json序列化是指将有key-value结构的数据类型(比如：结构体，Map，Slice)序列化成json字符串的操作 package main import ( \"encoding/json\" \"fmt\" ) type Hero struct { Name string `json:\"hero_name\"` Age int `json:\"hero_age\"` Sex string } //结构体序列化 func changeStruct() { hero := Hero{ Name: \"小陈\", Age: 18, Sex: \"男\", } //将结构体序列化 bytes, err := json.Marshal(hero) if err != nil{ fmt.Println(\"json marshal fail:\", err) } fmt.Printf(\"结构体序列化后的字段：%v\\n\", string(bytes)) } //Map序列化 func changeMap() { map1 := make(map[string]interface{}) map1[\"name\"] = \"张无忌\" map1[\"age\"] = 22 map1[\"address\"] = \"冰火岛\" //将map序列化 bytes, err := json.Marshal(map1) if err != nil { fmt.Println(\"json marshal fail:\", err) } fmt.Printf(\"Map序列化后的字段：%v\\n\", string(bytes)) } //Slice序列化 func changeSlice() { var slice []map[string]interface{} m1 := make(map[string]interface{}) m1[\"name\"] = \"张无忌\" m1[\"age\"] = 25 m1[\"address\"] = \"冰火岛\" slice = append(slice, m1) m2 := make(map[string]interface{}) m2[\"name\"] = \"张三丰\" m2[\"age\"] = \"88\" m2[\"address\"] = []string{\"武当山\", \"夏威夷\"} slice = append(slice, m2) //slice序列化 bytes, err := json.Marshal(slice) if err != nil { fmt.Println(\"json marshal fail:\", err) } fmt.Printf(\"Slice序列化后的字段：%v\\n\", string(bytes)) } //基本类型序列化(对基础类型序列化意义不大) func changeFloat() { var f float64 = 3.14 //对float序列化 bytes, err := json.Marshal(f) if err != nil { fmt.Println(\"json marshal fail:\", err) } fmt.Println(\"Float序列化后的字段：\", string(bytes)) } func main() { changeStruct() changeMap() changeSlice() changeFloat() } ","date":"2021-02-22","objectID":"/go-instance-03/:2:1","tags":["golang"],"title":"Go Instance 03","uri":"/go-instance-03/"},{"categories":["实例"],"content":"将json字符串反序列化成对应数据 ","date":"2021-02-22","objectID":"/go-instance-03/:3:0","tags":["golang"],"title":"Go Instance 03","uri":"/go-instance-03/"},{"categories":["实例"],"content":"将json字符串 反序列化成对应数据（比如：结构体，map，切片） package main import ( \"encoding/json\" \"fmt\" ) type Hero struct { Name string `json:\"hero_name\"` Age int `json:\"hero_age\"` Sex string } //将json字符串反序列化为结构体 func unmarshalStruct() { str := \"{\\\"hero_name\\\":\\\"小陈\\\",\\\"hero_age\\\":18,\\\"Sex\\\":\\\"男\\\"}\" var hero Hero err := json.Unmarshal([]byte(str), \u0026hero) if err != nil { fmt.Println(\"json unmarshal fail:\", err) } fmt.Printf(\"json反序列化为结构体：%v\\n\", hero) } //将json字符串反序列化为Map func unmarshalMap() { str := \"{\\\"name\\\": \\\"张无忌\\\",\\\"age\\\": 22,\\\"address\\\": \\\"冰火岛\\\"}\" //定义一个map，反序列化的时候不需要make，因为unmarshal封装了make var map1 map[string]interface{} err := json.Unmarshal([]byte(str), \u0026map1) if err != nil { fmt.Println(\"json unmarshal fail:\", err) } fmt.Printf(\"json反序列化为Map：%v\\n\",map1) } //将json字符串反序列化为Slice func unmarshalSlice() { str := \"[{\\\"address\\\":\\\"冰火岛\\\",\\\"age\\\":25,\\\"name\\\":\\\"张无忌\\\"},{\\\"address\\\":[\\\"武当山\\\",\\\"夏威夷\\\"],\\\"age\\\":\\\"88\\\",\\\"name\\\":\\\"张三丰\\\"}]\" //定义一个slice，反序列化的时候不需要make，因为unmarshal封装了make var slice []map[string]interface{} err := json.Unmarshal([]byte(str), \u0026slice) if err != nil { fmt.Println(\"json unmarshal fail:\", err) } fmt.Printf(\"json反序列化为Slice：%v\\n\", slice) } func main() { unmarshalStruct() unmarshalMap() unmarshalSlice() } ","date":"2021-02-22","objectID":"/go-instance-03/:3:1","tags":["golang"],"title":"Go Instance 03","uri":"/go-instance-03/"},{"categories":["实例"],"content":"Go Instance 02-文件操作","date":"2021-02-22","objectID":"/go-instance-02/","tags":["golang"],"title":"Go Instance 02","uri":"/go-instance-02/"},{"categories":["实例"],"content":"读取文件 ","date":"2021-02-22","objectID":"/go-instance-02/:1:0","tags":["golang"],"title":"Go Instance 02","uri":"/go-instance-02/"},{"categories":["实例"],"content":"案例1 读取文件的内容并显示在终端(带缓冲区的方式) package main import ( \"bufio\" \"fmt\" \"io\" \"os\" ) //读取文件的内容并显示在终端(带缓冲区的方式) func main() { //打开文件 file, err := os.Open(\"fileOperations/abc.txt\") if err != nil { fmt.Println(\"文件打开失败\") } //函数退出时关闭文件 defer file.Close() //输出文件 fmt.Printf(\"file=%v \\n\", \u0026file) //创建一个*Reader，带缓冲的，默认缓冲区大小为4096 reader := bufio.NewReader(file) //循环读取文件内容 for { //读到一个换行结束 s, err := reader.ReadString('\\n') //输出文件内容 fmt.Print(s) //io.EOF表示文件末尾 if err == io.EOF { fmt.Println() break } } fmt.Println(\"文件读取结束\") } ","date":"2021-02-22","objectID":"/go-instance-02/:1:1","tags":["golang"],"title":"Go Instance 02","uri":"/go-instance-02/"},{"categories":["实例"],"content":"案例2 对于文件不太大的情况，可以使用ioutil一次将整个文件读到内存里 package main import ( \"fmt\" \"io/ioutil\" ) //对于文件不太大的情况，可以使用ioutil一次将整个文件读到内存里 func main() { //打开文件 file, err := ioutil.ReadFile(\"fileOperations/abc.txt\") if err != nil { fmt.Println(\"open file err:\", err) } //把读取到的文件显示在终端 //不需要显式的Open和Close文件，因为这两个操作已经被封装在ioutilFile函数内部 fmt.Printf(\"file is %v\\n\", file) fmt.Printf(\"file is %v\\n\", string(file)) } ","date":"2021-02-22","objectID":"/go-instance-02/:1:2","tags":["golang"],"title":"Go Instance 02","uri":"/go-instance-02/"},{"categories":["实例"],"content":"写入文件 ","date":"2021-02-22","objectID":"/go-instance-02/:2:0","tags":["golang"],"title":"Go Instance 02","uri":"/go-instance-02/"},{"categories":["实例"],"content":"案例1 创建一个新文件写入5句hello package main import ( \"bufio\" \"fmt\" \"os\" ) //创建一个新文件写入5句hello func main() { //打开文件，可写可创建 file, err := os.OpenFile(\"fileOperations/write.txt\", os.O_WRONLY|os.O_CREATE, 0666) if err != nil{ fmt.Printf(\"open file err: %v\\n\", err) } //函数退出关闭文件 defer file.Close() //写入文件，使用带缓存的*writer writer := bufio.NewWriter(file) for i := 0; i \u003c 5; i++ { writer.WriteString(\"hello\\n\") } //Flush将缓存的文件真正写入到文件中 writer.Flush() fmt.Println(\"文件写入成功\") } ","date":"2021-02-22","objectID":"/go-instance-02/:2:1","tags":["golang"],"title":"Go Instance 02","uri":"/go-instance-02/"},{"categories":["实例"],"content":"案例2 打开已有文件追加内容 package main import ( \"bufio\" \"fmt\" \"os\" ) //打开已有文件追加内容 func main() { //打开文件，文件可写可以追加 file, err := os.OpenFile(\"fileOperations/write.txt\", os.O_APPEND|os.O_WRONLY, 0666) if err != nil { fmt.Println(\"file is err\", err) } //函数最后关闭文件 defer file.Close() //写入文件，使用带缓存的*writer writer := bufio.NewWriter(file) for i := 0; i \u003c 5; i++ { writer.WriteString(\"abc \\r\\n\") } //Flush将缓存文件真正写入到文件中 writer.Flush() } ","date":"2021-02-22","objectID":"/go-instance-02/:2:2","tags":["golang"],"title":"Go Instance 02","uri":"/go-instance-02/"},{"categories":["实例"],"content":"案例3 打开一个存在的文件读取内容并追加内容 package main import ( \"bufio\" \"fmt\" \"io\" \"os\" ) //打开一个存在的文件读取内容并追加内容 func main() { //打开文件，可读可写可追加 file, err := os.OpenFile(\"fileOperations/write.txt\", os.O_APPEND|os.O_RDWR, 0666) if err != nil { fmt.Println(\"file open err:\", err) } //函数结束关闭文件 defer file.Close() //读取文件 reader := bufio.NewReader(file) for{ s, err := reader.ReadString('\\n') fmt.Print(s) if err == io.EOF { break } } //写入文件 writer := bufio.NewWriter(file) for i := 0; i \u003c 5; i++ { writer.WriteString(\"hello world\\n\") } writer.Flush() } ","date":"2021-02-22","objectID":"/go-instance-02/:2:3","tags":["golang"],"title":"Go Instance 02","uri":"/go-instance-02/"},{"categories":["实例"],"content":"案例4 将一个文件内容复制到另一个文件中 package main import ( \"fmt\" \"io/ioutil\" \"os\" ) //将一个文件内容复制到另一个文件中 func main() { os.OpenFile(\"fileOperations/writecopy.txt\", os.O_CREATE|os.O_WRONLY, 0666) file, err := ioutil.ReadFile(\"fileOperations/write.txt\") if err != nil { fmt.Println(\"file1 open err:\", err) } err = ioutil.WriteFile(\"fileOperations/writecopy.txt\", file, 0666) if err != nil { fmt.Println(\"file2 copy err\", err) } } ","date":"2021-02-22","objectID":"/go-instance-02/:2:4","tags":["golang"],"title":"Go Instance 02","uri":"/go-instance-02/"},{"categories":["实例"],"content":"拷贝文件 ","date":"2021-02-22","objectID":"/go-instance-02/:3:0","tags":["golang"],"title":"Go Instance 02","uri":"/go-instance-02/"},{"categories":["实例"],"content":"案例1 将一个图片拷贝到另一个文件下 package main import ( \"bufio\" \"fmt\" \"io\" \"os\" ) //编写一个函数，传入两个文件路径 func copyFile(dstFile string, srcFile string) (written int64, err error) { //打开srcFile read, err := os.OpenFile(srcFile, os.O_RDONLY, 0) if err != nil { fmt.Println(\"srcFile open err:\", err) } defer read.Close() //通过srcFile找到 reader reader := bufio.NewReader(read) //打开dstFile write, err := os.OpenFile(dstFile, os.O_WRONLY|os.O_CREATE, 0666) if err != nil { fmt.Println(\"dstFile open err:\", err) } defer write.Close() //通过dstFile找到writer writer := bufio.NewWriter(write) return io.Copy(writer, reader) } func main() { //将srcFile文件拷贝到dstFile文件 srcFile := \"F:/hugo-blog/cc/static/go7.jpg\" dstFile := \"D:/bgird.jpg\" //调用copyFile完成拷贝 written, err := copyFile(dstFile, srcFile) if err != nil { fmt.Println(\"copy file err:\", err) } else { fmt.Println(\"copy file success, written:\", written) } } ","date":"2021-02-22","objectID":"/go-instance-02/:3:1","tags":["golang"],"title":"Go Instance 02","uri":"/go-instance-02/"},{"categories":["学习"],"content":"Go Study 14-goroutine","date":"2021-02-21","objectID":"/go-study-14/","tags":["golang"],"title":"Go Study 14","uri":"/go-study-14/"},{"categories":["学习"],"content":"goroutine ","date":"2021-02-21","objectID":"/go-study-14/:1:0","tags":["golang"],"title":"Go Study 14","uri":"/go-study-14/"},{"categories":["学习"],"content":"协程Coroutine 轻量级“线程” 非抢占式多任务处理，由协程主动交出控制权 编译器/解释器/虚拟机层面的多任务 多个协程可能在一个或多个线程上运行 coroutine\u0026ldquo;coroutine\u0026rdquo; \"\rcoroutine\r ","date":"2021-02-21","objectID":"/go-study-14/:1:1","tags":["golang"],"title":"Go Study 14","uri":"/go-study-14/"},{"categories":["学习"],"content":"goroutine的定义 任何函数只需加上go就能送给调度器运行 不需要在定义时区分是否是异步函数 调度器会在合适的点进行切换 使用-race来检测数据访问冲突 goroutine\u0026ldquo;goroutine\u0026rdquo; \"\rgoroutine\r ","date":"2021-02-21","objectID":"/go-study-14/:1:2","tags":["golang"],"title":"Go Study 14","uri":"/go-study-14/"},{"categories":["学习"],"content":"goroutine可能的切换点 I/O，select channel 等待锁 函数调用(有时) runtime.Gosched() 以上只是参考，不能保证切换，不能保证在其他地方不切换 ","date":"2021-02-21","objectID":"/go-study-14/:1:3","tags":["golang"],"title":"Go Study 14","uri":"/go-study-14/"},{"categories":["学习"],"content":"案例 ","date":"2021-02-21","objectID":"/go-study-14/:2:0","tags":["golang"],"title":"Go Study 14","uri":"/go-study-14/"},{"categories":["学习"],"content":"协程 Go协程在执行上来说是轻量级的线程 package main import \"fmt\" func f(s string) { for i := 0; i \u003c 3; i++ { fmt.Println(s) } } //Go协程在执行上来说是轻量级的线程 func main() { //使用一般方式运行f函数 f(\"direct\") //使用go f(s)在一个Go协程中调用这个函数 //这个新的Go协程会并行的执行这个函数的调用 go f(\"gorouting\") //为匿名函数启动一个Go协程 go func(msg string) { for i := 0; i \u003c 10; i++ { fmt.Println(msg) } }(\"going\") //现在这两个Go协程在独立的Go协程中异步运行，所以需要等他们结束 //Scanln代码，我们在程序退出前按下任意键结束 var in string fmt.Scanln(\u0026in) fmt.Println(\"done\") } 当运行这个程序时，将先看见阻塞式调用，然后是两个go协程交替输出，这种交替输出表示Go运行时是以异步方式运行协程的 ","date":"2021-02-21","objectID":"/go-study-14/:2:1","tags":["golang"],"title":"Go Study 14","uri":"/go-study-14/"},{"categories":["学习"],"content":"Go Study 13-测试","date":"2021-02-21","objectID":"/go-study-13/","tags":["golang"],"title":"Go Study 13","uri":"/go-study-13/"},{"categories":["学习"],"content":"测试 testing.T的应用 运行测试 ","date":"2021-02-21","objectID":"/go-study-13/:1:0","tags":["golang"],"title":"Go Study 13","uri":"/go-study-13/"},{"categories":["学习"],"content":"代码覆盖率 使用IDE查看代码覆盖 使用go test获取代码覆盖报告 使用go tool cover查看代码覆盖报告 ","date":"2021-02-21","objectID":"/go-study-13/:1:1","tags":["golang"],"title":"Go Study 13","uri":"/go-study-13/"},{"categories":["学习"],"content":"性能测试 testing.B的使用 ","date":"2021-02-21","objectID":"/go-study-13/:1:2","tags":["golang"],"title":"Go Study 13","uri":"/go-study-13/"},{"categories":["学习"],"content":"使用pprof进行性能调优 终端进入有测试文件的项目目录下 go test -bench . -cpuprofile cpu.out生成cpu.out go tool pprof cpu.out查看cpu.out 在交互式命令行输入web进行查看 ","date":"2021-02-21","objectID":"/go-study-13/:1:3","tags":["golang"],"title":"Go Study 13","uri":"/go-study-13/"},{"categories":["学习"],"content":"案例","date":"2021-02-21","objectID":"/go-study-13/:2:0","tags":["golang"],"title":"Go Study 13","uri":"/go-study-13/"},{"categories":["面试"],"content":"Go Interview 01-new与make的区别","date":"2021-02-20","objectID":"/go-interview-01/","tags":["golang"],"title":"Go Interview 01","uri":"/go-interview-01/"},{"categories":["面试"],"content":"new和make的定义 func new(Type) *Type func make(t Type, size ...IntegerType) Type 其中Type代表一个数据类型 ","date":"2021-02-20","objectID":"/go-interview-01/:1:0","tags":["golang"],"title":"Go Interview 01","uri":"/go-interview-01/"},{"categories":["面试"],"content":"二者的区别 ","date":"2021-02-20","objectID":"/go-interview-01/:2:0","tags":["golang"],"title":"Go Interview 01","uri":"/go-interview-01/"},{"categories":["面试"],"content":"返回值 从定义中可以看出，new返回的是指向Type的指针，make直接返回的是Type类型值 ","date":"2021-02-20","objectID":"/go-interview-01/:2:1","tags":["golang"],"title":"Go Interview 01","uri":"/go-interview-01/"},{"categories":["面试"],"content":"入参 new只有一个Type参数，Type可以是任意数据类型。make可以有多个参数，但是只能是slice，map或者chan中的一种。对于不同类型，size参数说明如下： 对于slice,第一个size表示长度，第二个size表示容量，且容量不能小于长度。如果省略第二个size，默认容量等于长度。 对于map，会根据size大小分配资源，以足够存储size个元素。如果省略size，会默认分配一个小的起始size 对于chan，size表示缓冲区容量。如果省略size，channel为无缓冲channel ","date":"2021-02-20","objectID":"/go-interview-01/:2:2","tags":["golang"],"title":"Go Interview 01","uri":"/go-interview-01/"},{"categories":["面试"],"content":"分配类型 new：用来分配内存，主要用来分配值类型 make：用来分配内存，主要用来分配引用类型 ","date":"2021-02-20","objectID":"/go-interview-01/:2:3","tags":["golang"],"title":"Go Interview 01","uri":"/go-interview-01/"},{"categories":["实例"],"content":"Go Instance 01-豆瓣爬虫","date":"2021-02-19","objectID":"/go-instance-01/","tags":["golang"],"title":"Go Instance 01","uri":"/go-instance-01/"},{"categories":["实例"],"content":"使用Go爬取豆瓣电影排行榜 package main import ( \"encoding/json\" \"fmt\" \"io/ioutil\" \"net/http\" \"os\" \"regexp\" \"strings\" ) func main() { data, err := GetHtml(\"https://movie.douban.com/chart\") if err != nil { fmt.Println(\"获取源代码失败:\", err) return } //创建文件 file, err := os.Create(\"movie.json\") if err != nil { fmt.Println(\"创建文件失败:\", err) return } encoder := json.NewEncoder(file) encoder.SetIndent(\" \", \" \") encoder.Encode(GetItem(data)) } func GetHtml(url string) ([]byte, error) { var clent http.Client req, err := http.NewRequest(\"GET\", url, nil) if err != nil { fmt.Println(\"创建请求失败:\", err) return nil, err } //添加请求头，才能访问到需要的网页源码 req.Header.Add(\"User-Agent\", \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.102 Safari/537.36 Edg/85.0.564.51\") resp, err := clent.Do(req) if err != nil { fmt.Println(\"请求失败:\", err) return nil, err } data, err := ioutil.ReadAll(resp.Body) if err != nil { fmt.Println(\"读取失败:\", err) return nil, err } defer resp.Body.Close() return data, nil } type Item struct { Link string `json:\"link\"` Name string `json:\"name\"` Info string `json:\"info\"` Rate string `json:\"rate\"` RateNum string `json:\"rate_num\"` } func GetItem(data []byte) []Item { //正则匹配需要的内容 pattern := regexp.MustCompile(`(?s)\u003cdiv.*?class=\"pl2\".*?\u003e.*?\u003ca href=\"(.*?)\".*?\u003e(.*?)/.*?\u003cspan.*?\u003c/span\u003e.*?\u003cp class=\"pl\"\u003e(.*?)\u003c/p\u003e.*?\u003cdiv.*?\u003e.*?\u003cspan class=\"rating_nums\"\u003e(.*?)\u003c/span\u003e.*?\u003cspan class=\"pl\"\u003e\\((.*?)\\)\u003c/span\u003e.*?\u003c/div\u003e`) //查找网页中所有的匹配项 items := pattern.FindAllSubmatch(data, -1) var res []Item for _, item := range items { res = append(res, Item{ Link: string(item[1]), Name: strings.TrimSpace(string(item[2])), Info: string(item[3]), Rate: string(item[4]), RateNum: string(item[5]), }) } return res } ","date":"2021-02-19","objectID":"/go-instance-01/:1:0","tags":["golang"],"title":"Go Instance 01","uri":"/go-instance-01/"},{"categories":["学习"],"content":"Go Study 12-资源管理与出错处理","date":"2021-02-18","objectID":"/go-study-12/","tags":["golang"],"title":"Go Study 12","uri":"/go-study-12/"},{"categories":["学习"],"content":"defer调用 确保调用在函数结束时发生 多defer相当于栈(先进后出) 参数在defer语句时计算 ","date":"2021-02-18","objectID":"/go-study-12/:1:0","tags":["golang"],"title":"Go Study 12","uri":"/go-study-12/"},{"categories":["学习"],"content":"何时使用defer调用 Open/Close Lock/Unlock PrintHeader/PrintFooter ","date":"2021-02-18","objectID":"/go-study-12/:2:0","tags":["golang"],"title":"Go Study 12","uri":"/go-study-12/"},{"categories":["学习"],"content":"错误处理二 如何实现统一的错误处理逻辑 ","date":"2021-02-18","objectID":"/go-study-12/:3:0","tags":["golang"],"title":"Go Study 12","uri":"/go-study-12/"},{"categories":["学习"],"content":"panic 停止当前函数运行 一直向上返回，执行每一层的defer 如果没有遇见recover，程序退出 ","date":"2021-02-18","objectID":"/go-study-12/:4:0","tags":["golang"],"title":"Go Study 12","uri":"/go-study-12/"},{"categories":["学习"],"content":"recover 仅在defer调用中使用 获取panic的值 如果无法处理，可重新panic ","date":"2021-02-18","objectID":"/go-study-12/:5:0","tags":["golang"],"title":"Go Study 12","uri":"/go-study-12/"},{"categories":["学习"],"content":"error vs panic 意料之中的：使用error。如：文件打不开 意料之外的：使用panic。如：数组越界 ","date":"2021-02-18","objectID":"/go-study-12/:6:0","tags":["golang"],"title":"Go Study 12","uri":"/go-study-12/"},{"categories":["学习"],"content":"错误处理综合实例 defer + panic + recover Type Assertion 函数式编程的应用 ","date":"2021-02-18","objectID":"/go-study-12/:7:0","tags":["golang"],"title":"Go Study 12","uri":"/go-study-12/"},{"categories":["学习"],"content":"案例 ","date":"2021-02-18","objectID":"/go-study-12/:8:0","tags":["golang"],"title":"Go Study 12","uri":"/go-study-12/"},{"categories":["学习"],"content":"错误处理 Go语言使用一个独立的明确的返回值来传递错误信息。这与使用异常的Java和Ruby以及在C语言中常见到的超重的单返回值/错误值相比，Go语言的处理方式能清楚知道那个函数返回了错误，并能像调用那些没有出错函数一样调用 package main import ( \"errors\" \"fmt\" ) //按照惯例，错误通常是最后一个返回值并且是error类型，一个内建的接口 func f1(arg int) (int, error) { if arg == 42 { //error.New 构造一个使用给定错误信息的基本error值 return -1, errors.New(\"can't work with 42\") } //返回错误值为nil，代表没有错误 return arg+3, nil } //通过实现Error方法来自定义error是可以的 //这里使用自定义错误类型来表示上面的参数错误 type argError struct { arg int prob string } func (e *argError) Error() string { return fmt.Sprintf(\"%d-%s\", e.arg, e.prob) } func f2(arg int) (int, error) { if arg == 42 { //这个例子中，使用\u0026argError语法来建立一个新的结构体 //提供arg和prob两个字段的值 return -1, \u0026argError{arg, \"can't work with it\"} } return arg+3, nil } func main() { //下面两个循环测试了各个返回错误的函数 //注意在if行内的错误检查代码，在Go中是一个普遍的用法 for _, i := range []int{7, 42}{ if r, e := f1(i); e != nil { fmt.Println(\"f1 failed: \", e) } else { fmt.Println(\"f1 worked: \", r) } } for _, i := range []int{7, 42} { if r, e := f2(i); e != nil { fmt.Println(\"f2 failed: \", e) } else { fmt.Println(\"f2 worked: \", r) } } //如果想在程序中使用一个自定义错误类型中的数据 //需要通过类型断言来得到这个错误类型的实例 _, e := f2(42) if ae, ok := e.(*argError); ok { fmt.Println(ae.arg) fmt.Println(ae.prob) } } ","date":"2021-02-18","objectID":"/go-study-12/:8:1","tags":["golang"],"title":"Go Study 12","uri":"/go-study-12/"},{"categories":["学习"],"content":"Go Study 11-函数与闭包","date":"2021-02-18","objectID":"/go-study-11/","tags":["golang"],"title":"Go Study 11","uri":"/go-study-11/"},{"categories":["学习"],"content":"函数与闭包 ","date":"2021-02-18","objectID":"/go-study-11/:1:0","tags":["golang"],"title":"Go Study 11","uri":"/go-study-11/"},{"categories":["学习"],"content":"函数式编程 vs 函数指针 函数式一等公民：参数，变量，返回值都可以是函数 高阶函数 函数 -\u003e 闭包 ","date":"2021-02-18","objectID":"/go-study-11/:1:1","tags":["golang"],"title":"Go Study 11","uri":"/go-study-11/"},{"categories":["学习"],"content":"“正统”函数式编程 不可变性：不能有状态，只有常量和函数 函数只能有一个参数 ","date":"2021-02-18","objectID":"/go-study-11/:1:2","tags":["golang"],"title":"Go Study 11","uri":"/go-study-11/"},{"categories":["学习"],"content":"go 语言闭包的应用 更为自然，不需要修饰如何访问自由变量 没有Lambda表达式，但是有匿名函数 闭包与函数\u0026ldquo;闭包与函数\u0026rdquo; \"\r闭包与函数\r ","date":"2021-02-18","objectID":"/go-study-11/:1:3","tags":["golang"],"title":"Go Study 11","uri":"/go-study-11/"},{"categories":["学习"],"content":"案例 ","date":"2021-02-18","objectID":"/go-study-11/:2:0","tags":["golang"],"title":"Go Study 11","uri":"/go-study-11/"},{"categories":["学习"],"content":"基本函数 函数是Go的中心 package main import \"fmt\" //这里是一个函数，接受两个int，并以int返回它们的和 func plus(a, b int) int { //Go需要明确的返回值 return a+b } func main() { //通过name(args)来调用一个函数 result := plus(1, 2) fmt.Println(result) } ","date":"2021-02-18","objectID":"/go-study-11/:2:1","tags":["golang"],"title":"Go Study 11","uri":"/go-study-11/"},{"categories":["学习"],"content":"多返回值函数 Go内建多返回值支持。这个特性在Go语言中经常被用到，例如用来同时返回一个函数的结果和错误信息 package main import \"fmt\" //(int, int)在这个函数中标志着这个函数返回2个int func vals() (int, int) { return 3, 7 } func main() { //通过多赋值操作来使用两个不同的返回值 a, b := vals() fmt.Println(a) fmt.Println(b) //如果想返回一部分值，可以使用空白定义符_ _, c := vals() fmt.Println(c) } ","date":"2021-02-18","objectID":"/go-study-11/:2:2","tags":["golang"],"title":"Go Study 11","uri":"/go-study-11/"},{"categories":["学习"],"content":"可变参数函数 可变参数函数。可以用任意数量的参数调用。例如，fmt.Println是一个常见的变参函数 package main import \"fmt\" //这个函数使用任意数目的int作为参数 func sum(nums ...int) { fmt.Print(nums, \" \") total := 0 for _, num := range nums { total += num } fmt.Println(total) } func main() { //变参函数使用常规的调用方法，除了参数比较特殊 sum(1, 2) sum(1, 2, 3) //如果slice已经有多个值，想作为变参使用，可以这样调用func(slice...) nums := []int{1, 2, 3, 4, 5} sum(nums...) } ","date":"2021-02-18","objectID":"/go-study-11/:2:3","tags":["golang"],"title":"Go Study 11","uri":"/go-study-11/"},{"categories":["学习"],"content":"闭包 Go支持通过闭包来使用匿名函数。匿名函数在你想定义一个不需要命名的内联函数时很实用 package main import \"fmt\" //这个intSeq函数返回另一个在intSeq函数体内定义的匿名函数 //这个函数的返回使用闭包的方式 隐藏 变量 i func intSeq() func() int { i := 0 return func() int { i += 1 return i } } func main() { //调用nextInt函数，将返回值(也是一个函数)赋给nextInt //这个函数的值包含了自己的值i，在每次调用nextInt都会更新i nextInt := intSeq() //多次调用闭包，查看效果 fmt.Println(nextInt()) fmt.Println(nextInt()) fmt.Println(nextInt()) fmt.Println(nextInt()) fmt.Println(nextInt()) //更换函数，确定每个函数的i是独立的 nextInts := intSeq() fmt.Println(nextInts()) } ","date":"2021-02-18","objectID":"/go-study-11/:2:4","tags":["golang"],"title":"Go Study 11","uri":"/go-study-11/"},{"categories":["学习"],"content":"递归函数 Go支持递归，这是一个经典的阶乘案例 package main import \"fmt\" //fact函数在到达fact(0)前一直在调用自身 func fact(n int) int { if n == 0 { return 1 } return n * fact(n-1) } func main() { fmt.Println(fact(5)) } ","date":"2021-02-18","objectID":"/go-study-11/:2:5","tags":["golang"],"title":"Go Study 11","uri":"/go-study-11/"},{"categories":["学习"],"content":"Go Study 10-接口","date":"2021-02-17","objectID":"/go-study-10/","tags":["golang"],"title":"Go Study 10","uri":"/go-study-10/"},{"categories":["学习"],"content":"接口 接口由使用者定义 ","date":"2021-02-17","objectID":"/go-study-10/:1:0","tags":["golang"],"title":"Go Study 10","uri":"/go-study-10/"},{"categories":["学习"],"content":"duck typing “像鸭子走路，像鸭子叫(长得像鸭子)，那么就是鸭子” 描述事物的外部行为而非内部结构 严格来说go属于结构化类型系统，类似duck typing ","date":"2021-02-17","objectID":"/go-study-10/:2:0","tags":["golang"],"title":"Go Study 10","uri":"/go-study-10/"},{"categories":["学习"],"content":"接口变量里有什么 接口变量1\u0026ldquo;接口变量1\u0026rdquo; \"\r接口变量1\r 接口变量2\u0026ldquo;接口变量2\u0026rdquo; \"\r接口变量2\r 接口变量自带指针 接口变量同样采用值传递，几乎不需要使用接口的指针 指针接收者实现只能以指针方式使用；值接收者都可以 ","date":"2021-02-17","objectID":"/go-study-10/:3:0","tags":["golang"],"title":"Go Study 10","uri":"/go-study-10/"},{"categories":["学习"],"content":"查看接口变量 表示任何变量：interface{} Type Assertion Type Switch ","date":"2021-02-17","objectID":"/go-study-10/:4:0","tags":["golang"],"title":"Go Study 10","uri":"/go-study-10/"},{"categories":["学习"],"content":"特殊接口 Stringer Reader/Writer ","date":"2021-02-17","objectID":"/go-study-10/:5:0","tags":["golang"],"title":"Go Study 10","uri":"/go-study-10/"},{"categories":["学习"],"content":"案例 ","date":"2021-02-17","objectID":"/go-study-10/:6:0","tags":["golang"],"title":"Go Study 10","uri":"/go-study-10/"},{"categories":["学习"],"content":"接口 接口：Go语言中组织和命名相关的方法集合的机制。接口是方法特征的命名集合 package main import ( \"fmt\" \"math\" ) //这里是一个几何体的基本接口 type geometry interface { area() float64 perim() float64 } //这个例子中，将让rect和circle实现这个接口 type rect struct { width float64 height float64 } type circle struct { radius float64 } //在Go中实现接口，需要实现这个接口的所有方法 //rect实现接口 func (r rect) area() float64 { return r.width * r.height } func (r rect) perim() float64 { return 2*r.width + 2*r.height } //circle实现接口 func (c circle) area() float64 { return math.Pi * c.radius * c.radius } func (c circle) perim() float64 { return math.Pi * c.radius * 2 } //如果有一个变量是接口类型，可以调用这个被命名接口的方法 //这里有一个通用的measure函数，利用特性，可以用在任何geometry(几何学)上 func measure(g geometry) { fmt.Println(g) fmt.Println(g.area()) fmt.Println(g.perim()) } func main() { r := rect{width: 3, height: 4} c := circle{radius: 5} //结构体类型circle和rect都实现了geometry接口 //所以可以使用他们的实例作为measure的参数 measure(r) measure(c) } ","date":"2021-02-17","objectID":"/go-study-10/:6:1","tags":["golang"],"title":"Go Study 10","uri":"/go-study-10/"},{"categories":["学习"],"content":"Go Study 09-GOPATH","date":"2021-02-17","objectID":"/go-study-09/","tags":["golang"],"title":"Go Study 09","uri":"/go-study-09/"},{"categories":["学习"],"content":"GOPATH环境变量 默认在~/go(unix，linux)，%USERPOFILE%\\go(windows) 官方推荐：所有项目和第三方库都放在同一个GOPATH下 也可以将每个项目放在不同的GOPATH ","date":"2021-02-17","objectID":"/go-study-09/:1:0","tags":["golang"],"title":"Go Study 09","uri":"/go-study-09/"},{"categories":["学习"],"content":"go get 获取第三方库 go get + 包(github可以，golang不行) 使用gopm来获取无法下载的包 go get -v github.com/gpmgo/gopm ","date":"2021-02-17","objectID":"/go-study-09/:2:0","tags":["golang"],"title":"Go Study 09","uri":"/go-study-09/"},{"categories":["学习"],"content":"GOPATH下目录结构 go build来编译 go install 产生pkg文件和可执行文件 go run 直接编译运行 ","date":"2021-02-17","objectID":"/go-study-09/:3:0","tags":["golang"],"title":"Go Study 09","uri":"/go-study-09/"},{"categories":["学习"],"content":"GOPATH下目录结构 src git repository 1 git repository 2 pkg git repository 1 git repository 2 bin 执行文件1,2,3… ","date":"2021-02-17","objectID":"/go-study-09/:4:0","tags":["golang"],"title":"Go Study 09","uri":"/go-study-09/"},{"categories":["学习"],"content":"Go Study 08-封装","date":"2021-02-16","objectID":"/go-study-08/","tags":["golang"],"title":"Go Study 08","uri":"/go-study-08/"},{"categories":["学习"],"content":"封装 名字一般使用CamelCase 首字母大写：public 首字母小写：private ","date":"2021-02-16","objectID":"/go-study-08/:1:0","tags":["golang"],"title":"Go Study 08","uri":"/go-study-08/"},{"categories":["学习"],"content":"包 每个目录一个包 main包包含可执行入口 为结构定义的方法必须放在同一个包内 可以是不同文件 ","date":"2021-02-16","objectID":"/go-study-08/:2:0","tags":["golang"],"title":"Go Study 08","uri":"/go-study-08/"},{"categories":["学习"],"content":"如何扩充系统类型或者别人的类型 定义别名 使用组合 ","date":"2021-02-16","objectID":"/go-study-08/:2:1","tags":["golang"],"title":"Go Study 08","uri":"/go-study-08/"},{"categories":["学习"],"content":"Go Study 07-面向对象，struct","date":"2021-02-16","objectID":"/go-study-07/","tags":["golang"],"title":"Go Study 07","uri":"/go-study-07/"},{"categories":["学习"],"content":"面向对象 go语言仅支持封装，不支持继承和多态 go语言没有class，只有struct ","date":"2021-02-16","objectID":"/go-study-07/:1:0","tags":["golang"],"title":"Go Study 07","uri":"/go-study-07/"},{"categories":["学习"],"content":"结构的创建 type treeNode struct { value int left, right *treeNode } //自定义工厂函数 func createNode(value int) *treeNode { //返回局部变量地址 return \u0026treeNode{value: value} } func main() { var root treeNode fmt.Println(root) root = treeNode{value: 3} root.left = \u0026treeNode{} root.right = \u0026treeNode{5, nil, nil} root.right.left = new(treeNode) root.left.right = createNode(2) } 不论地址还是结构本身，一律使用.来访问成员 使用自定义工厂函数(createNode) 注意返回了局部变量的地址 ","date":"2021-02-16","objectID":"/go-study-07/:2:0","tags":["golang"],"title":"Go Study 07","uri":"/go-study-07/"},{"categories":["学习"],"content":"为结构定义方法 func (node treeNode) print() { fmt.Println(node.value) } 显示定义和命名方法接受者 ","date":"2021-02-16","objectID":"/go-study-07/:3:0","tags":["golang"],"title":"Go Study 07","uri":"/go-study-07/"},{"categories":["学习"],"content":"使用指针作为方法接受者 func (node *treeNode) setValue(value int) { node.value = value } 只有使用指针才可以改变结构内容 nil指针也可以调用方法 ","date":"2021-02-16","objectID":"/go-study-07/:4:0","tags":["golang"],"title":"Go Study 07","uri":"/go-study-07/"},{"categories":["学习"],"content":"值接受者 vs 指针接受者 要改变内容必须使用指针接收者 结构过大也考虑使用指针接收者(因为值接收者使用时会拷贝一份，结构过大拷贝代价也大) 一致性：如有指针接收者，最好都使用指针接收者 很简单的不可变对象使用值接收者可以减轻GC负担(太多的指针会增加垃圾服务器GC的负担) 值接收者是go语言特有 值/指针接收者均可接收值/指针 ","date":"2021-02-16","objectID":"/go-study-07/:5:0","tags":["golang"],"title":"Go Study 07","uri":"/go-study-07/"},{"categories":["学习"],"content":"案例 ","date":"2021-02-16","objectID":"/go-study-07/:6:0","tags":["golang"],"title":"Go Study 07","uri":"/go-study-07/"},{"categories":["学习"],"content":"结构体 Go的结构体是各个字段 字段类型的集合 package main import \"fmt\" type person struct { name string age int } func main() { //使用这个语法创建一个新的结构体函数 fmt.Println(person{\"Bob\", 20}) //可以在初始化一个结构体元素时指定字段名 fmt.Println(person{name:\"Alice\", age:18}) //省略的字段将被初始化为零值 fmt.Println(person{name:\"Fred\"}) //\u0026前缀生成一个结构体指针 fmt.Println(\u0026person{name:\"Ann\", age:40}) //使用点来访问结构体字段 s := person{name:\"Sean\", age:50} fmt.Println(s.name) fmt.Println(s.age) //也可以对结构体指针引用，指针会被自动解引用 sp := \u0026s fmt.Println(sp.age) //结构体是可变的 sp.age = 51 fmt.Println(s.age) s.age = 52 fmt.Println(s.age) } ","date":"2021-02-16","objectID":"/go-study-07/:6:1","tags":["golang"],"title":"Go Study 07","uri":"/go-study-07/"},{"categories":["学习"],"content":"方法 Go支持在结构体类型中定义方法 package main import \"fmt\" type rect struct { wight int height int } //area方法有一个接收器类型rect来计算矩形面积 func (r rect) area() int { return r.height * r.wight } //可以为值或指针类型的接收器定义方法，这是个值类型接收器 //计算矩形周长 func (r rect) perim() int { return 2*r.wight + 2*r.height } //指针类型接收器可以改变实际值 func (r *rect) changeH(val int) { r.height = val } //值类型接收器改变拷贝值 func (r rect) changeW(val int) { r.wight = val } func main() { r := rect{10, 5} //调用上面为结构体定义的方法 fmt.Println(r.area()) fmt.Println(r.perim()) r.changeH(20) r.changeW(15) fmt.Println(r) //Go自动处理方法调用时值和指针之间的转换 //可以使用指针来调用方法避免在方法调用时产生一个拷贝或让方法能够改变接收的数据 rp := \u0026r rp.changeH(25) rp.changeW(30) fmt.Println(rp.area()) fmt.Println(rp.perim()) } ","date":"2021-02-16","objectID":"/go-study-07/:6:2","tags":["golang"],"title":"Go Study 07","uri":"/go-study-07/"},{"categories":["学习"],"content":"值和指针 Go支持指针，允许在程序中通过引用传递值或数据结构 package main import \"fmt\" //通过两个不同的函数来比较值和指针类型的不同 //zeroVal有一个int型参数，所以使用值传递 //zeroVal将从调用它的函数中获得一个ival形参的拷贝 func zeroVal(ival int) { ival = 0 } //zeroPtr和上面不同是*int，意味着它使用的是指针 //函数体内的*iptr接着解引用这个指针，从它内存地址得到这个地址当前值 //对一个解引用指针进行赋值会改变这个指针引用的真实地址的值 func zeroPtr(iptr *int) { *iptr = 0 } func main() { i := 1 fmt.Println(\"initial: \", i) zeroVal(i) fmt.Println(\"zeroVal: \", i) //通过\u0026i语法来获取i的内存地址 zeroPtr(\u0026i) //指针也是可以被打印的 fmt.Println(\"zeroPtr: \", i) fmt.Println(\"point: \", \u0026i) } ","date":"2021-02-16","objectID":"/go-study-07/:6:3","tags":["golang"],"title":"Go Study 07","uri":"/go-study-07/"},{"categories":["学习"],"content":"Go Study 06-rune字符串","date":"2021-02-16","objectID":"/go-study-06/","tags":["golang"],"title":"Go Study 06","uri":"/go-study-06/"},{"categories":["学习"],"content":"rune相当于go的char ","date":"2021-02-16","objectID":"/go-study-06/:1:0","tags":["golang"],"title":"Go Study 06","uri":"/go-study-06/"},{"categories":["学习"],"content":"使用range遍历pos，rune对 s := \"Yes我是你爸爸!\" for _, b := range []byte(s) { fmt.Printf(\"%X \", b) } fmt.Println() for i, ch := range s { fmt.Printf(\"(%d %X) \", i, ch) } ","date":"2021-02-16","objectID":"/go-study-06/:1:1","tags":["golang"],"title":"Go Study 06","uri":"/go-study-06/"},{"categories":["学习"],"content":"使用utf8.RuneCountInString获得字符数量 fmt.Println(\"Rune count:\", utf8.RuneCountInString(s)) ","date":"2021-02-16","objectID":"/go-study-06/:1:2","tags":["golang"],"title":"Go Study 06","uri":"/go-study-06/"},{"categories":["学习"],"content":"使用len获得字节长度 fmt.Println(len(s)) ","date":"2021-02-16","objectID":"/go-study-06/:1:3","tags":["golang"],"title":"Go Study 06","uri":"/go-study-06/"},{"categories":["学习"],"content":"使用[]byte获得字节 bytes := []byte(s) for len(bytes) \u003e 0 { ch, size := utf8.DecodeRune(bytes) bytes = bytes[size:] fmt.Printf(\"%c \", ch) } ","date":"2021-02-16","objectID":"/go-study-06/:1:4","tags":["golang"],"title":"Go Study 06","uri":"/go-study-06/"},{"categories":["学习"],"content":"其他字符串操作 ","date":"2021-02-16","objectID":"/go-study-06/:2:0","tags":["golang"],"title":"Go Study 06","uri":"/go-study-06/"},{"categories":["学习"],"content":"Fields，Split，Join ","date":"2021-02-16","objectID":"/go-study-06/:2:1","tags":["golang"],"title":"Go Study 06","uri":"/go-study-06/"},{"categories":["学习"],"content":"Contains，Index ","date":"2021-02-16","objectID":"/go-study-06/:2:2","tags":["golang"],"title":"Go Study 06","uri":"/go-study-06/"},{"categories":["学习"],"content":"ToLower，ToUpper ","date":"2021-02-16","objectID":"/go-study-06/:2:3","tags":["golang"],"title":"Go Study 06","uri":"/go-study-06/"},{"categories":["学习"],"content":"Trim，TrimRight，TrimLeft","date":"2021-02-16","objectID":"/go-study-06/:2:4","tags":["golang"],"title":"Go Study 06","uri":"/go-study-06/"},{"categories":["学习"],"content":"Go Study 05-leetcode例题","date":"2021-02-16","objectID":"/go-study-05/","tags":["golang"],"title":"Go Study 05","uri":"/go-study-05/"},{"categories":["学习"],"content":"寻找最长不含有重复字符的子串 abcabcbb -\u003e abc bbbbb -\u003e b pwwkew -\u003ewke func lenthofNonRepeatingSubStr(s string) int { lastOccurred := make(map[rune]int) start := 0 maxLength := 0 for i, ch := range []rune (s){ if lastI, ok := lastOccurred[ch]; ok \u0026\u0026 lastI \u003e= start { fmt.Println(lastI) fmt.Println(ok) start = lastI + 1 } if i-start+1 \u003e maxLength { maxLength = i-start+1 } lastOccurred[ch] = i } return maxLength } ","date":"2021-02-16","objectID":"/go-study-05/:1:0","tags":["golang"],"title":"Go Study 05","uri":"/go-study-05/"},{"categories":["学习"],"content":"Go Study 04-数组、切片和容器","date":"2021-02-15","objectID":"/go-study-04/","tags":["golang"],"title":"Go Study 04","uri":"/go-study-04/"},{"categories":["学习"],"content":"数组 var arr1 [5]int arr2 := [3]int{1,3,5} arr3 := [...]int{2,4,6,8,10} var grid [4][5]int 数量写在类型前 ","date":"2021-02-15","objectID":"/go-study-04/:1:0","tags":["golang"],"title":"Go Study 04","uri":"/go-study-04/"},{"categories":["学习"],"content":"数组的遍历 长度遍历 for i := 0; i \u003c len(arr3); i++ { fmt.Println(arr3[i]) } range只取index for i := range arr3 { fmt.Println(arr3[i]) } range取index和value maxi := -1 maxnum := -1 for i, v := range arr3{ if v \u003e maxnum { maxi = i maxnum = v } } fmt.Println(maxi, maxnum) range只取value sum := 0 for _, v := range arr3 { sum += v } 可以通过_省略变量 不仅range，任何地方都可以通过_省略变量 如果只要i，可写成 for i := range numbers ","date":"2021-02-15","objectID":"/go-study-04/:2:0","tags":["golang"],"title":"Go Study 04","uri":"/go-study-04/"},{"categories":["学习"],"content":"为什么要用range 意义明确，美观 ","date":"2021-02-15","objectID":"/go-study-04/:3:0","tags":["golang"],"title":"Go Study 04","uri":"/go-study-04/"},{"categories":["学习"],"content":"数组是值类型 [10]int 和[20]int 是不同类型 调用func f(arr [10]int) 会拷贝数组 在go语言中一般不直接使用数组 ","date":"2021-02-15","objectID":"/go-study-04/:4:0","tags":["golang"],"title":"Go Study 04","uri":"/go-study-04/"},{"categories":["学习"],"content":"Slice(切片) arr := [...]int{0, 1, 2, 3, 4, 5, 6, 7} s := arr[2:6] s的值为[2 3 4 5] arr := [...]int{0, 1, 2, 3, 4, 5, 6, 7} s := arr[2:6] s[0] = 10 Slice 本身没有数据，是对底层array的一个view arr 的值变为[0 1 10 3 4 5 6 7] ","date":"2021-02-15","objectID":"/go-study-04/:5:0","tags":["golang"],"title":"Go Study 04","uri":"/go-study-04/"},{"categories":["学习"],"content":"Reslice s := arr[2:6] s = s[:3] s = s[1:] s = arr[:] ","date":"2021-02-15","objectID":"/go-study-04/:6:0","tags":["golang"],"title":"Go Study 04","uri":"/go-study-04/"},{"categories":["学习"],"content":"Slice 的实现 slice的实现\u0026ldquo;slice的实现\u0026rdquo; \"\rslice的实现\r ","date":"2021-02-15","objectID":"/go-study-04/:7:0","tags":["golang"],"title":"Go Study 04","uri":"/go-study-04/"},{"categories":["学习"],"content":"Slice 的扩展 arr := [...]int{0, 1, 2, 3, 4, 5, 6, 7} s1 := arr[2:6] s2 := arr[3:5] s1 的值为[2 3 4 5]，s2 的值为[5 6] slice 可以向后扩展，不可以向前扩展 s[i] 不可以超越 len(s)，向后扩展不可以超越底层数组cap(s) ","date":"2021-02-15","objectID":"/go-study-04/:8:0","tags":["golang"],"title":"Go Study 04","uri":"/go-study-04/"},{"categories":["学习"],"content":"向Slice 添加元素 添加元素时如果超越cap，系统就会重新分配更大的底层数组 由于值传递的关系，必须接受append的返回值 s = append(s, val) ","date":"2021-02-15","objectID":"/go-study-04/:9:0","tags":["golang"],"title":"Go Study 04","uri":"/go-study-04/"},{"categories":["学习"],"content":"创建Slice ","date":"2021-02-15","objectID":"/go-study-04/:10:0","tags":["golang"],"title":"Go Study 04","uri":"/go-study-04/"},{"categories":["学习"],"content":"创建一个前99个奇数 var s []int for i := 0; i \u003c 100; i++ { s = append(s, 2*i+1) } ","date":"2021-02-15","objectID":"/go-study-04/:10:1","tags":["golang"],"title":"Go Study 04","uri":"/go-study-04/"},{"categories":["学习"],"content":"创建一个确定的切片 s1 := []int{2, 4, 6, 8} ","date":"2021-02-15","objectID":"/go-study-04/:10:2","tags":["golang"],"title":"Go Study 04","uri":"/go-study-04/"},{"categories":["学习"],"content":"创建一个len为16的切片 s2 := make([]int, 16) ","date":"2021-02-15","objectID":"/go-study-04/:10:3","tags":["golang"],"title":"Go Study 04","uri":"/go-study-04/"},{"categories":["学习"],"content":"创建一个len为10，cap为32的切片 s3 := make([]int, 10, 32) ","date":"2021-02-15","objectID":"/go-study-04/:10:4","tags":["golang"],"title":"Go Study 04","uri":"/go-study-04/"},{"categories":["学习"],"content":"复制切片 copy(s2, s1) ","date":"2021-02-15","objectID":"/go-study-04/:11:0","tags":["golang"],"title":"Go Study 04","uri":"/go-study-04/"},{"categories":["学习"],"content":"删除切片的元素 ","date":"2021-02-15","objectID":"/go-study-04/:12:0","tags":["golang"],"title":"Go Study 04","uri":"/go-study-04/"},{"categories":["学习"],"content":"删除切片里的一个元素(删除s2的第四个元素) s2 = append(s2[:3], s2[4:]...) ","date":"2021-02-15","objectID":"/go-study-04/:12:1","tags":["golang"],"title":"Go Study 04","uri":"/go-study-04/"},{"categories":["学习"],"content":"删除切片第一个元素 s2 = s2[1:] ","date":"2021-02-15","objectID":"/go-study-04/:12:2","tags":["golang"],"title":"Go Study 04","uri":"/go-study-04/"},{"categories":["学习"],"content":"删除切片最后一个元素 s2 = s2[:len(s2)-1] ","date":"2021-02-15","objectID":"/go-study-04/:12:3","tags":["golang"],"title":"Go Study 04","uri":"/go-study-04/"},{"categories":["学习"],"content":"Map m := map[string]string { \"name\": \"cc\", \"course\": \"golang\", \"site\": \"im\", \"quality\": \"notbad\" } map[K]V, map[K1]map[K2]V ","date":"2021-02-15","objectID":"/go-study-04/:13:0","tags":["golang"],"title":"Go Study 04","uri":"/go-study-04/"},{"categories":["学习"],"content":"Map的操作 ","date":"2021-02-15","objectID":"/go-study-04/:14:0","tags":["golang"],"title":"Go Study 04","uri":"/go-study-04/"},{"categories":["学习"],"content":"Map的遍历 使用range遍历key，或者遍历key，value对 for k, v := range m { fmt.Println(k, v) } 不保证遍历顺序，如需顺序，需手动对key排序 使用len来获得元素的个数 ","date":"2021-02-15","objectID":"/go-study-04/:14:1","tags":["golang"],"title":"Go Study 04","uri":"/go-study-04/"},{"categories":["学习"],"content":"创建：make(map[string]int) //m2 == empty m2 := make(map[string]int) //m3 == nil var m3 map[string]int ","date":"2021-02-15","objectID":"/go-study-04/:14:2","tags":["golang"],"title":"Go Study 04","uri":"/go-study-04/"},{"categories":["学习"],"content":"获取元素：map[key] name := m[\"name\"] ","date":"2021-02-15","objectID":"/go-study-04/:14:3","tags":["golang"],"title":"Go Study 04","uri":"/go-study-04/"},{"categories":["学习"],"content":"key不存在时，获得Value类型的初始值 name1 := m[\"name1\"] ","date":"2021-02-15","objectID":"/go-study-04/:14:4","tags":["golang"],"title":"Go Study 04","uri":"/go-study-04/"},{"categories":["学习"],"content":"用value, ok := map[key]来判断是否存在key if name1, ok := m[\"name1\"]; ok { fmt.Println(name1) } else { fmt.Println(\"key does not exist\") } ","date":"2021-02-15","objectID":"/go-study-04/:14:5","tags":["golang"],"title":"Go Study 04","uri":"/go-study-04/"},{"categories":["学习"],"content":"使用delete来删除一个元素 delete(m, \"age\") ","date":"2021-02-15","objectID":"/go-study-04/:14:6","tags":["golang"],"title":"Go Study 04","uri":"/go-study-04/"},{"categories":["学习"],"content":"Map的key map使用哈希表，必须可以比较相等 除了slice，map，function的内建类型都可以作为key Struct类型不包含上述字段，也可以作为key ","date":"2021-02-15","objectID":"/go-study-04/:15:0","tags":["golang"],"title":"Go Study 04","uri":"/go-study-04/"},{"categories":["学习"],"content":"案例 ","date":"2021-02-15","objectID":"/go-study-04/:16:0","tags":["golang"],"title":"Go Study 04","uri":"/go-study-04/"},{"categories":["学习"],"content":"数组 在Go中数组是一个固定长度的数列。在Go中相对于数组而言，slice使用更多 func arraySample() { //创建了一个数组a来存放刚好5个int。元素类型和长度是数组类型的一部分 //数组默认是零值 var a [5]int fmt.Println(a) //使用array[index] = value语法来设置数组指定位置的值 //使用array[index]来得到值 a[4] = 100 fmt.Println(a) fmt.Println(a[4]) //使用内置函数len返回数组的长度 fmt.Println(\"len: \", len(a)) //使用这个语法一行内初始化一个数组 b := [5]int{1, 2, 3, 4, 5} fmt.Println(\"dcl: \", b) //数组的存储类型是单一的，但是可以组合这些数据来构造多维的数据结构 var twoD [2][3]int for i := 0; i \u003c 2; i++ { for j := 0; j \u003c 3; j++ { twoD[i][j] = i + j } } fmt.Println(\"2d: \", twoD) } ","date":"2021-02-15","objectID":"/go-study-04/:16:1","tags":["golang"],"title":"Go Study 04","uri":"/go-study-04/"},{"categories":["学习"],"content":"切片 Slice是Go中一个关键的数据类型，是一个比数组更加强大的序列接口 func sliceSample() { //slice的类型仅由它所包含的元素决定(不像数组还需要元素个数) //创建一个长度非零的空slice，需要使用内建的方法 make //创建一个长度为3的string类型slice(初始化为零值) s := make([]string, 3) fmt.Println(\"emp: \", s) //通过slice[index] = value来设置值 //slice[index]来获取值 s[0] = \"a\" s[1] = \"b\" s[2] = \"c\" fmt.Println(s) fmt.Println(s[2]) //通过len来获取slice长度 fmt.Println(\"len: \", len(s)) //作为基本操作的补充，slice支持比数组更多的操作 //其中一个是内建的append，它返回一个包含一个或多个新值的slice //slice底层是由指针数组和len以及cap组成的，append不会改变slice地址 s = append(s, \"d\") s = append(s, \"e\", \"f\") fmt.Println(\"append: \", s) //slice可以被copy //这里新建一个空的和s相同长度的slice c，并将s复制给c c := make([]string, len(s)) copy(c, s) fmt.Println(\"copy c: \",c) //slice支持通过slice[low:high]语法进行切片处理 l := s[2:5] fmt.Println(\"切片之后2-5slice: \", l) //这个slice从s[0]到(包含)s[5] l = s[:5] fmt.Println(\"从s[0]到s[5]: \", l) //这个slice从s[2]到s最后一个值 l = s[2:] fmt.Println(\"从s[2]到slice最后一个值: \", l) //在一行代码中声明并初始化一个slice变量 t := []string{\"g\", \"h\", \"i\"} fmt.Println(\"dcl: \", t) //slice可以组成多维数据结构 twoD := make([][]int, 3) for i := 0; i \u003c 3; i++ { innerlen := 4 twoD[i] = make([]int, innerlen) for j := 0; j \u003c innerlen; j++ { twoD[i][j] = i + j } } fmt.Println(\"2d: \", twoD) } ","date":"2021-02-15","objectID":"/go-study-04/:16:2","tags":["golang"],"title":"Go Study 04","uri":"/go-study-04/"},{"categories":["学习"],"content":"关联数组 map是Go内置关联数据类型(在其他语言成为哈希或字典) func mapsSample() { //要创建一个空的map，需要使用内建的map1 := make(map[key-type]value-type) m := make(map[string]int) fmt.Println(m) //使用经典的map1[key] = value语法来设置键值对 m[\"k1\"] = 1 m[\"k2\"] = 2 fmt.Println(\"map: \", m) //使用map1[key]来获取一个键的值 v1 := m[\"k1\"] fmt.Println(v1) //当对一个map调用内建len，返回的是键值对数目 fmt.Println(\"len: \", len(m)) //内建的delete可以从一个map中移除键值对 delete(m, \"k2\") fmt.Println(\"delete\", m) //从一个map中取值时，可选第二个返回值是这个键是否存在于map中 //这个可以用来消除键不存在或键有零值产生的歧义 _, prs := m[\"k2\"] fmt.Println(\"prs: \", prs) //一行申明和初始化一个map n := map[string]int{\"foo\": 1, \"bar\": 2, \"zhang\": 3} fmt.Println(n) } ","date":"2021-02-15","objectID":"/go-study-04/:16:3","tags":["golang"],"title":"Go Study 04","uri":"/go-study-04/"},{"categories":["学习"],"content":"Go Study 03-循环语句","date":"2021-02-15","objectID":"/go-study-03/","tags":["golang"],"title":"Go Study 03","uri":"/go-study-03/"},{"categories":["学习"],"content":"for for的条件里不需要括号 for的条件里可以省略初始条件，结束条件，递增表达式 sum := 0 for i := 1; i \u003c= 100; i++ { sum += i } 省略初始条件，相当于while func convertToBin(n int) string { result := \"\" for ; n \u003e 0; n /= 2 { lsp := n % 2 result = strconv.Itoa(lsp) + result } return result } 省略初始条件和递增条件，也相当于while func printFile(filename string) { file, err := os.Open(filename) if err != nil { panic(err) } // 逐行读取file的内容 scanner := bufio.NewScanner(file) for scanner.Scan() { fmt.Println(scanner.Text()) } } 无限循环 func forever() { for { fmt.Println(\"abc\") } } ","date":"2021-02-15","objectID":"/go-study-03/:1:0","tags":["golang"],"title":"Go Study 03","uri":"/go-study-03/"},{"categories":["学习"],"content":"基本语法要点回顾 for, if后面的条件没有括号 if条件里也可以定义变量 没有while switch不需要break，也可以直接switch多个条件 ","date":"2021-02-15","objectID":"/go-study-03/:2:0","tags":["golang"],"title":"Go Study 03","uri":"/go-study-03/"},{"categories":["学习"],"content":"案例 func sample() { //1.最常用的方式，带单个循环条件 i := 1 for i \u003c= 3 { fmt.Println(i) i += 1 } //2.经典的初始化/条件/后续形式for循环 for j := 7; j \u003c= 9; j++ { fmt.Println(j) } //3.不带条件的for循环将一直执行，直到循环体内使用了break或者return来跳出循环 for { fmt.Println(\"loop\") break } } ","date":"2021-02-15","objectID":"/go-study-03/:3:0","tags":["golang"],"title":"Go Study 03","uri":"/go-study-03/"},{"categories":["学习"],"content":"Range遍历 range迭代各种各样的数据结构 func loopSample2() { //这里使用range来统计一个slice的元素个数，数组也采用这种方式 nums := []int{2,4,5,3} sum := 0 for _, num := range nums { sum += num } fmt.Println(\"sum: \", sum) //range在数组和slice中同样提供了每项的索引和值 //不需要索引时可以使用_来忽略她 for i, num := range nums { if num == 3 { fmt.Println(\"index: \", i) } } //range在map中迭代键值对 kvs := map[string]string{ \"name\": \"cc\", \"age\": \"18\", } for k, v := range kvs { fmt.Printf(\"%v -\u003e %v\\n\", k, v) } //range在字符串中迭代Unicode编码 for i, v := range \"go\" { fmt.Println(i, v) } } ","date":"2021-02-15","objectID":"/go-study-03/:3:1","tags":["golang"],"title":"Go Study 03","uri":"/go-study-03/"},{"categories":["学习"],"content":"Go Study 02-条件语句","date":"2021-02-15","objectID":"/go-study-02/","tags":["golang"],"title":"Go Study 02","uri":"/go-study-02/"},{"categories":["学习"],"content":"if if的条件里不需要括号 func bounded(v int) int { if v \u003e 100 { return 100 } else if v \u003c 0 { return 0 } else { return v } } if的条件里可以赋值 if contents, err := ioutil.ReadFile(filename); err != nil { fmt.Println(err) } else { fmt.Printf(\"%s\\n\", contents) } if条件里赋值的变量作用域就在这个if语句里 ","date":"2021-02-15","objectID":"/go-study-02/:1:0","tags":["golang"],"title":"Go Study 02","uri":"/go-study-02/"},{"categories":["学习"],"content":"switch switch会自动break，除非使用fallthrough func eval(a, b int, op string) int { var result int switch op { case \"+\": result = a + b case \"-\": result = a - b case \"*\": result = a * b case \"/\": result = a / b default: panic(\"unsupported operator:\" + op) } return result } switch后可以没有表达式 func grade(score int) string { g := \"\" switch { case score \u003c 60: g = \"D\" case score \u003c 80: g = \"C\" case score \u003c 90: g = \"B\" case score \u003c= 100: g = \"A\" default: panic(fmt.Sprintf(\"Wrong score: %d\", score)) } return g } ","date":"2021-02-15","objectID":"/go-study-02/:2:0","tags":["golang"],"title":"Go Study 02","uri":"/go-study-02/"},{"categories":["学习"],"content":"案例 ","date":"2021-02-15","objectID":"/go-study-02/:3:0","tags":["golang"],"title":"Go Study 02","uri":"/go-study-02/"},{"categories":["学习"],"content":"if/else分支 if和else分支结构在Go中当然是直接了当的了 func branchSample1() { if 7 % 2 == 0 { //7是偶数 fmt.Println(\"7 is even\") } else { //7是奇数 fmt.Println(\"7 is odd\") } //也可以不要else，只用if if 8 % 4 == 0 { fmt.Println(\"8 is divisible by 4\") } //在条件语句之前可以有一个语句，任何在这里声明的变量都可以在所有的条件分支中使用 if num := 9; num \u003c 0 { fmt.Println(num, \"is negative\") } else if num \u003c 10 { fmt.Println(num, \"has 1 digit\") } else { fmt.Println(num, \"has multiple digit\") } } ","date":"2021-02-15","objectID":"/go-study-02/:3:1","tags":["golang"],"title":"Go Study 02","uri":"/go-study-02/"},{"categories":["学习"],"content":"switch分支 func branchSample2() { //一个基本的switch i := 2 switch i { case 1: fmt.Println(\"one\") case 2: fmt.Println(\"two\") case 3: fmt.Println(\"three\") } //在一个case语句中可以使用逗号分割多个表达式 //使用了可选的default分支 switch time.Now().Weekday() { case time.Saturday, time.Sunday: fmt.Println(\"It's the weekend\") default: fmt.Println(\"It's a weekday\") } //不带表达式的switch是实现if/else的另一种方式 //这里展示了case表达式是如何使用非常量的 t := time.Now() switch { case t.Hour() \u003c 12: fmt.Println(\"it's before noon\") default: fmt.Println(\"it's after noon\") } } ","date":"2021-02-15","objectID":"/go-study-02/:3:2","tags":["golang"],"title":"Go Study 02","uri":"/go-study-02/"},{"categories":["学习"],"content":"Go Study 01-变量常量","date":"2021-02-15","objectID":"/go-study-01/","tags":["golang"],"title":"Go Study 01","uri":"/go-study-01/"},{"categories":["学习"],"content":"变量定义 ","date":"2021-02-15","objectID":"/go-study-01/:1:0","tags":["golang"],"title":"Go Study 01","uri":"/go-study-01/"},{"categories":["学习"],"content":"使用var关键字 var a,b,c bool var s1,s2 string = “hello”, “world” 可以放在函数内，或直接放在包内 使用var()集中定义变量 ","date":"2021-02-15","objectID":"/go-study-01/:1:1","tags":["golang"],"title":"Go Study 01","uri":"/go-study-01/"},{"categories":["学习"],"content":"让编译器自动决定类型 var a,b,i,s1,s2 = true, false, 3, “hello”, “world” ","date":"2021-02-15","objectID":"/go-study-01/:1:2","tags":["golang"],"title":"Go Study 01","uri":"/go-study-01/"},{"categories":["学习"],"content":"使用:=定义变量 a,b,i,s1,s2 := true, false, 3, “hello”, “world” 只能在函数内使用 ","date":"2021-02-15","objectID":"/go-study-01/:1:3","tags":["golang"],"title":"Go Study 01","uri":"/go-study-01/"},{"categories":["学习"],"content":"内建变量类型 bool, string (u)int, (u)int8, (u)int16, (u)int32, (u)int(64), uintptr(指针) byte, rune float32, float64, complex64, complex128 (complex是复数) ","date":"2021-02-15","objectID":"/go-study-01/:2:0","tags":["golang"],"title":"Go Study 01","uri":"/go-study-01/"},{"categories":["学习"],"content":"强制类型转换 类型转换是强制的 var a,b int = 3, 4 var int = math.Sqrt(aa + bb) (错误) var int = int(math.Sqrt(float64(aa + bb))) (正确) ","date":"2021-02-15","objectID":"/go-study-01/:3:0","tags":["golang"],"title":"Go Study 01","uri":"/go-study-01/"},{"categories":["学习"],"content":"常量定义 const filename = “abc.txt” const 数值可以作为各种类型使用 const a, b = 3, 4 var c int = int(math.Sqrt(aa + bb)) ","date":"2021-02-15","objectID":"/go-study-01/:4:0","tags":["golang"],"title":"Go Study 01","uri":"/go-study-01/"},{"categories":["学习"],"content":"使用常量定义枚举类型 普通枚举类型 const ( cpp = 1 java = 2 python = 3 golang = 4 ) 自增值枚举类型 const ( cpp = iota java python golang ) ","date":"2021-02-15","objectID":"/go-study-01/:5:0","tags":["golang"],"title":"Go Study 01","uri":"/go-study-01/"},{"categories":["学习"],"content":"变量定义要点回顾 变量类型写在变量名之后 编译器可推测变量类型 没有char，只有rune 原生支持复数类型 ","date":"2021-02-15","objectID":"/go-study-01/:6:0","tags":["golang"],"title":"Go Study 01","uri":"/go-study-01/"},{"categories":["学习"],"content":"案例 ","date":"2021-02-15","objectID":"/go-study-01/:7:0","tags":["golang"],"title":"Go Study 01","uri":"/go-study-01/"},{"categories":["学习"],"content":"值 Go拥有各值类型，包括字符串，整型，浮点型，布尔型等 func value() { //字符串通过+连接 fmt.Println(\"go\" + \"lang\") //浮点数和整数 fmt.Println(\"1+1=\", 1+1) fmt.Println(\"7.0/3.0=\", 7.0/3.0) //布尔型和逻辑运算符 fmt.Println(true \u0026\u0026 false) fmt.Println(true || false) fmt.Println(!true) } ","date":"2021-02-15","objectID":"/go-study-01/:7:1","tags":["golang"],"title":"Go Study 01","uri":"/go-study-01/"},{"categories":["学习"],"content":"变量 在Go中，变量被显式声明，并被编译器所用来检查函数调用时的类型正确性 func varible() { //声明一个变量 var a string = \"initial\" fmt.Println(a) //声明多个变量 var b, c int = 1, 2 fmt.Println(b, c) //Go 将自动推断已经初始化的变量类型 var d = true fmt.Printf(\"%T %v\\n\", d, d) //声明变量且没有给出对应初始值，变量会被初始化为零值 var e int fmt.Println(e) //:=语句是申明并初始化变量的简写 f := \"short\" fmt.Println(f) } ","date":"2021-02-15","objectID":"/go-study-01/:7:2","tags":["golang"],"title":"Go Study 01","uri":"/go-study-01/"},{"categories":["学习"],"content":"常量 Go支持字符、字符串、布尔和数值常量 func constant() { //const用于声明一个常量 const s = \"constant\" fmt.Println(\"s=\", s) //const语句可以出现在任何var语句可以出现的地方 const n = 500000000 fmt.Println(n) //常数表达式可以执行任意精度的运算 const d = 3e20 / n fmt.Println(\"d = 3e20/n : \", d) //数值型常量是没有确定的类型，直到他们被给定一个类型，比如说一次显示的类型转化 fmt.Println(\"int64(d) = \", int64(d)) //当上下文需要的时候，一个数可以被给定一个类型，比如变量赋值或函数调用 //举个栗子，这里的math.Sin()需要一个float64参数 fmt.Println(\"math.Sin(n) = \", math.Sin(n)) } ","date":"2021-02-15","objectID":"/go-study-01/:7:3","tags":["golang"],"title":"Go Study 01","uri":"/go-study-01/"},{"categories":["学习"],"content":"Linux Network 02","date":"2021-02-14","objectID":"/linux-network-02/","tags":["Linux网络编程"],"title":"Linux Network 02","uri":"/linux-network-02/"},{"categories":["学习"],"content":"Socket(套接字)编程 ","date":"2021-02-14","objectID":"/linux-network-02/:1:0","tags":["Linux网络编程"],"title":"Linux Network 02","uri":"/linux-network-02/"},{"categories":["学习"],"content":"套接字概念 在TCP/IP协议中，“IP地址+TCP或UDP端口号”唯一标识网络通讯中的一个进程。“IP地址+端口号”就对应一个socket。欲建立连接的两个进程各自有一个socket来标识，那么这两个socket组成的socket pair就唯一标识一个连接。因此可以用Socket来描述网络连接的一对一关系 socket通信原理socket通信原理 \"\rsocket通信原理\r 在网络通信中，套接字一定是成对出现的。一端的发送缓冲区对应对端的接收缓冲区。我们使用同一个文件描述符索发送缓冲区和接收缓冲区 ","date":"2021-02-14","objectID":"/linux-network-02/:1:1","tags":["Linux网络编程"],"title":"Linux Network 02","uri":"/linux-network-02/"},{"categories":["学习"],"content":"Linux Network 01","date":"2021-02-13","objectID":"/linux-network-01/","tags":["Linux网络编程"],"title":"Linux Network 01","uri":"/linux-network-01/"},{"categories":["学习"],"content":"协议的概念 ","date":"2021-02-13","objectID":"/linux-network-01/:1:0","tags":["Linux网络编程"],"title":"Linux Network 01","uri":"/linux-network-01/"},{"categories":["学习"],"content":"什么是协议？ 从应用的角度出发，协议可以理解为“规则”，是数据传输和数据解释的规则 ","date":"2021-02-13","objectID":"/linux-network-01/:1:1","tags":["Linux网络编程"],"title":"Linux Network 01","uri":"/linux-network-01/"},{"categories":["学习"],"content":"典型协议 传输层 常见的协议有TCP/UDP协议 应用层 常见的协议有HTTP/FTP协议 网络层 常见的协议有IP/ICMP/IGMP协议 网络接口层 常见的协议有ARP/RARP协议 TCP传输控制协议是一种面向连接的、可靠地、基于字节流的传输层通信协议 UDP用户数据报协议是OSI参考模型中一种无连接的传输层协议，提供面向事务的简单不可靠信息传送服务 HTTP超文本传输协议是互联网上应用最广泛的一种网络协议 FTP文件传输协议 IP协议是因特网互联协议 ICMP协议是Internet控制报文协议，它是TCP/IP协议族的一个子协议，用于在IP主机、路由器之间传递控制消息 IGMP协议是Internet组管理协议，是因特网协议家族中的一个组播协议。该协议运行在主机和组播路由器之间 ARP协议是正向地址解析协议，通过已知IP寻找对应主机的MAC地址 RARP协议是反向地址转换协议，通过MAC地址确定IP地址 ","date":"2021-02-13","objectID":"/linux-network-01/:1:2","tags":["Linux网络编程"],"title":"Linux Network 01","uri":"/linux-network-01/"},{"categories":["学习"],"content":"网络应用程序设计模式 ","date":"2021-02-13","objectID":"/linux-network-01/:2:0","tags":["Linux网络编程"],"title":"Linux Network 01","uri":"/linux-network-01/"},{"categories":["学习"],"content":"C/S模式 传统的网络应用设计模式，客户机(client)/服务器(server)模式。需要在通讯两端各自部署客户机和服务器来完成数据通信 ","date":"2021-02-13","objectID":"/linux-network-01/:2:1","tags":["Linux网络编程"],"title":"Linux Network 01","uri":"/linux-network-01/"},{"categories":["学习"],"content":"B/S模式 浏览器(Brower)/服务器(server)模式。只需要在一端部署服务器，而另一端使用每台PC都默认配置的浏览器即可完成数据的传输 ","date":"2021-02-13","objectID":"/linux-network-01/:2:2","tags":["Linux网络编程"],"title":"Linux Network 01","uri":"/linux-network-01/"},{"categories":["学习"],"content":"C/S优缺点 优点 1、协议选用灵活 2、数据可以提前缓存 缺点 1、对用户安全构成威胁 2、开发工作量较大 ","date":"2021-02-13","objectID":"/linux-network-01/:2:3","tags":["Linux网络编程"],"title":"Linux Network 01","uri":"/linux-network-01/"},{"categories":["学习"],"content":"B/S优缺点 优点 1、不会安装第三方软件，安全性高 2、只需要开发服务端，工作量减小 3、可以跨平台 缺点 1、需要支持HTTP协议 2、不能进行数据缓存 ","date":"2021-02-13","objectID":"/linux-network-01/:2:4","tags":["Linux网络编程"],"title":"Linux Network 01","uri":"/linux-network-01/"},{"categories":["学习"],"content":"分层模型 OSI参考模型 TCP/IP模型 应用层-- 表示层 |-\u003e 应用层 会话层-- 传输层 传输层 网络层 网络层 数据链路层-|-\u003e 网络接口层 物理层------ ","date":"2021-02-13","objectID":"/linux-network-01/:3:0","tags":["Linux网络编程"],"title":"Linux Network 01","uri":"/linux-network-01/"},{"categories":["学习"],"content":"OSI七层模型 1、物理层：主要定义物理设备标准，如网线的接口类型、光纤的接口类型、各种传输介质的传输速率等。他的主要作用是传输比特流 2、数据链路层：定义了如何让格式化数据以帧为单位进行传输，以及如何让控制对物理介质访问。这一层通常还提供错误检测和纠正，以确保数据的可靠传输 3、网络层：在位于不同地理位置的网络中的两个主机系统之间提供链接和路径选择。Internet的发展使得从世界各站点访问信息的用户数大大增加，而网络层正是管理这种连接的层 4、传输层：定义了一些传输数据的协议和端口号(www端口80等)，如：TCP(传输控制协议，传输效率低，可靠性强，用于传输可靠性要求高，数据量大的数据)，UDP(用户数据报协议，与TCP特性恰恰相反，用于传输可靠性要求不高，数据量小的数据，如QQ聊天数据就是通过这种方式传输的)。主要是将下层接受的数据进行分段和传输，达到目的地址后再进行重组，常常把这一层数据叫做段。 5、会话层：通过传输层(端口号：传输端口与接收端口)建立数据传输的通路。主要在你的系统之间发起会话或者接受会话请求(设备之间需要互相认识可以是IP也可以是MAC或者是主机名)。 6、表示层：可确保一个系统的应用层所发送的信息可以被另一个系统的应用读取。如：PC程序与另一台计算机进行通信，其中一台计算机使用扩展二一十进制交换码(EBCDIC)，而另一台则使用美国信息交换标准码(ASCII)来表示相同字符，如有必要，表示层会通过使用一种通格式来实现多种数据格式之间的转换。 7、应用层：是最靠近用户的OSI层，这一层为用户的应用程序(例如电子邮件、文件传输和终端仿真)提供网络服务 ","date":"2021-02-13","objectID":"/linux-network-01/:3:1","tags":["Linux网络编程"],"title":"Linux Network 01","uri":"/linux-network-01/"},{"categories":["学习"],"content":"TCP/IP四层模型 TCP/IP网络协议栈分为应用层、传输层、网络层、链路层四层 其中应用层典型的是FTP协议，传输层典型的是TCP或UDP协议，网络层典型的是IP协议，链路层典型的是以太网帧协议 TCP/IP模型TCP/IP模型 \"\rTCP/IP模型\r ","date":"2021-02-13","objectID":"/linux-network-01/:3:2","tags":["Linux网络编程"],"title":"Linux Network 01","uri":"/linux-network-01/"},{"categories":["学习"],"content":"通信过程 通信过程通信过程 \"\r通信过程\r ","date":"2021-02-13","objectID":"/linux-network-01/:4:0","tags":["Linux网络编程"],"title":"Linux Network 01","uri":"/linux-network-01/"},{"categories":["学习"],"content":"协议格式 ","date":"2021-02-13","objectID":"/linux-network-01/:5:0","tags":["Linux网络编程"],"title":"Linux Network 01","uri":"/linux-network-01/"},{"categories":["学习"],"content":"数据包封装 数据包封装TCP/IP数据包封装 \"\r数据包封装\r ","date":"2021-02-13","objectID":"/linux-network-01/:5:1","tags":["Linux网络编程"],"title":"Linux Network 01","uri":"/linux-network-01/"},{"categories":["学习"],"content":"java02","date":"2021-02-10","objectID":"/java02/","tags":["java"],"title":"Java02","uri":"/java02/"},{"categories":["学习"],"content":"标识符注意点 所有的标识符都应该以字母(A-Z或者a-z)，美元符($)或者下划线(_)开始 首字符之后可以是字母(A-Z或者a-z)，美元符($)，下划线(_)或数字的任何字符组合 不能使用关键字作为变量名或者方法名 标识符是大小写敏感的 合法标识符举例：age、$salary、_value、__1_value 非法标识符举例：123abc、-salary、#abc 可以使用中文命名，但是一般不建议这样去使用，也不建议使用拼音，很Low 数据类型 ","date":"2021-02-10","objectID":"/java02/:0:0","tags":["java"],"title":"Java02","uri":"/java02/"},{"categories":["学习"],"content":"强类型语言 要求变量的使用要严格符合规定，所有变量都必须先定义后才能使用 ","date":"2021-02-10","objectID":"/java02/:1:0","tags":["java"],"title":"Java02","uri":"/java02/"},{"categories":["学习"],"content":"弱类型语言 ","date":"2021-02-10","objectID":"/java02/:2:0","tags":["java"],"title":"Java02","uri":"/java02/"},{"categories":["学习"],"content":"java的数据类型分为两大类 基本类型(primitive type) 数值类型 整数类型 byte占一个字节范围：-128~127 short占两个字节范围：-32768~32767 int占四个字节范围：… long占八个字节范围：… 浮点类型 float占四个字节 double占八个字节 字符类型 char占两个字节 boolean类型：占一位其值只有true和false两个 引用类型(reference type) 类 接口 数组 什么是字节 位(bit)：是计算机内部数据储存的最小单位，11001100是一个八位二进制数 字节(byte)：是计算机数据处理的基本单位，习惯上用大写B来表示 1B(byte，字节) = 8bit(位) 字符：是指计算机中使用的字母、数字、字和符号 1bit表示1位 1Byte表示一个字节 1B=8b 1024B = 1KB 1024KB = 1M 1024M = 1G 类型转换 由于java是强类型语言，所以要进行有些运算的时候，需要用到类型转换 低-\u003e高 byte,short,char-\u003eint-\u003elong-\u003efloat-\u003edouble 运算中，不同的数据类型先转换成同一类型，然后进行运算 强制类型转换 (类型)变量名 高到低 自动类型转换 低到高 注意点： 1、不能对布尔值进行转换 2、不能把对象类型转换成不相关的类型 3、在把高容量转换成低容量的时候，强制转换 4、转换的时候可能存在内存溢出或者精度问题 变量 变量是什么？ 变量就是可以变化的量 java是一种强类型语言，每个变量都必须声明其类型。 java变量是程序中最基本的存储单元，其要素包括变量名，变量类型和作用域 注意事项： 每个变量都有类型，类型可以是基本类型，也可以是引用类型 变量名必须是合法的标识符 变量声明是一条完整的语句，因此每一个声明都必须以分号结束 变量的命名规范 所有变量、方法、类名：见名知意 类成员变量：首字母小写和驼峰原则：monthSalary 局部变量：首字母小写和驼峰原则 常量：大写字母和下划线：MAX_VALUE 类名：首字母大写和驼峰原则：Man，GoodMan 方法名：首字母小写和驼峰原则：run()，runRun() 常量 常量(Constant)：初始化(initialize)后不能再改变值！不会变动的值 所谓常量可以理解为一种特殊的变量，它的值被设定后，在程序运行过程中不允许被改变 final 常量名 = 值; 常量名一般使用大写字符 ","date":"2021-02-10","objectID":"/java02/:3:0","tags":["java"],"title":"Java02","uri":"/java02/"},{"categories":["学习"],"content":"java01","date":"2021-02-09","objectID":"/java01/","tags":["java"],"title":"Java01","uri":"/java01/"},{"categories":["学习"],"content":"java是一门跨平台语言(jvm虚拟机) java特性和优势 简单性 面向对象 可移植性(write once, run anywhere) 高性能 分布式 动态性 多线程 安全性 健壮性 java三大版本 javaSE：标准版(桌面程序，控制台开发…) javaME：嵌入式开发(手机，小家电…) javaEE：E企业级开发(web端，服务器开发…) JDK、JRE、JVM JDK：Java Development Kit(java开发者工具) JRE：Java Runtime Environment(java运行时环境) JVM：Java Virtual Machine(java虚拟机) JDK\u003eJRE\u003eJVM","date":"2021-02-09","objectID":"/java01/:0:0","tags":["java"],"title":"Java01","uri":"/java01/"},{"categories":["学习"],"content":"dos常用命令","date":"2021-02-08","objectID":"/dos-code/","tags":["dos"],"title":"Dos Code","uri":"/dos-code/"},{"categories":["学习"],"content":"盘符切换 切换到C盘： c: 切换到E盘： e: 查看当前目录下的所有文件 dir 切换目录 cd change directory cd .. 清理屏幕 cls 退出终端 exit 查看电脑ip ipconfig 打开应用 calc mspaint notepad ping命令 ping 192.168.1.* 文件操作 创建一个文件夹：md 目录名 移除一个文件夹：rd 目录名 创建一个文件： cd\u003e 文件名 移除一个文件： del 文件名","date":"2021-02-08","objectID":"/dos-code/:0:0","tags":["dos"],"title":"Dos Code","uri":"/dos-code/"},{"categories":["学习"],"content":"markdown学习01","date":"2021-02-07","objectID":"/markdown-study01/","tags":["markdown"],"title":"Markdown Study01","uri":"/markdown-study01/"},{"categories":["学习"],"content":"1 标题 ","date":"2021-02-07","objectID":"/markdown-study01/:0:0","tags":["markdown"],"title":"Markdown Study01","uri":"/markdown-study01/"},{"categories":["学习"],"content":"h2 标题 ","date":"2021-02-07","objectID":"/markdown-study01/:1:0","tags":["markdown"],"title":"Markdown Study01","uri":"/markdown-study01/"},{"categories":["学习"],"content":"h3 标题 h4 标题 h5 标题 h6 标题、 要添加自定义标题ID，请在与标题相同的行中将自定义ID放在花括号中 ###一个很棒的标题 {#custom-id} 2 注释 注释和HTML兼容的 3 水平线 HTML中的\u003chr\u003e标签是用来在段落元素之间创建一个“专题间隔”的 Markdown可以使用以下方式： -–：三个连续的破折号 ___：三个连续的下划线 ***：三个连续的星号 4 段落 HTML中将用\u003cp\u003e\u003c/p\u003e标签包裹 Markdown直接按照纯文本的方式书写段落 5 内联HTML元素 这是HTML 6 强调 ","date":"2021-02-07","objectID":"/markdown-study01/:1:1","tags":["markdown"],"title":"Markdown Study01","uri":"/markdown-study01/"},{"categories":["学习"],"content":"加粗 用于强调带有较粗字体的文本片段 以下文本会被渲染为粗体 **渲染为粗体** __渲染为粗体__ 输出的HTML看起来像这样 \u003cstrong\u003e渲染为粗体\u003c/strong\u003e ","date":"2021-02-07","objectID":"/markdown-study01/:2:0","tags":["markdown"],"title":"Markdown Study01","uri":"/markdown-study01/"},{"categories":["学习"],"content":"斜体 用于强调带有斜体的文本片段 以下文本片段被渲染成斜体 *渲染为斜体* _渲染为斜体_ 输出的HTML看起来像这样 \u003cem\u003e渲染为斜体\u003c/em\u003e ","date":"2021-02-07","objectID":"/markdown-study01/:3:0","tags":["markdown"],"title":"Markdown Study01","uri":"/markdown-study01/"},{"categories":["学习"],"content":"删除线 以下文本片段会被渲染成删除线 ~~这段文本带有删除线~~ 输出的HTML看起来像这样 \u003cdel\u003e这段文本带有删除线\u003c/del\u003e 这段文本带有删除线 ","date":"2021-02-07","objectID":"/markdown-study01/:4:0","tags":["markdown"],"title":"Markdown Study01","uri":"/markdown-study01/"},{"categories":["学习"],"content":"组合 加粗，斜体和删除线可以组合使用 ***加粗和斜体*** ~~**删除线和加粗**~~ ~~*删除和斜体*~~ ~~***加粗，斜体和删除线***~~ 输出的HTML看起来像这样 \u003cem\u003e\u003cstrong\u003e加粗和斜体\u003c/strong\u003e\u003c/em\u003e \u003cdel\u003e\u003cstrong\u003e删除线和加粗\u003c/strong\u003e\u003c/em\u003e \u003cdel\u003e\u003cem\u003e删除线和斜体\u003cem\u003e\u003c/del\u003e \u003cdel\u003e\u003cem\u003e\u003cstrong\u003e加粗，斜体和删除线\u003c/strong\u003e\u003c/em\u003e\u003c/del\u003e 加粗和斜体 删除线和加粗 删除和斜体 加粗，斜体和删除线 7 引用 用于在文档中引用其他来源的内容块 在要引用的任何文本之前添加\u003e: \u003e **Fusion Drive** combines a hard drive with a flash storage 输出的HTML看起来像这样 \u003cblockquote\u003e \u003cp\u003e \u003cstrong\u003eFusion Drive\u003c/strong\u003e combines a hard drive with a flash storage \u003c/p\u003e \u003c/blockquote\u003e 引用也可以嵌套 \u003e **Fusion Drive** combines a hard drive with a flash storage \u003e\u003e 111 Fusion Drive combines a hard drive with a flash storage 111 8 列表 ","date":"2021-02-07","objectID":"/markdown-study01/:5:0","tags":["markdown"],"title":"Markdown Study01","uri":"/markdown-study01/"},{"categories":["学习"],"content":"无序列表 一系列项的列表，其中项的顺序没有明显关系 你可以使用以下任何符号来表示无序列表中的项 * 一项内容 * 子内容 - 一项内容 + 一项内容 一项内容 子内容 一项内容 一项内容 ","date":"2021-02-07","objectID":"/markdown-study01/:6:0","tags":["markdown"],"title":"Markdown Study01","uri":"/markdown-study01/"},{"categories":["学习"],"content":"有序列表 一系列项的列表，其中项的顺序确实很重要 1. a 2. b 3. c 输出的HTML看起来像这样 \u003col\u003e \u003cli\u003ea\u003c/li\u003e \u003cli\u003eb\u003c/li\u003e \u003cli\u003ec\u003c/li\u003e \u003c/ol\u003e a b c ","date":"2021-02-07","objectID":"/markdown-study01/:7:0","tags":["markdown"],"title":"Markdown Study01","uri":"/markdown-study01/"},{"categories":["学习"],"content":"任务列表 任务列表使你可以创建带有复选框的列表，要创建列表，请在任务列表项之前添加破折号(-)和带有空格的方括号([ ])，要选择复选框，请在方括号之间添加x([x]) - [x] a - [ ] b - [ ] c Write the press release Update the website Contact the media 9 代码 ","date":"2021-02-07","objectID":"/markdown-study01/:8:0","tags":["markdown"],"title":"Markdown Study01","uri":"/markdown-study01/"},{"categories":["学习"],"content":"行内代码 用\\包装行内代码段 在这个例子中, \\\u003csection\u003e\\\u003c/section\u003e 会被包裹成 **代码**. \u003cp\u003e 在这个例子中, \u003ccode\u003e\u0026lt;section\u0026gt;\u0026lt;/section\u0026gt;\u003c/code\u003e 会被包裹成 \u003cstrong\u003e代码\u003c/strong\u003e. \u003c/p\u003e 呈现的输出效果如下： 在这个例子中, \u003csection\u003e\u003c/section\u003e 会被包裹成 代码. ","date":"2021-02-07","objectID":"/markdown-study01/:9:0","tags":["markdown"],"title":"Markdown Study01","uri":"/markdown-study01/"},{"categories":["学习"],"content":"缩进代码 // Some comments line 1 of code line 2 of code line 3 of code 输出的HTML看起来像这样： \u003cpre\u003e \u003ccode\u003e // Some comments line 1 of code line 2 of code line 3 of code \u003c/code\u003e \u003c/pre\u003e 呈现的输出效果如下： // Some comments line 1 of code line 2 of code line 3 of code ","date":"2021-02-07","objectID":"/markdown-study01/:10:0","tags":["markdown"],"title":"Markdown Study01","uri":"/markdown-study01/"},{"categories":["学习"],"content":"围栏代码块 使用“围栏”```来生成一段带有语言属性的代码块 Sample text here... Sample text here... 10 表格 通过在每个单元格之间添加竖线作为分隔线，并在标题下添加一行破折号(也由竖线分隔)来创建表格，注意竖线不需要垂直对齐 在任何标题下方的破折号右侧添加冒号将使该列的文本右对齐 在任何标题下方的破折号两边添加冒号将使该列的对齐文本居中 | Option | Description | | ------ | ----------- | | data | path to data files to supply the data that will be passed into templates. | | engine | engine to be used for processing templates. Handlebars is the default. | | ext | extension to be used for dest files. | 输出的HTML看起来像这样 \u003ctable\u003e \u003cthead\u003e \u003ctr\u003e \u003cth\u003eOption\u003c/th\u003e \u003cth\u003eDescription\u003c/th\u003e \u003c/tr\u003e \u003c/thead\u003e \u003ctbody\u003e \u003ctr\u003e \u003ctd\u003edata\u003c/td\u003e \u003ctd\u003epath to data files to supply the data that will be passed into templates.\u003c/td\u003e \u003c/tr\u003e \u003ctr\u003e \u003ctd\u003eengine\u003c/td\u003e \u003ctd\u003eengine to be used for processing templates. Handlebars is the default.\u003c/td\u003e \u003c/tr\u003e \u003ctr\u003e \u003ctd\u003eext\u003c/td\u003e \u003ctd\u003eextension to be used for dest files.\u003c/td\u003e \u003c/tr\u003e \u003c/tbody\u003e \u003c/table\u003e Option Description data path to data files to supply the data that will be passed into templates. engine engine to be used for processing templates. Handlebars is the default. ext extension to be used for dest files. 链接 ","date":"2021-02-07","objectID":"/markdown-study01/:11:0","tags":["markdown"],"title":"Markdown Study01","uri":"/markdown-study01/"},{"categories":["学习"],"content":"基本链接 \u003chttps://assemble.io\u003e \u003ccontact@revolunet.com\u003e [Assemble](https://assemble.io) 输出的HTML看起来像这样 \u003ca href=\"https://assemble.io\"\u003ehttps://assemble.io\u003c/a\u003e \u003ca href=\"mailto:contact@revolunet.com\"\u003econtact@revolunet.com\u003c/a\u003e \u003ca href=\"https://assemble.io\"\u003eAssemble\u003c/a\u003e 呈现的输出效果如下(将鼠标悬停在链接上，没有提示) https://assemble.io contact@revolunet.com Assemble ","date":"2021-02-07","objectID":"/markdown-study01/:12:0","tags":["markdown"],"title":"Markdown Study01","uri":"/markdown-study01/"},{"categories":["学习"],"content":"添加一个标题 [Upstage](https://github.com/upstage/ \"Visit Upstage!\") 输出的HTML看起来像这样 \u003ca href=\"https://github.com/upstage/\" title=\"Visit Upstage!\"\u003eUpstage\u003c/a\u003e 呈现的输出效果如下(将鼠标悬停在链接上，会有一行提示) Upstage 12 脚注 脚注使你可以添加注释和参考，而不会使文档正文混乱，当你使用脚注时，会在添加脚注引用的位置出现带有链接的上标标号，读者可以单击链接以跳至页面底部的脚注内容 要创建脚注引用，请在方括号中添加插入符号和标识符 (1)，标识符可以是数字或单词，但不能包含空格或制表符。标识符仅将脚注引用与脚注本身相关联 - 在脚注输出中, 脚注按顺序编号。 在中括号内使用插入符号和数字以及用冒号和文本来添加脚注内容 (1：这是一段脚注)。你不一定要在文档末尾添加脚注. 可以将它们放在除列表，引用和表格等元素之外的任何位置。 这是一个数字脚注[^1]. 这是一个带标签的脚注[^label] [^1]: 这是一个数字脚注 [^label]: 这是一个带标签的脚注 这是一个数字脚注1. 这是一个带标签的脚注2 13 图片 图片的语法与链接相似，但包含一个在前面的感叹号 ![Minion](https://octodex.github.com/images/minion.png) ![Alt text](https://octodex.github.com/images/stormtroopocat.jpg \"The Stormtroopocat\") The StormtroopocatAlt text \"\rThe Stormtroopocat\r 这是一个数字脚注 ↩︎ 这是一个带标签的脚注 ↩︎ ","date":"2021-02-07","objectID":"/markdown-study01/:13:0","tags":["markdown"],"title":"Markdown Study01","uri":"/markdown-study01/"},{"categories":["生活"],"content":"第一篇blog","date":"2021-02-05","objectID":"/first_post/","tags":["我的"],"title":"First_post","uri":"/first_post/"},{"categories":["生活"],"content":"first post LoveIt主题中文文档 emoji表情 去露营啦! ⛺ 很快就回来. 真开心! 😂 blog前置参数注解 ","date":"2021-02-05","objectID":"/first_post/:0:0","tags":["我的"],"title":"First_post","uri":"/first_post/"},{"categories":null,"content":"aa ","date":"0001-01-01","objectID":"/about/:0:0","tags":null,"title":"","uri":"/about/"}]